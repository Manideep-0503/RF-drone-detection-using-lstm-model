{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8W/K8SzQJJ7VyV1zXgbrC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manideep-0503/RF-drone-detection-using-lstm-model/blob/main/singlevariable_lstm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BBH1eJ_w9pmh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***generating linear sequence of the angle.***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I4GOJ3A1-3DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=[i for i in range(0,360,12)]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUPdbd3S-grl",
        "outputId": "d041a0d7-e30a-439e-d3ce-e94063118b83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 12, 24, 36, 48, 60, 72, 84, 96, 108, 120, 132, 144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276, 288, 300, 312, 324, 336, 348]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "for i in range(len(x) - 2):\n",
        "    sample = x[i:i+3]\n",
        "    X.append(sample)\n",
        "\n",
        "X_array = np.array(X)\n",
        "\n",
        "print(len(X_array))\n",
        "X_array=X_array.reshape(28,3,1)\n",
        "print(X_array.shape)\n",
        "print(X_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1W23JBG_Y6_",
        "outputId": "b1cbad49-2be4-498e-b757-b78e3a9fed43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n",
            "(28, 3, 1)\n",
            "[[[  0]\n",
            "  [ 12]\n",
            "  [ 24]]\n",
            "\n",
            " [[ 12]\n",
            "  [ 24]\n",
            "  [ 36]]\n",
            "\n",
            " [[ 24]\n",
            "  [ 36]\n",
            "  [ 48]]\n",
            "\n",
            " [[ 36]\n",
            "  [ 48]\n",
            "  [ 60]]\n",
            "\n",
            " [[ 48]\n",
            "  [ 60]\n",
            "  [ 72]]\n",
            "\n",
            " [[ 60]\n",
            "  [ 72]\n",
            "  [ 84]]\n",
            "\n",
            " [[ 72]\n",
            "  [ 84]\n",
            "  [ 96]]\n",
            "\n",
            " [[ 84]\n",
            "  [ 96]\n",
            "  [108]]\n",
            "\n",
            " [[ 96]\n",
            "  [108]\n",
            "  [120]]\n",
            "\n",
            " [[108]\n",
            "  [120]\n",
            "  [132]]\n",
            "\n",
            " [[120]\n",
            "  [132]\n",
            "  [144]]\n",
            "\n",
            " [[132]\n",
            "  [144]\n",
            "  [156]]\n",
            "\n",
            " [[144]\n",
            "  [156]\n",
            "  [168]]\n",
            "\n",
            " [[156]\n",
            "  [168]\n",
            "  [180]]\n",
            "\n",
            " [[168]\n",
            "  [180]\n",
            "  [192]]\n",
            "\n",
            " [[180]\n",
            "  [192]\n",
            "  [204]]\n",
            "\n",
            " [[192]\n",
            "  [204]\n",
            "  [216]]\n",
            "\n",
            " [[204]\n",
            "  [216]\n",
            "  [228]]\n",
            "\n",
            " [[216]\n",
            "  [228]\n",
            "  [240]]\n",
            "\n",
            " [[228]\n",
            "  [240]\n",
            "  [252]]\n",
            "\n",
            " [[240]\n",
            "  [252]\n",
            "  [264]]\n",
            "\n",
            " [[252]\n",
            "  [264]\n",
            "  [276]]\n",
            "\n",
            " [[264]\n",
            "  [276]\n",
            "  [288]]\n",
            "\n",
            " [[276]\n",
            "  [288]\n",
            "  [300]]\n",
            "\n",
            " [[288]\n",
            "  [300]\n",
            "  [312]]\n",
            "\n",
            " [[300]\n",
            "  [312]\n",
            "  [324]]\n",
            "\n",
            " [[312]\n",
            "  [324]\n",
            "  [336]]\n",
            "\n",
            " [[324]\n",
            "  [336]\n",
            "  [348]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array([X_array[i+1,2,0] for i in range(X_array.shape[0]-1)])\n",
        "y=np.append(y,360)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An0nbVOUCBRu",
        "outputId": "897c150e-3a4b-411b-cef3-618bd2a14713"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 36  48  60  72  84  96 108 120 132 144 156 168 180 192 204 216 228 240\n",
            " 252 264 276 288 300 312 324 336 348 360]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_index=int(len(X_array) * 0.8)\n",
        "\n",
        "X_train = X_array[:split_index]\n",
        "X_test = X_array[split_index:]\n",
        "y_train = y[:split_index]\n",
        "y_test = y[split_index:]"
      ],
      "metadata": {
        "id": "UBi3u957C4ds"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O51i3kfRNO9u",
        "outputId": "f3d9034a-8676-4987-81a2-fb4d20104b4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[  0]\n",
            "  [ 12]\n",
            "  [ 24]]\n",
            "\n",
            " [[ 12]\n",
            "  [ 24]\n",
            "  [ 36]]\n",
            "\n",
            " [[ 24]\n",
            "  [ 36]\n",
            "  [ 48]]\n",
            "\n",
            " [[ 36]\n",
            "  [ 48]\n",
            "  [ 60]]\n",
            "\n",
            " [[ 48]\n",
            "  [ 60]\n",
            "  [ 72]]\n",
            "\n",
            " [[ 60]\n",
            "  [ 72]\n",
            "  [ 84]]\n",
            "\n",
            " [[ 72]\n",
            "  [ 84]\n",
            "  [ 96]]\n",
            "\n",
            " [[ 84]\n",
            "  [ 96]\n",
            "  [108]]\n",
            "\n",
            " [[ 96]\n",
            "  [108]\n",
            "  [120]]\n",
            "\n",
            " [[108]\n",
            "  [120]\n",
            "  [132]]\n",
            "\n",
            " [[120]\n",
            "  [132]\n",
            "  [144]]\n",
            "\n",
            " [[132]\n",
            "  [144]\n",
            "  [156]]\n",
            "\n",
            " [[144]\n",
            "  [156]\n",
            "  [168]]\n",
            "\n",
            " [[156]\n",
            "  [168]\n",
            "  [180]]\n",
            "\n",
            " [[168]\n",
            "  [180]\n",
            "  [192]]\n",
            "\n",
            " [[180]\n",
            "  [192]\n",
            "  [204]]\n",
            "\n",
            " [[192]\n",
            "  [204]\n",
            "  [216]]\n",
            "\n",
            " [[204]\n",
            "  [216]\n",
            "  [228]]\n",
            "\n",
            " [[216]\n",
            "  [228]\n",
            "  [240]]\n",
            "\n",
            " [[228]\n",
            "  [240]\n",
            "  [252]]\n",
            "\n",
            " [[240]\n",
            "  [252]\n",
            "  [264]]\n",
            "\n",
            " [[252]\n",
            "  [264]\n",
            "  [276]]]\n",
            "[[[264]\n",
            "  [276]\n",
            "  [288]]\n",
            "\n",
            " [[276]\n",
            "  [288]\n",
            "  [300]]\n",
            "\n",
            " [[288]\n",
            "  [300]\n",
            "  [312]]\n",
            "\n",
            " [[300]\n",
            "  [312]\n",
            "  [324]]\n",
            "\n",
            " [[312]\n",
            "  [324]\n",
            "  [336]]\n",
            "\n",
            " [[324]\n",
            "  [336]\n",
            "  [348]]]\n",
            "[ 36  48  60  72  84  96 108 120 132 144 156 168 180 192 204 216 228 240\n",
            " 252 264 276 288]\n",
            "[300 312 324 336 348 360]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A_sFGT1DNOmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa75C7lfETAY",
        "outputId": "b9be84e5-ad81-4317-992d-a7433138881f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense"
      ],
      "metadata": {
        "id": "mRgrD5HsDe0W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(3, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DaTaq6uFAqN",
        "outputId": "06ae7c77-7484-449c-b986-5dde2317976e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 50)                10400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10451 (40.82 KB)\n",
            "Trainable params: 10451 (40.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxubhTH7FI97",
        "outputId": "3de777bd-f804-4805-8dff-726d80995db4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 21257.9316 - val_loss: 71082.6094\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 20583.0371 - val_loss: 68458.0078\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 19864.4570 - val_loss: 65269.8008\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 19139.0996 - val_loss: 62027.3555\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 18472.3594 - val_loss: 59409.2422\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 17889.3867 - val_loss: 57275.8008\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 17371.0215 - val_loss: 55500.3984\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 16902.6973 - val_loss: 53969.1641\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 16469.5195 - val_loss: 52636.1055\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 16063.0166 - val_loss: 51403.2188\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 15670.9287 - val_loss: 50259.0625\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15294.7100 - val_loss: 49105.4141\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 14926.0186 - val_loss: 47922.5312\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14557.7432 - val_loss: 46742.4023\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 14198.8203 - val_loss: 45541.2109\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 13832.4199 - val_loss: 44266.4766\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13449.8867 - val_loss: 42890.8750\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 13043.1875 - val_loss: 41331.1797\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 12598.2070 - val_loss: 39386.7734\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 12101.8438 - val_loss: 36952.4180\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 11560.4238 - val_loss: 34481.0508\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11013.2441 - val_loss: 32320.8398\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 10490.9404 - val_loss: 30445.7031\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9993.6123 - val_loss: 28787.6680\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 9510.2715 - val_loss: 27267.5215\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 9028.5146 - val_loss: 25743.5684\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8531.3164 - val_loss: 23962.2910\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7997.8862 - val_loss: 21640.0488\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7422.3604 - val_loss: 18990.5254\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6840.1265 - val_loss: 16785.9707\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6312.5396 - val_loss: 15245.4395\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5871.2524 - val_loss: 14133.1064\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5507.7744 - val_loss: 13270.5059\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5202.0049 - val_loss: 12552.0010\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4936.6323 - val_loss: 11909.6152\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4698.1147 - val_loss: 11304.8857\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4476.3379 - val_loss: 10717.3486\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4263.8657 - val_loss: 10133.8418\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4054.4631 - val_loss: 9535.0879\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3841.5652 - val_loss: 8883.4248\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3616.0845 - val_loss: 8097.7485\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3363.5388 - val_loss: 7021.9009\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3061.0789 - val_loss: 5492.7861\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2680.3489 - val_loss: 3689.5234\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2211.0452 - val_loss: 2069.0374\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1693.9247 - val_loss: 758.0867\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1201.1124 - val_loss: 72.3607\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 803.4937 - val_loss: 65.5536\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 550.2002 - val_loss: 459.9361\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 431.3852 - val_loss: 1326.3696\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 427.6813 - val_loss: 1834.1921\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 447.8045 - val_loss: 1908.5505\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 444.8879 - val_loss: 1701.4993\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 419.6316 - val_loss: 1412.4036\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 384.7159 - val_loss: 1205.6575\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 353.5857 - val_loss: 1108.4299\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 331.8227 - val_loss: 1074.6276\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 317.9333 - val_loss: 1063.2737\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 308.5710 - val_loss: 1053.5125\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 301.2077 - val_loss: 1037.0387\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 294.4236 - val_loss: 1011.3538\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 287.5524 - val_loss: 976.4352\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 280.3530 - val_loss: 933.4672\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 272.8231 - val_loss: 884.5231\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 265.0905 - val_loss: 832.1639\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 257.3414 - val_loss: 778.5865\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 249.7619 - val_loss: 725.2660\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 242.4969 - val_loss: 673.5815\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 235.6770 - val_loss: 624.0535\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 229.3193 - val_loss: 573.9962\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 223.0753 - val_loss: 523.3414\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 216.9003 - val_loss: 469.4033\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 210.5375 - val_loss: 403.5125\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 203.4758 - val_loss: 313.1520\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 195.4640 - val_loss: 207.5057\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 187.2916 - val_loss: 136.2782\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 180.4876 - val_loss: 121.3815\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 175.1000 - val_loss: 159.0987\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 171.5207 - val_loss: 193.6796\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 168.9722 - val_loss: 198.0055\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 165.2593 - val_loss: 167.6982\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 159.4388 - val_loss: 130.5661\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 153.2693 - val_loss: 105.6957\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 147.8983 - val_loss: 91.7930\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 142.4234 - val_loss: 85.3880\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 136.0586 - val_loss: 84.3766\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 128.6626 - val_loss: 87.1289\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 120.4901 - val_loss: 91.1583\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 112.1493 - val_loss: 93.0702\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 105.0560 - val_loss: 100.6751\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 101.2653 - val_loss: 96.8925\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 96.9242 - val_loss: 78.4541\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 90.5736 - val_loss: 59.3053\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 84.5882 - val_loss: 46.2424\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 80.1528 - val_loss: 37.2646\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 76.9326 - val_loss: 29.5982\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 74.3996 - val_loss: 22.9892\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 72.4537 - val_loss: 17.7583\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 71.1830 - val_loss: 14.1712\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 70.4172 - val_loss: 12.4781\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 69.6435 - val_loss: 13.1624\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 68.5253 - val_loss: 17.3299\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 67.1726 - val_loss: 26.6629\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 65.9175 - val_loss: 41.3838\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 65.0200 - val_loss: 57.2470\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 64.4268 - val_loss: 67.5623\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 63.8388 - val_loss: 68.5965\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 63.0453 - val_loss: 61.0576\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 62.0801 - val_loss: 48.8064\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 61.1360 - val_loss: 36.8386\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 60.3683 - val_loss: 28.6799\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 59.7284 - val_loss: 25.2733\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 59.0272 - val_loss: 26.1283\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 58.1733 - val_loss: 30.3727\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 57.2527 - val_loss: 36.4724\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 56.4029 - val_loss: 41.7963\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 55.6560 - val_loss: 43.5322\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 54.9249 - val_loss: 40.5397\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 54.1228 - val_loss: 34.1620\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 53.2561 - val_loss: 27.1017\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 52.3910 - val_loss: 21.5018\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 51.5602 - val_loss: 18.0567\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 50.7379 - val_loss: 16.4652\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 49.9050 - val_loss: 16.0824\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 49.1054 - val_loss: 16.1469\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 48.4184 - val_loss: 15.7871\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 47.8385 - val_loss: 14.3032\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 47.2040 - val_loss: 11.8839\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 46.4649 - val_loss: 9.5277\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 45.8273 - val_loss: 7.9894\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 45.3384 - val_loss: 7.4351\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 44.8144 - val_loss: 7.7367\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 44.1919 - val_loss: 8.5561\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 43.6294 - val_loss: 9.1114\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 43.1575 - val_loss: 8.6635\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 42.5869 - val_loss: 7.6610\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 42.0443 - val_loss: 6.9812\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 41.6321 - val_loss: 7.0048\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 41.2072 - val_loss: 7.6943\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 40.7529 - val_loss: 8.6433\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 40.3637 - val_loss: 9.0832\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 39.9638 - val_loss: 8.7303\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 39.5062 - val_loss: 8.2102\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 39.1181 - val_loss: 8.1487\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 38.7658 - val_loss: 8.6843\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 38.3915 - val_loss: 9.4385\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 38.0580 - val_loss: 9.6234\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 37.7347 - val_loss: 8.9446\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 37.3679 - val_loss: 8.0684\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 37.0328 - val_loss: 7.6325\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 36.7055 - val_loss: 7.7032\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 36.3672 - val_loss: 7.8570\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 36.0692 - val_loss: 7.5388\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 35.7697 - val_loss: 6.8176\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 35.4604 - val_loss: 6.2673\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 35.1742 - val_loss: 6.1880\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 34.8743 - val_loss: 6.4031\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 34.5858 - val_loss: 6.4260\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 34.3164 - val_loss: 6.0497\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 34.0385 - val_loss: 5.6611\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 33.7807 - val_loss: 5.6144\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 33.5192 - val_loss: 5.8425\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 33.2573 - val_loss: 5.9640\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 33.0069 - val_loss: 5.7746\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 32.7495 - val_loss: 5.5549\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 32.5052 - val_loss: 5.6057\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 32.2623 - val_loss: 5.8907\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 32.0214 - val_loss: 6.1096\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 31.7890 - val_loss: 6.0874\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 31.5525 - val_loss: 6.0217\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 31.3230 - val_loss: 6.1555\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 31.0950 - val_loss: 6.4645\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 30.8691 - val_loss: 6.6947\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 30.6501 - val_loss: 6.6873\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 30.4303 - val_loss: 6.5935\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 30.2153 - val_loss: 6.6252\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 30.0016 - val_loss: 6.7769\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 29.7883 - val_loss: 6.8531\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 29.5790 - val_loss: 6.7361\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 29.3697 - val_loss: 6.5537\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 29.1641 - val_loss: 6.4850\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 28.9600 - val_loss: 6.5348\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 28.7568 - val_loss: 6.5532\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 28.5566 - val_loss: 6.4226\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 28.3557 - val_loss: 6.0805\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 28.1568 - val_loss: 4.7953\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 27.9590 - val_loss: 6.2241\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 27.7766 - val_loss: 5.4167\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 27.5650 - val_loss: 3.4017\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 27.3917 - val_loss: 4.4730\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 27.1719 - val_loss: 5.0409\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 26.9987 - val_loss: 3.7127\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 26.7877 - val_loss: 3.0130\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 26.6112 - val_loss: 4.0061\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 26.4115 - val_loss: 3.7551\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 26.2218 - val_loss: 2.6127\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 26.0369 - val_loss: 2.7848\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 25.8382 - val_loss: 3.2934\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 25.6635 - val_loss: 2.6890\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 25.4643 - val_loss: 2.2804\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 25.2895 - val_loss: 2.7449\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 25.0975 - val_loss: 2.7650\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 24.9174 - val_loss: 2.1928\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 24.7330 - val_loss: 2.1666\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 24.5481 - val_loss: 2.4622\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 24.3696 - val_loss: 2.1209\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 24.1870 - val_loss: 1.7590\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 24.0163 - val_loss: 1.9599\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 23.8372 - val_loss: 1.9801\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 23.6648 - val_loss: 1.6038\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 23.4895 - val_loss: 1.6029\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 23.3142 - val_loss: 1.7977\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 23.1432 - val_loss: 1.5510\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 22.9675 - val_loss: 1.3765\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 22.7983 - val_loss: 1.5614\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 22.6297 - val_loss: 1.4564\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 22.4621 - val_loss: 1.2131\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 22.2977 - val_loss: 1.3302\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 22.1307 - val_loss: 1.3221\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 21.9670 - val_loss: 1.0878\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 21.8040 - val_loss: 1.1585\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 21.6400 - val_loss: 1.1962\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 21.4791 - val_loss: 0.9913\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 21.3182 - val_loss: 1.0490\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 21.1599 - val_loss: 0.9948\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 21.0027 - val_loss: 0.8544\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 20.8442 - val_loss: 0.9144\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 20.6881 - val_loss: 0.7852\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 20.5330 - val_loss: 0.6715\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 20.3782 - val_loss: 0.6856\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 20.2240 - val_loss: 0.5062\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 20.0703 - val_loss: 0.6078\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 19.9167 - val_loss: 0.4538\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 19.7634 - val_loss: 0.5689\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 19.6102 - val_loss: 0.4478\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 19.4573 - val_loss: 0.5517\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 19.3081 - val_loss: 0.3182\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 19.1604 - val_loss: 0.6856\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 19.0161 - val_loss: 0.1133\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 18.8878 - val_loss: 1.1758\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 18.7927 - val_loss: 8.5204e-04\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 18.6823 - val_loss: 0.9924\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 18.4891 - val_loss: 0.2273\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 18.2881 - val_loss: 0.0888\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 18.1688 - val_loss: 0.9993\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 18.0672 - val_loss: 0.0554\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 17.9026 - val_loss: 0.3598\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 17.7241 - val_loss: 0.7416\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 17.6145 - val_loss: 0.0257\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 17.5008 - val_loss: 0.5417\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 17.3234 - val_loss: 0.3828\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 17.1754 - val_loss: 0.0296\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 17.0667 - val_loss: 0.5417\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 16.9258 - val_loss: 0.1063\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 16.7651 - val_loss: 0.0742\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 16.6315 - val_loss: 0.4420\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 16.5123 - val_loss: 0.0246\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 16.3718 - val_loss: 0.2264\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 16.2219 - val_loss: 0.2440\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 16.0881 - val_loss: 0.0284\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 15.9641 - val_loss: 0.3358\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 15.8262 - val_loss: 0.0655\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 15.6817 - val_loss: 0.0773\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 15.5453 - val_loss: 0.1984\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 15.4184 - val_loss: 0.0059\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 15.2902 - val_loss: 0.1792\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 15.1528 - val_loss: 0.0186\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 15.0118 - val_loss: 0.0553\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 14.8753 - val_loss: 0.0819\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 14.7437 - val_loss: 0.0093\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 14.6141 - val_loss: 0.1385\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 14.4850 - val_loss: 0.0051\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 14.3531 - val_loss: 0.1034\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 14.2186 - val_loss: 0.0068\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 14.0841 - val_loss: 0.0596\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 13.9494 - val_loss: 0.0066\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 13.8151 - val_loss: 0.0282\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 13.6829 - val_loss: 0.0075\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 13.5500 - val_loss: 0.0177\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 13.4175 - val_loss: 0.0110\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 13.2862 - val_loss: 0.0097\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 13.1548 - val_loss: 0.0124\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 13.0234 - val_loss: 0.0150\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 12.8923 - val_loss: 0.0154\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 12.7640 - val_loss: 0.0639\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 12.6391 - val_loss: 0.0631\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 12.5233 - val_loss: 0.3266\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 12.4438 - val_loss: 0.5140\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 12.4269 - val_loss: 1.4349\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 12.5068 - val_loss: 0.8733\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 12.2909 - val_loss: 0.2847\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 11.9175 - val_loss: 0.1750\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 11.7614 - val_loss: 0.5790\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 11.8059 - val_loss: 0.5110\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11.6082 - val_loss: 0.0352\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11.3501 - val_loss: 0.4208\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 11.3738 - val_loss: 0.4777\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 11.2194 - val_loss: 0.0368\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 10.9701 - val_loss: 0.3268\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 10.9778 - val_loss: 0.4133\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 10.8077 - val_loss: 0.0905\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 10.5985 - val_loss: 0.2420\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 10.5888 - val_loss: 0.2946\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 10.3907 - val_loss: 0.1630\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10.2338 - val_loss: 0.1748\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 10.1917 - val_loss: 0.1519\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.9844 - val_loss: 0.2254\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.8756 - val_loss: 0.0925\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.7806 - val_loss: 0.0625\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.5929 - val_loss: 0.2736\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9.5069 - val_loss: 0.0233\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 9.3759 - val_loss: 0.0326\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 9.2217 - val_loss: 0.3020\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9.1322 - val_loss: 0.0142\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.9840 - val_loss: 0.0205\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.8562 - val_loss: 0.2819\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.7524 - val_loss: 0.0406\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.6042 - val_loss: 0.0166\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.4908 - val_loss: 0.2520\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.3736 - val_loss: 0.0803\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 8.2323 - val_loss: 0.0186\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.1246 - val_loss: 0.2366\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.0011 - val_loss: 0.1188\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.8669 - val_loss: 0.0245\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.7577 - val_loss: 0.2094\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.6310 - val_loss: 0.1444\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.5044 - val_loss: 0.0348\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.3936 - val_loss: 0.2042\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.2676 - val_loss: 0.1621\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.1444 - val_loss: 0.0494\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.0324 - val_loss: 0.2072\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.9087 - val_loss: 0.1687\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7877 - val_loss: 0.0626\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.6754 - val_loss: 0.2072\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.5547 - val_loss: 0.1628\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.4368 - val_loss: 0.0792\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.3246 - val_loss: 0.2126\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.2066 - val_loss: 0.1550\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.0895 - val_loss: 0.0991\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.9781 - val_loss: 0.2270\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.8648 - val_loss: 0.1536\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.7498 - val_loss: 0.1205\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.6393 - val_loss: 0.2320\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.5290 - val_loss: 0.1432\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.4168 - val_loss: 0.1382\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.3081 - val_loss: 0.2332\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.2008 - val_loss: 0.1279\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.0921 - val_loss: 0.1669\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.9843 - val_loss: 0.2213\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.8797 - val_loss: 0.1294\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.7756 - val_loss: 0.2067\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.6704 - val_loss: 0.1920\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.5673 - val_loss: 0.1423\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.4665 - val_loss: 0.2211\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.3659 - val_loss: 0.1637\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.2655 - val_loss: 0.1596\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.1671 - val_loss: 0.2108\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.0702 - val_loss: 0.1423\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.9737 - val_loss: 0.1782\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.8778 - val_loss: 0.1791\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.7835 - val_loss: 0.1407\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.6903 - val_loss: 0.1755\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.5974 - val_loss: 0.1478\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.5064 - val_loss: 0.1414\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.4178 - val_loss: 0.1658\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.3300 - val_loss: 0.0986\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.2433 - val_loss: 0.1293\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.1575 - val_loss: 0.1108\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0722 - val_loss: 0.1047\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9886 - val_loss: 0.1395\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9137 - val_loss: 0.0889\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8265 - val_loss: 0.1072\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7486 - val_loss: 0.1134\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.6711 - val_loss: 0.0846\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5950 - val_loss: 0.1344\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5202 - val_loss: 0.0822\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4464 - val_loss: 0.1039\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3729 - val_loss: 0.0656\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.3012 - val_loss: 0.0569\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.2314 - val_loss: 0.0619\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.1624 - val_loss: 0.0419\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.1015 - val_loss: 0.0624\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.0304 - val_loss: 0.0226\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.9674 - val_loss: 0.0625\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9047 - val_loss: 0.0242\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8433 - val_loss: 0.0576\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7831 - val_loss: 0.0252\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.7234 - val_loss: 0.0383\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.6650 - val_loss: 0.0274\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.6079 - val_loss: 0.0330\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.5518 - val_loss: 0.0345\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4976 - val_loss: 0.0391\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.4456 - val_loss: 0.0481\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.3953 - val_loss: 0.0524\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3456 - val_loss: 0.0652\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2973 - val_loss: 0.0686\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2499 - val_loss: 0.0968\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1.2036 - val_loss: 0.0939\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1586 - val_loss: 0.1398\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1144 - val_loss: 0.1129\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.0720 - val_loss: 0.1968\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.0390 - val_loss: 0.1297\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9961 - val_loss: 0.3203\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9642 - val_loss: 0.1252\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9371 - val_loss: 0.4839\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9191 - val_loss: 0.1267\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9202 - val_loss: 0.8978\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9268 - val_loss: 0.1655\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.9605 - val_loss: 1.3076\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.9174 - val_loss: 0.1724\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8455 - val_loss: 0.8615\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7156 - val_loss: 0.6652\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6578 - val_loss: 0.3334\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6775 - val_loss: 1.3984\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6813 - val_loss: 0.3931\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6338 - val_loss: 1.0087\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5556 - val_loss: 1.0805\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5339 - val_loss: 0.4956\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5506 - val_loss: 1.3906\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5209 - val_loss: 0.7046\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4678 - val_loss: 0.8407\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4384 - val_loss: 1.3358\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4403 - val_loss: 0.6510\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4304 - val_loss: 1.2863\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3898 - val_loss: 1.0940\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3606 - val_loss: 0.8440\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.3563 - val_loss: 1.4615\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3470 - val_loss: 0.8919\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3212 - val_loss: 1.1403\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2962 - val_loss: 1.3393\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2886 - val_loss: 0.8849\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2831 - val_loss: 1.3885\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.2637 - val_loss: 1.0909\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2423 - val_loss: 1.0313\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2319 - val_loss: 1.3614\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.2259 - val_loss: 0.9379\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2144 - val_loss: 1.2274\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.1977 - val_loss: 1.1474\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1868 - val_loss: 0.9716\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.1800 - val_loss: 1.2945\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1738 - val_loss: 0.9719\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.1632 - val_loss: 1.1440\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1516 - val_loss: 1.1555\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.1438 - val_loss: 0.9828\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.1385 - val_loss: 1.2648\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.1313 - val_loss: 1.0377\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1220 - val_loss: 1.1849\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.1147 - val_loss: 1.2149\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1091 - val_loss: 1.0760\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1039 - val_loss: 1.2871\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0983 - val_loss: 1.0781\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0923 - val_loss: 1.1878\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0864 - val_loss: 1.1786\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0816 - val_loss: 1.1000\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0775 - val_loss: 1.2733\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0734 - val_loss: 1.1188\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0687 - val_loss: 1.2581\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0644 - val_loss: 1.2018\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0605 - val_loss: 1.1879\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0567 - val_loss: 1.2810\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0536 - val_loss: 1.1633\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0509 - val_loss: 1.2963\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0479 - val_loss: 1.2094\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0447 - val_loss: 1.2682\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0417 - val_loss: 1.2915\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0391 - val_loss: 1.2451\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0369 - val_loss: 1.3463\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0349 - val_loss: 1.2575\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0326 - val_loss: 1.3476\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0305 - val_loss: 1.2897\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0284 - val_loss: 1.3145\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0267 - val_loss: 1.3348\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0250 - val_loss: 1.3018\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0235 - val_loss: 1.3692\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0221 - val_loss: 1.3057\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0209 - val_loss: 1.3713\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0195 - val_loss: 1.3265\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0182 - val_loss: 1.3594\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0170 - val_loss: 1.3540\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0160 - val_loss: 1.3487\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0150 - val_loss: 1.3829\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0140 - val_loss: 1.3502\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0132 - val_loss: 1.4017\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0124 - val_loss: 1.3598\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - val_loss: 1.4023\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0108 - val_loss: 1.3639\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0101 - val_loss: 1.3903\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - val_loss: 1.3741\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - val_loss: 1.3874\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0083 - val_loss: 1.3880\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0078 - val_loss: 1.3816\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0074 - val_loss: 1.3945\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0069 - val_loss: 1.3714\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0065 - val_loss: 1.3972\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0061 - val_loss: 1.3719\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - val_loss: 1.4037\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0054 - val_loss: 1.3762\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - val_loss: 1.4057\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0048 - val_loss: 1.3773\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0046 - val_loss: 1.4033\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0043 - val_loss: 1.3750\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - val_loss: 1.4019\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - val_loss: 1.3760\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - val_loss: 1.4050\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 1.3758\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 1.4069\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 1.3686\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - val_loss: 1.4061\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - val_loss: 1.3570\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - val_loss: 1.4120\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - val_loss: 1.3477\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - val_loss: 1.4286\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - val_loss: 1.3305\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 1.4507\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - val_loss: 1.2960\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 1.4881\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 1.2411\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0050 - val_loss: 1.5594\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - val_loss: 1.1507\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0103 - val_loss: 1.6963\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0160 - val_loss: 1.0080\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0270 - val_loss: 1.9561\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0423 - val_loss: 0.8156\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0730 - val_loss: 2.3787\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1021 - val_loss: 0.6510\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1554 - val_loss: 2.7401\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1552 - val_loss: 0.7100\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1494 - val_loss: 2.3470\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0664 - val_loss: 1.3588\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0100 - val_loss: 1.4135\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0087 - val_loss: 2.3383\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0472 - val_loss: 1.0255\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0773 - val_loss: 2.3815\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0468 - val_loss: 1.4735\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0099 - val_loss: 1.5723\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0050 - val_loss: 2.2491\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0291 - val_loss: 1.2170\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0435 - val_loss: 2.1777\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0219 - val_loss: 1.6562\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - val_loss: 1.5109\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0086 - val_loss: 2.1823\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0232 - val_loss: 1.3410\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0228 - val_loss: 1.9245\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - val_loss: 1.7661\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - val_loss: 1.4129\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0117 - val_loss: 2.0190\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0161 - val_loss: 1.4041\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0094 - val_loss: 1.6647\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - val_loss: 1.7429\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - val_loss: 1.3231\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0106 - val_loss: 1.7929\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0091 - val_loss: 1.4088\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - val_loss: 1.4666\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 1.6527\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - val_loss: 1.2729\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - val_loss: 1.6075\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0047 - val_loss: 1.3934\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 1.3505\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 1.5571\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - val_loss: 1.2502\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - val_loss: 1.4797\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - val_loss: 1.3683\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 1.2873\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 1.4738\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - val_loss: 1.2359\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - val_loss: 1.3954\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 1.3371\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 1.2559\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 1.4105\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - val_loss: 1.2298\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - val_loss: 1.3490\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 1.3093\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 1.2475\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 1.3658\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - val_loss: 1.2254\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0018 - val_loss: 1.3241\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 1.2823\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0011 - val_loss: 1.2452\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 1.3286\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 1.2206\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 1.3034\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - val_loss: 1.2601\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 1.2445\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 1.3010\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - val_loss: 1.2201\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 1.2924\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 1.2458\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 1.2506\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 1.2813\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 1.2245\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 1.2845\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - val_loss: 1.2351\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0011 - val_loss: 1.2558\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.9090e-04 - val_loss: 1.2617\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0010 - val_loss: 1.2283\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 1.2719\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 1.2259\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - val_loss: 1.2565\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 9.9726e-04 - val_loss: 1.2431\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.7078e-04 - val_loss: 1.2332\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9.8342e-04 - val_loss: 1.2579\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - val_loss: 1.2230\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 1.2552\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9.9947e-04 - val_loss: 1.2302\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.7072e-04 - val_loss: 1.2392\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.5415e-04 - val_loss: 1.2429\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.5790e-04 - val_loss: 1.2241\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 9.7116e-04 - val_loss: 1.2467\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.7736e-04 - val_loss: 1.2194\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.6958e-04 - val_loss: 1.2378\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.5385e-04 - val_loss: 1.2240\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9.4091e-04 - val_loss: 1.2232\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.3732e-04 - val_loss: 1.2296\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 9.4163e-04 - val_loss: 1.2124\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.4689e-04 - val_loss: 1.2297\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.4793e-04 - val_loss: 1.2090\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.4261e-04 - val_loss: 1.2226\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.3321e-04 - val_loss: 1.2117\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 9.2507e-04 - val_loss: 1.2117\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.2179e-04 - val_loss: 1.2150\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.2261e-04 - val_loss: 1.2027\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.2474e-04 - val_loss: 1.2143\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.2483e-04 - val_loss: 1.1989\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.2192e-04 - val_loss: 1.2092\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9.1715e-04 - val_loss: 1.1991\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.1164e-04 - val_loss: 1.2015\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.0826e-04 - val_loss: 1.2007\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.0634e-04 - val_loss: 1.1943\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 9.0657e-04 - val_loss: 1.2009\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 9.0616e-04 - val_loss: 1.1898\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.0546e-04 - val_loss: 1.1989\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.0382e-04 - val_loss: 1.1877\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.0111e-04 - val_loss: 1.1952\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.9830e-04 - val_loss: 1.1869\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8.9536e-04 - val_loss: 1.1902\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.9234e-04 - val_loss: 1.1870\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.9028e-04 - val_loss: 1.1851\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.8861e-04 - val_loss: 1.1867\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 8.8730e-04 - val_loss: 1.1809\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.8648e-04 - val_loss: 1.1858\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.8520e-04 - val_loss: 1.1775\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.8439e-04 - val_loss: 1.1837\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.8241e-04 - val_loss: 1.1753\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.8061e-04 - val_loss: 1.1809\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 8.7905e-04 - val_loss: 1.1736\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.7679e-04 - val_loss: 1.1779\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.7472e-04 - val_loss: 1.1723\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.7252e-04 - val_loss: 1.1739\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.7063e-04 - val_loss: 1.1707\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.6869e-04 - val_loss: 1.1699\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.6713e-04 - val_loss: 1.1691\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.6546e-04 - val_loss: 1.1662\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.6439e-04 - val_loss: 1.1678\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.6298e-04 - val_loss: 1.1625\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.6196e-04 - val_loss: 1.1664\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.6072e-04 - val_loss: 1.1591\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.5975e-04 - val_loss: 1.1643\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.5835e-04 - val_loss: 1.1560\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5739e-04 - val_loss: 1.1620\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5563e-04 - val_loss: 1.1532\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.5434e-04 - val_loss: 1.1594\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.5275e-04 - val_loss: 1.1504\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5171e-04 - val_loss: 1.1573\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.5070e-04 - val_loss: 1.1469\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.4976e-04 - val_loss: 1.1557\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.4935e-04 - val_loss: 1.1432\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.4925e-04 - val_loss: 1.1543\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.4921e-04 - val_loss: 1.1394\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.4917e-04 - val_loss: 1.1533\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.5010e-04 - val_loss: 1.1350\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.5245e-04 - val_loss: 1.1530\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5473e-04 - val_loss: 1.1298\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.5978e-04 - val_loss: 1.1540\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.6717e-04 - val_loss: 1.1233\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.7935e-04 - val_loss: 1.1571\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.9748e-04 - val_loss: 1.1144\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.2723e-04 - val_loss: 1.1644\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 9.7708e-04 - val_loss: 1.1007\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 1.1778\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 1.0797\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 1.2009\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 1.0469\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - val_loss: 1.2443\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 0.9928\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0048 - val_loss: 1.3233\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0073 - val_loss: 0.9063\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0120 - val_loss: 1.4722\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0193 - val_loss: 0.7727\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 1.7513\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0531 - val_loss: 0.6021\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0917 - val_loss: 2.1950\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1255 - val_loss: 0.4767\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1877 - val_loss: 2.5048\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.1728 - val_loss: 0.5683\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.1528 - val_loss: 2.0203\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0587 - val_loss: 1.2301\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - val_loss: 1.1359\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0149 - val_loss: 2.1607\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0581 - val_loss: 0.8461\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0838 - val_loss: 2.1056\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0438 - val_loss: 1.3394\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0061 - val_loss: 1.3173\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0084 - val_loss: 2.0864\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0353 - val_loss: 1.0546\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0453 - val_loss: 1.9333\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0185 - val_loss: 1.5373\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - val_loss: 1.2823\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0127 - val_loss: 1.9994\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0262 - val_loss: 1.1806\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0212 - val_loss: 1.6627\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0045 - val_loss: 1.6122\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - val_loss: 1.1871\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0147 - val_loss: 1.7867\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0164 - val_loss: 1.2280\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0073 - val_loss: 1.3969\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0011 - val_loss: 1.5490\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - val_loss: 1.1057\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0118 - val_loss: 1.5438\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - val_loss: 1.2265\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0021 - val_loss: 1.2205\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0018 - val_loss: 1.4495\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0061 - val_loss: 1.0727\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0075 - val_loss: 1.3680\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - val_loss: 1.2130\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 9.6475e-04 - val_loss: 1.1241\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 1.3531\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - val_loss: 1.0616\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0043 - val_loss: 1.2506\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0018 - val_loss: 1.1924\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 9.6486e-04 - val_loss: 1.0756\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - val_loss: 1.2743\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - val_loss: 1.0592\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 1.1770\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0011 - val_loss: 1.1713\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0011 - val_loss: 1.0568\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - val_loss: 1.2203\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0024 - val_loss: 1.0631\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0016 - val_loss: 1.1358\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 8.7576e-04 - val_loss: 1.1504\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0011 - val_loss: 1.0486\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 1.1768\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - val_loss: 1.0605\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 1.1073\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.3043e-04 - val_loss: 1.1258\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.9481e-04 - val_loss: 1.0419\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 1.1406\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 1.0518\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 1.0866\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.2077e-04 - val_loss: 1.1011\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.1746e-04 - val_loss: 1.0372\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - val_loss: 1.1133\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0011 - val_loss: 1.0425\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 9.6661e-04 - val_loss: 1.0731\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 8.1700e-04 - val_loss: 1.0784\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 8.5118e-04 - val_loss: 1.0328\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 9.7633e-04 - val_loss: 1.0904\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0010 - val_loss: 1.0325\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 9.2350e-04 - val_loss: 1.0633\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 8.1904e-04 - val_loss: 1.0588\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 8.0931e-04 - val_loss: 1.0310\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.7652e-04 - val_loss: 1.0729\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 9.2215e-04 - val_loss: 1.0259\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8.9264e-04 - val_loss: 1.0582\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.2547e-04 - val_loss: 1.0451\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9287e-04 - val_loss: 1.0338\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 8.1636e-04 - val_loss: 1.0612\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.5495e-04 - val_loss: 1.0251\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.6051e-04 - val_loss: 1.0564\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.2837e-04 - val_loss: 1.0364\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.9393e-04 - val_loss: 1.0388\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.8773e-04 - val_loss: 1.0516\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.0587e-04 - val_loss: 1.0277\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.2284e-04 - val_loss: 1.0542\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.1844e-04 - val_loss: 1.0318\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 7.9817e-04 - val_loss: 1.0439\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.8091e-04 - val_loss: 1.0439\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.7964e-04 - val_loss: 1.0329\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 7.8994e-04 - val_loss: 1.0512\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.9809e-04 - val_loss: 1.0311\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.9458e-04 - val_loss: 1.0480\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.8302e-04 - val_loss: 1.0382\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 7.7278e-04 - val_loss: 1.0389\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.7077e-04 - val_loss: 1.0459\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.7506e-04 - val_loss: 1.0328\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.7926e-04 - val_loss: 1.0474\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.7816e-04 - val_loss: 1.0336\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.7234e-04 - val_loss: 1.0421\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.6571e-04 - val_loss: 1.0386\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.6266e-04 - val_loss: 1.0350\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.6347e-04 - val_loss: 1.0421\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 7.6510e-04 - val_loss: 1.0312\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.6520e-04 - val_loss: 1.0409\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.6302e-04 - val_loss: 1.0318\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.5908e-04 - val_loss: 1.0360\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.5598e-04 - val_loss: 1.0343\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.5437e-04 - val_loss: 1.0305\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.5426e-04 - val_loss: 1.0355\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 7.5460e-04 - val_loss: 1.0270\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.5423e-04 - val_loss: 1.0337\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.5248e-04 - val_loss: 1.0264\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 7.4986e-04 - val_loss: 1.0295\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.4747e-04 - val_loss: 1.0271\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.4600e-04 - val_loss: 1.0248\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.4498e-04 - val_loss: 1.0273\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.4438e-04 - val_loss: 1.0213\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.4365e-04 - val_loss: 1.0258\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.4275e-04 - val_loss: 1.0198\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.4085e-04 - val_loss: 1.0228\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 7.3907e-04 - val_loss: 1.0194\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 7.3776e-04 - val_loss: 1.0191\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.3620e-04 - val_loss: 1.0190\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.3552e-04 - val_loss: 1.0157\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.3454e-04 - val_loss: 1.0180\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.3365e-04 - val_loss: 1.0133\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.3259e-04 - val_loss: 1.0161\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.3126e-04 - val_loss: 1.0117\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 7.2992e-04 - val_loss: 1.0134\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.2844e-04 - val_loss: 1.0108\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.2737e-04 - val_loss: 1.0104\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.2603e-04 - val_loss: 1.0099\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.2483e-04 - val_loss: 1.0077\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.2360e-04 - val_loss: 1.0085\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.2261e-04 - val_loss: 1.0054\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.2150e-04 - val_loss: 1.0068\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 7.2035e-04 - val_loss: 1.0035\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.1957e-04 - val_loss: 1.0046\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.1796e-04 - val_loss: 1.0019\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.1693e-04 - val_loss: 1.0021\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 7.1568e-04 - val_loss: 1.0006\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.1430e-04 - val_loss: 0.9996\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.1345e-04 - val_loss: 0.9992\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.1209e-04 - val_loss: 0.9972\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.1103e-04 - val_loss: 0.9976\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.0984e-04 - val_loss: 0.9949\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 7.0886e-04 - val_loss: 0.9958\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0761e-04 - val_loss: 0.9930\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.0644e-04 - val_loss: 0.9938\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.0548e-04 - val_loss: 0.9911\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.0438e-04 - val_loss: 0.9918\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.0328e-04 - val_loss: 0.9893\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.0196e-04 - val_loss: 0.9897\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.0098e-04 - val_loss: 0.9875\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.9963e-04 - val_loss: 0.9876\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.9843e-04 - val_loss: 0.9858\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.9731e-04 - val_loss: 0.9856\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.9638e-04 - val_loss: 0.9840\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.9531e-04 - val_loss: 0.9837\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.9420e-04 - val_loss: 0.9822\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.9285e-04 - val_loss: 0.9817\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.9195e-04 - val_loss: 0.9804\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.9062e-04 - val_loss: 0.9798\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.8976e-04 - val_loss: 0.9786\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.8859e-04 - val_loss: 0.9780\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.8732e-04 - val_loss: 0.9768\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.8627e-04 - val_loss: 0.9762\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.8512e-04 - val_loss: 0.9749\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.8400e-04 - val_loss: 0.9744\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6.8301e-04 - val_loss: 0.9731\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.8177e-04 - val_loss: 0.9727\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.8106e-04 - val_loss: 0.9712\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.7988e-04 - val_loss: 0.9710\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.7888e-04 - val_loss: 0.9693\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.7744e-04 - val_loss: 0.9693\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.7649e-04 - val_loss: 0.9673\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.7568e-04 - val_loss: 0.9678\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7457e-04 - val_loss: 0.9651\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.7346e-04 - val_loss: 0.9665\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.7269e-04 - val_loss: 0.9627\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.7160e-04 - val_loss: 0.9655\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.7094e-04 - val_loss: 0.9599\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.7007e-04 - val_loss: 0.9649\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7041e-04 - val_loss: 0.9567\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.7074e-04 - val_loss: 0.9651\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.7201e-04 - val_loss: 0.9524\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.7472e-04 - val_loss: 0.9665\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6.8002e-04 - val_loss: 0.9464\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.8971e-04 - val_loss: 0.9705\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 7.0707e-04 - val_loss: 0.9373\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.3750e-04 - val_loss: 0.9786\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.9093e-04 - val_loss: 0.9227\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 8.8725e-04 - val_loss: 0.9950\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.8978\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 1.0271\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.8546\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - val_loss: 1.0906\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0048 - val_loss: 0.7793\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0085 - val_loss: 1.2187\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0147 - val_loss: 0.6546\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0276 - val_loss: 1.4812\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0474 - val_loss: 0.4806\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0902 - val_loss: 1.9809\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1380 - val_loss: 0.3364\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.2390 - val_loss: 2.5946\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.2634 - val_loss: 0.3390\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.3031 - val_loss: 2.3120\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1468 - val_loss: 0.9075\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0275 - val_loss: 1.1041\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0104 - val_loss: 2.2411\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0850 - val_loss: 0.6686\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.1409 - val_loss: 2.1894\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0626 - val_loss: 1.3915\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - val_loss: 1.1011\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0306 - val_loss: 2.3238\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0700 - val_loss: 1.0136\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0538 - val_loss: 1.7263\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - val_loss: 1.9242\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0174 - val_loss: 1.0424\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0518 - val_loss: 2.0696\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0309 - val_loss: 1.4748\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - val_loss: 1.2673\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0139 - val_loss: 2.0184\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0307 - val_loss: 1.1759\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0190 - val_loss: 1.5010\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - val_loss: 1.7010\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0116 - val_loss: 1.0515\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0231 - val_loss: 1.6037\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0104 - val_loss: 1.3301\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0011 - val_loss: 1.0773\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0096 - val_loss: 1.5493\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0143 - val_loss: 1.0696\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - val_loss: 1.1856\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 1.3722\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - val_loss: 0.9590\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0102 - val_loss: 1.2740\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - val_loss: 1.1560\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.9690\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0053 - val_loss: 1.2685\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0066 - val_loss: 0.9849\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0027 - val_loss: 1.0362\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 9.2121e-04 - val_loss: 1.1649\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - val_loss: 0.9031\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - val_loss: 1.0959\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - val_loss: 1.0294\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 8.2709e-04 - val_loss: 0.9118\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - val_loss: 1.1035\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - val_loss: 0.9273\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - val_loss: 0.9691\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 7.3013e-04 - val_loss: 1.0494\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - val_loss: 0.8868\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - val_loss: 1.0191\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - val_loss: 0.9674\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 6.9015e-04 - val_loss: 0.9015\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0014 - val_loss: 1.0219\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0018 - val_loss: 0.9006\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.9408\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.7567e-04 - val_loss: 0.9779\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0011 - val_loss: 0.8773\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0015 - val_loss: 0.9703\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0011 - val_loss: 0.9210\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 6.8168e-04 - val_loss: 0.8950\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 8.7933e-04 - val_loss: 0.9666\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0012 - val_loss: 0.8827\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 9.9817e-04 - val_loss: 0.9265\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.9518e-04 - val_loss: 0.9326\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 7.5298e-04 - val_loss: 0.8773\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 9.7148e-04 - val_loss: 0.9420\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 9.2316e-04 - val_loss: 0.8934\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 7.1056e-04 - val_loss: 0.8954\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 6.8346e-04 - val_loss: 0.9287\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 8.2625e-04 - val_loss: 0.8731\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 8.5510e-04 - val_loss: 0.9155\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 7.2343e-04 - val_loss: 0.8999\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.5624e-04 - val_loss: 0.8796\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 7.3128e-04 - val_loss: 0.9193\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 7.8681e-04 - val_loss: 0.8785\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 7.2597e-04 - val_loss: 0.8988\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 6.5321e-04 - val_loss: 0.9047\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.7390e-04 - val_loss: 0.8767\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 7.2828e-04 - val_loss: 0.9108\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 7.1617e-04 - val_loss: 0.8861\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 6.6058e-04 - val_loss: 0.8903\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 6.4666e-04 - val_loss: 0.9060\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 6.8033e-04 - val_loss: 0.8792\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 6.9487e-04 - val_loss: 0.9039\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 6.6578e-04 - val_loss: 0.8922\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6.3887e-04 - val_loss: 0.8875\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.4842e-04 - val_loss: 0.9060\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.6835e-04 - val_loss: 0.8846\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 6.6258e-04 - val_loss: 0.9007\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 6.4002e-04 - val_loss: 0.8979\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6.3283e-04 - val_loss: 0.8888\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.4481e-04 - val_loss: 0.9060\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.5181e-04 - val_loss: 0.8898\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6.4083e-04 - val_loss: 0.8990\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 6.2804e-04 - val_loss: 0.9004\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.2894e-04 - val_loss: 0.8901\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 6.3641e-04 - val_loss: 0.9039\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 6.3617e-04 - val_loss: 0.8921\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 6.2735e-04 - val_loss: 0.8964\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.2126e-04 - val_loss: 0.8996\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 6.2361e-04 - val_loss: 0.8899\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 6.2738e-04 - val_loss: 0.9004\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 6.2501e-04 - val_loss: 0.8919\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 6.1874e-04 - val_loss: 0.8936\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 6.1558e-04 - val_loss: 0.8968\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 6.1715e-04 - val_loss: 0.8884\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.1844e-04 - val_loss: 0.8959\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.1601e-04 - val_loss: 0.8895\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 6.1201e-04 - val_loss: 0.8897\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6.1003e-04 - val_loss: 0.8922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(X_test).flatten()\n",
        "print(X_test)\n",
        "print(test_predictions)\n",
        "test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test})\n",
        "test_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "QDgQzgCEFs_H",
        "outputId": "3ff6cb81-5fea-4796-d727-4d47c108ce8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 197ms/step\n",
            "[[[264]\n",
            "  [276]\n",
            "  [288]]\n",
            "\n",
            " [[276]\n",
            "  [288]\n",
            "  [300]]\n",
            "\n",
            " [[288]\n",
            "  [300]\n",
            "  [312]]\n",
            "\n",
            " [[300]\n",
            "  [312]\n",
            "  [324]]\n",
            "\n",
            " [[312]\n",
            "  [324]\n",
            "  [336]]\n",
            "\n",
            " [[324]\n",
            "  [336]\n",
            "  [348]]]\n",
            "[302.0077  314.49863 327.01102 339.5382  352.0749  364.61688]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Test Predictions  Actuals\n",
              "0        302.007690      300\n",
              "1        314.498627      312\n",
              "2        327.011017      324\n",
              "3        339.538208      336\n",
              "4        352.074890      348\n",
              "5        364.616882      360"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1d4241f-695f-411f-8e7b-185f9eb2de5b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Predictions</th>\n",
              "      <th>Actuals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>302.007690</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>314.498627</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>327.011017</td>\n",
              "      <td>324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>339.538208</td>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>352.074890</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>364.616882</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1d4241f-695f-411f-8e7b-185f9eb2de5b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1d4241f-695f-411f-8e7b-185f9eb2de5b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1d4241f-695f-411f-8e7b-185f9eb2de5b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ed4be44-8de9-4ff8-9690-3a57a8221026\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ed4be44-8de9-4ff8-9690-3a57a8221026')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ed4be44-8de9-4ff8-9690-3a57a8221026 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a70544e5-138c-4bb8-966c-488bbad55e3c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a70544e5-138c-4bb8-966c-488bbad55e3c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_results",
              "summary": "{\n  \"name\": \"test_results\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Test Predictions\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          302.0076904296875,\n          314.4986267089844,\n          364.61688232421875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actuals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 300,\n        \"max\": 360,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          300,\n          312,\n          360\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_results['Test Predictions'],color='blue',marker='o')\n",
        "plt.plot(test_results['Actuals'],color='red',marker='s')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "VbxddybTPCYG",
        "outputId": "b91a4fc8-8b4a-43cb-a84e-72377cce80f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7a1630221510>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(3, 1)))\n",
        "model1.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model1.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model1.add(LSTM(25, activation='relu'))\n",
        "model1.add(Dense(20, activation='relu'))\n",
        "model1.add(Dense(10, activation='relu'))\n",
        "model1.add(Dense(1))\n",
        "model1.compile(optimizer='adam', loss='mse')\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsKPYbPEU7tH",
        "outputId": "07b7980a-9df3-4613-c4c1-a477f06bd22e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 3, 200)            161600    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 100)            120400    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 3, 50)             30200     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 25)                7600      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                520       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320541 (1.22 MB)\n",
            "Trainable params: 320541 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FkLCMruVQSk",
        "outputId": "c21a3a96-18e2-4762-c8ba-16aa6a36f277"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 6s 6s/step - loss: 20904.2168 - val_loss: 69986.7031\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 20880.6992 - val_loss: 69961.8828\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 20875.8398 - val_loss: 69937.6719\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 20867.5938 - val_loss: 69916.8594\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 20862.3770 - val_loss: 69869.3594\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 20849.2949 - val_loss: 69829.8750\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 20834.4746 - val_loss: 69814.9375\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 20814.7773 - val_loss: 69813.9219\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 20792.4043 - val_loss: 69679.1406\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 20760.3418 - val_loss: 69326.8906\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 20703.8652 - val_loss: 68947.6094\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 20629.4258 - val_loss: 68303.0312\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 20488.7676 - val_loss: 67111.1094\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 20245.1621 - val_loss: 65676.8594\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 19905.5859 - val_loss: 64450.5742\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 19466.9844 - val_loss: 62483.1016\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 18916.4199 - val_loss: 59571.0625\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 18195.5723 - val_loss: 55739.3750\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 17230.1035 - val_loss: 51283.7109\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 16037.4141 - val_loss: 45284.4922\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 14442.2656 - val_loss: 37385.4922\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 12359.3926 - val_loss: 30172.6523\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9798.3291 - val_loss: 18342.2168\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5897.3862 - val_loss: 2215.1567\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1674.2028 - val_loss: 207.0503\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 418.7672 - val_loss: 5684.7295\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1096.5822 - val_loss: 11837.9004\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2299.2427 - val_loss: 11859.0020\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2367.0955 - val_loss: 6426.6865\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1425.8683 - val_loss: 3484.4368\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 619.5502 - val_loss: 1143.2775\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 299.0587 - val_loss: 182.5263\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 257.7895 - val_loss: 13.9145\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 359.7879 - val_loss: 235.5574\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 473.4025 - val_loss: 437.7931\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 474.3157 - val_loss: 225.0322\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 360.2139 - val_loss: 40.4301\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 205.6880 - val_loss: 38.7839\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 90.4162 - val_loss: 1043.8567\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 268.7691 - val_loss: 791.7805\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 225.4724 - val_loss: 97.7485\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 88.9669 - val_loss: 6.0414\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 89.3064 - val_loss: 75.6484\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 133.2878 - val_loss: 100.3293\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 149.2896 - val_loss: 58.1097\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 128.8304 - val_loss: 8.1654\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 92.5861 - val_loss: 19.5935\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 67.7903 - val_loss: 131.9090\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 68.0922 - val_loss: 282.6594\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 83.3908 - val_loss: 364.5115\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 92.7300 - val_loss: 329.9363\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 84.6549 - val_loss: 216.9661\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 67.7078 - val_loss: 102.0417\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 56.9546 - val_loss: 30.9035\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 58.2657 - val_loss: 6.3917\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 65.0718 - val_loss: 2.2442\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 67.1143 - val_loss: 3.6460\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 60.8935 - val_loss: 13.6033\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 50.7474 - val_loss: 39.5252\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 45.2023 - val_loss: 78.2831\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 49.4742 - val_loss: 107.2886\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 47.0831 - val_loss: 115.6038\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 46.1945 - val_loss: 101.4385\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 43.9777 - val_loss: 74.5450\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 41.4647 - val_loss: 47.5279\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 40.1707 - val_loss: 28.0921\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 40.1773 - val_loss: 17.7065\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 40.2718 - val_loss: 14.3542\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 39.1834 - val_loss: 16.2081\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 36.7664 - val_loss: 22.8039\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 34.1821 - val_loss: 33.1918\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 32.4218 - val_loss: 43.6442\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 31.6944 - val_loss: 49.1172\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 31.1774 - val_loss: 46.2796\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 29.9758 - val_loss: 36.4418\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 27.9563 - val_loss: 24.6191\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 25.9076 - val_loss: 15.3764\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 24.4197 - val_loss: 10.3054\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 23.2031 - val_loss: 8.9106\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 21.5849 - val_loss: 10.5924\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 19.3884 - val_loss: 15.2151\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 17.0593 - val_loss: 22.0172\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 15.1555 - val_loss: 28.3216\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 13.6943 - val_loss: 30.3448\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 12.1833 - val_loss: 26.7203\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 10.4187 - val_loss: 19.8756\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.6588 - val_loss: 13.2553\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.2201 - val_loss: 8.8032\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.1683 - val_loss: 6.7629\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.2420 - val_loss: 6.6292\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.2546 - val_loss: 7.9918\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.2742 - val_loss: 10.4051\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4608 - val_loss: 12.9773\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1.8828 - val_loss: 14.5101\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.4573 - val_loss: 14.2211\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.0853 - val_loss: 12.2824\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.7722 - val_loss: 9.6467\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5826 - val_loss: 7.2923\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5152 - val_loss: 5.7255\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4888 - val_loss: 4.9839\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4270 - val_loss: 4.8604\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.3399 - val_loss: 5.0220\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2923 - val_loss: 5.0455\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3042 - val_loss: 4.5847\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3222 - val_loss: 3.6084\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2977 - val_loss: 2.4323\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.2530 - val_loss: 1.4539\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2383 - val_loss: 0.8614\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2594 - val_loss: 0.6004\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.2760 - val_loss: 0.5442\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.2682 - val_loss: 0.5963\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2601 - val_loss: 0.6582\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2669 - val_loss: 0.6217\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2598 - val_loss: 0.4710\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.2212 - val_loss: 0.3056\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.1828 - val_loss: 0.2088\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.1661 - val_loss: 0.1821\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1522 - val_loss: 0.2109\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1249 - val_loss: 0.3140\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0925 - val_loss: 0.4984\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0718 - val_loss: 0.7062\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0621 - val_loss: 0.8475\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0525 - val_loss: 0.8805\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0410 - val_loss: 0.8407\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0350 - val_loss: 0.7969\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0364 - val_loss: 0.8015\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0383 - val_loss: 0.8741\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0358 - val_loss: 1.0008\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0328 - val_loss: 1.1353\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0338 - val_loss: 1.2152\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0367 - val_loss: 1.2007\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0362 - val_loss: 1.1034\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0321 - val_loss: 0.9750\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0281 - val_loss: 0.8701\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0260 - val_loss: 0.8182\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0239 - val_loss: 0.8196\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0205 - val_loss: 0.8516\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0178 - val_loss: 0.8764\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0172 - val_loss: 0.8581\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0171 - val_loss: 0.7848\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0158 - val_loss: 0.6764\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0140 - val_loss: 0.5686\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0132 - val_loss: 0.4897\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0132 - val_loss: 0.4491\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0126 - val_loss: 0.4413\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0111 - val_loss: 0.4511\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0098 - val_loss: 0.4594\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0090 - val_loss: 0.4513\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - val_loss: 0.4242\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0066 - val_loss: 0.3883\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0057 - val_loss: 0.3578\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0056 - val_loss: 0.3417\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0055 - val_loss: 0.3412\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0051 - val_loss: 0.3500\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - val_loss: 0.3577\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0050 - val_loss: 0.3552\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - val_loss: 0.3403\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0051 - val_loss: 0.3189\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0050 - val_loss: 0.3002\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - val_loss: 0.2913\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0049 - val_loss: 0.2937\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0045 - val_loss: 0.3038\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - val_loss: 0.3145\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - val_loss: 0.3189\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - val_loss: 0.3143\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - val_loss: 0.3035\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - val_loss: 0.2927\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - val_loss: 0.2874\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - val_loss: 0.2894\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - val_loss: 0.2970\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - val_loss: 0.3060\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.3119\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - val_loss: 0.3131\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - val_loss: 0.3113\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - val_loss: 0.3100\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - val_loss: 0.3124\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0031 - val_loss: 0.3191\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - val_loss: 0.3282\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - val_loss: 0.3362\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - val_loss: 0.3401\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 0.3391\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - val_loss: 0.3355\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0027 - val_loss: 0.3322\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - val_loss: 0.3318\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - val_loss: 0.3348\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0027 - val_loss: 0.3395\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0026 - val_loss: 0.3434\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - val_loss: 0.3447\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - val_loss: 0.3431\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - val_loss: 0.3400\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0025 - val_loss: 0.3376\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - val_loss: 0.3373\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0025 - val_loss: 0.3392\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - val_loss: 0.3420\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - val_loss: 0.3442\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0024 - val_loss: 0.3450\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - val_loss: 0.3447\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - val_loss: 0.3445\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - val_loss: 0.3458\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - val_loss: 0.3489\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0024 - val_loss: 0.3534\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - val_loss: 0.3580\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0024 - val_loss: 0.3615\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 0.3633\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - val_loss: 0.3640\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0023 - val_loss: 0.3646\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0023 - val_loss: 0.3661\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0023 - val_loss: 0.3685\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - val_loss: 0.3713\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0023 - val_loss: 0.3737\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - val_loss: 0.3749\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - val_loss: 0.3751\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0023 - val_loss: 0.3747\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - val_loss: 0.3744\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0023 - val_loss: 0.3747\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0022 - val_loss: 0.3754\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0022 - val_loss: 0.3759\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - val_loss: 0.3757\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - val_loss: 0.3749\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - val_loss: 0.3737\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - val_loss: 0.3727\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - val_loss: 0.3722\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - val_loss: 0.3724\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - val_loss: 0.3729\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - val_loss: 0.3733\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - val_loss: 0.3734\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0022 - val_loss: 0.3730\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 0.3726\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0022 - val_loss: 0.3724\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0021 - val_loss: 0.3727\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - val_loss: 0.3731\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0021 - val_loss: 0.3737\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0021 - val_loss: 0.3742\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - val_loss: 0.3743\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0021 - val_loss: 0.3743\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0021 - val_loss: 0.3744\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0021 - val_loss: 0.3747\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0021 - val_loss: 0.3752\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0021 - val_loss: 0.3757\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0021 - val_loss: 0.3761\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - val_loss: 0.3763\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0021 - val_loss: 0.3763\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0021 - val_loss: 0.3763\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - val_loss: 0.3763\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0020 - val_loss: 0.3766\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0020 - val_loss: 0.3771\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0020 - val_loss: 0.3775\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0020 - val_loss: 0.3778\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - val_loss: 0.3779\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0020 - val_loss: 0.3780\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - val_loss: 0.3782\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - val_loss: 0.3785\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - val_loss: 0.3789\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0020 - val_loss: 0.3793\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - val_loss: 0.3795\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0020 - val_loss: 0.3797\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - val_loss: 0.3799\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0020 - val_loss: 0.3801\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - val_loss: 0.3804\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - val_loss: 0.3807\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0019 - val_loss: 0.3811\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0019 - val_loss: 0.3814\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - val_loss: 0.3815\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - val_loss: 0.3816\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0019 - val_loss: 0.3818\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0019 - val_loss: 0.3820\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0019 - val_loss: 0.3824\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0019 - val_loss: 0.3827\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0019 - val_loss: 0.3829\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0019 - val_loss: 0.3831\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - val_loss: 0.3833\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0019 - val_loss: 0.3835\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0019 - val_loss: 0.3838\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - val_loss: 0.3841\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - val_loss: 0.3844\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0019 - val_loss: 0.3846\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0019 - val_loss: 0.3848\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - val_loss: 0.3850\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - val_loss: 0.3852\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - val_loss: 0.3855\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - val_loss: 0.3858\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - val_loss: 0.3861\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - val_loss: 0.3863\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0018 - val_loss: 0.3864\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - val_loss: 0.3866\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - val_loss: 0.3867\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - val_loss: 0.3868\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - val_loss: 0.3870\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - val_loss: 0.3872\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0018 - val_loss: 0.3874\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - val_loss: 0.3875\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - val_loss: 0.3876\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0018 - val_loss: 0.3877\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - val_loss: 0.3879\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - val_loss: 0.3881\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - val_loss: 0.3882\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.3882\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - val_loss: 0.3883\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.3883\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - val_loss: 0.3884\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - val_loss: 0.3886\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - val_loss: 0.3887\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - val_loss: 0.3888\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.3889\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - val_loss: 0.3890\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.3891\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.3892\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - val_loss: 0.3894\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - val_loss: 0.3895\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.3896\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - val_loss: 0.3897\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - val_loss: 0.3899\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - val_loss: 0.3900\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - val_loss: 0.3902\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - val_loss: 0.3904\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.3906\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - val_loss: 0.3907\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.3908\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - val_loss: 0.3910\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - val_loss: 0.3912\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - val_loss: 0.3913\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - val_loss: 0.3915\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.3917\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - val_loss: 0.3918\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.3919\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - val_loss: 0.3921\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0016 - val_loss: 0.3922\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - val_loss: 0.3924\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - val_loss: 0.3926\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - val_loss: 0.3926\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.3928\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - val_loss: 0.3929\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - val_loss: 0.3930\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.3931\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - val_loss: 0.3933\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - val_loss: 0.3933\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - val_loss: 0.3934\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - val_loss: 0.3935\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - val_loss: 0.3936\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 0.3937\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.3938\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 0.3939\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - val_loss: 0.3940\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0015 - val_loss: 0.3940\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - val_loss: 0.3942\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - val_loss: 0.3943\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - val_loss: 0.3943\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.3943\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.3944\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 0.3945\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.3945\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - val_loss: 0.3945\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 0.3946\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 0.3946\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - val_loss: 0.3946\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - val_loss: 0.3946\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - val_loss: 0.3947\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - val_loss: 0.3947\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - val_loss: 0.3948\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0015 - val_loss: 0.3949\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.3950\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - val_loss: 0.3950\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0015 - val_loss: 0.3950\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 0.3950\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 0.3951\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - val_loss: 0.3952\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - val_loss: 0.3953\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0014 - val_loss: 0.3953\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - val_loss: 0.3954\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - val_loss: 0.3955\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - val_loss: 0.3956\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - val_loss: 0.3957\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 0.3958\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - val_loss: 0.3959\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - val_loss: 0.3960\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0014 - val_loss: 0.3960\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 0.3961\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - val_loss: 0.3962\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - val_loss: 0.3962\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0014 - val_loss: 0.3964\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - val_loss: 0.3964\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - val_loss: 0.3964\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - val_loss: 0.3963\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - val_loss: 0.3964\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - val_loss: 0.3964\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - val_loss: 0.3964\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - val_loss: 0.3963\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - val_loss: 0.3963\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - val_loss: 0.3962\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - val_loss: 0.3962\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - val_loss: 0.3961\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0014 - val_loss: 0.3961\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - val_loss: 0.3960\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - val_loss: 0.3959\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0013 - val_loss: 0.3958\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - val_loss: 0.3957\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0013 - val_loss: 0.3957\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.0013 - val_loss: 0.3956\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0013 - val_loss: 0.3956\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0013 - val_loss: 0.3955\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - val_loss: 0.3954\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 0.3954\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.3953\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - val_loss: 0.3952\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - val_loss: 0.3951\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - val_loss: 0.3951\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - val_loss: 0.3950\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0013 - val_loss: 0.3950\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0013 - val_loss: 0.3949\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0013 - val_loss: 0.3949\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - val_loss: 0.3948\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0013 - val_loss: 0.3947\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.3947\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - val_loss: 0.3946\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - val_loss: 0.3946\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - val_loss: 0.3945\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - val_loss: 0.3944\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - val_loss: 0.3944\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0013 - val_loss: 0.3943\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.0013 - val_loss: 0.3943\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.0013 - val_loss: 0.3942\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0013 - val_loss: 0.3941\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - val_loss: 0.3941\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 0.3940\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - val_loss: 0.3939\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.3939\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0013 - val_loss: 0.3938\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0012 - val_loss: 0.3937\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.3936\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.3936\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0012 - val_loss: 0.3935\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0012 - val_loss: 0.3934\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0012 - val_loss: 0.3933\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0012 - val_loss: 0.3932\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0012 - val_loss: 0.3932\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0012 - val_loss: 0.3932\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0012 - val_loss: 0.3931\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 0.3929\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0012 - val_loss: 0.3928\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0012 - val_loss: 0.3927\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - val_loss: 0.3927\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - val_loss: 0.3926\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0012 - val_loss: 0.3925\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0012 - val_loss: 0.3924\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0012 - val_loss: 0.3922\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0012 - val_loss: 0.3922\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0012 - val_loss: 0.3921\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - val_loss: 0.3920\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0012 - val_loss: 0.3920\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0012 - val_loss: 0.3918\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - val_loss: 0.3917\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0012 - val_loss: 0.3916\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0012 - val_loss: 0.3915\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0012 - val_loss: 0.3915\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - val_loss: 0.3914\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0012 - val_loss: 0.3913\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0012 - val_loss: 0.3912\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0012 - val_loss: 0.3910\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0012 - val_loss: 0.3910\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0012 - val_loss: 0.3909\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - val_loss: 0.3908\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0012 - val_loss: 0.3907\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - val_loss: 0.3905\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0012 - val_loss: 0.3904\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0011 - val_loss: 0.3903\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - val_loss: 0.3903\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - val_loss: 0.3902\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0011 - val_loss: 0.3901\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0011 - val_loss: 0.3899\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - val_loss: 0.3897\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - val_loss: 0.3896\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - val_loss: 0.3896\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - val_loss: 0.3894\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0011 - val_loss: 0.3893\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0011 - val_loss: 0.3891\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - val_loss: 0.3890\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.3889\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - val_loss: 0.3888\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0011 - val_loss: 0.3887\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - val_loss: 0.3886\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0011 - val_loss: 0.3884\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - val_loss: 0.3883\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - val_loss: 0.3882\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.3880\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - val_loss: 0.3880\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - val_loss: 0.3879\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0011 - val_loss: 0.3878\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0011 - val_loss: 0.3876\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - val_loss: 0.3874\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0011 - val_loss: 0.3873\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - val_loss: 0.3872\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - val_loss: 0.3871\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0011 - val_loss: 0.3869\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - val_loss: 0.3867\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - val_loss: 0.3865\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - val_loss: 0.3864\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - val_loss: 0.3863\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - val_loss: 0.3862\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0011 - val_loss: 0.3860\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0011 - val_loss: 0.3858\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - val_loss: 0.3856\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - val_loss: 0.3855\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - val_loss: 0.3854\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0010 - val_loss: 0.3853\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0010 - val_loss: 0.3852\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - val_loss: 0.3850\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0010 - val_loss: 0.3848\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0010 - val_loss: 0.3846\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0010 - val_loss: 0.3845\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0010 - val_loss: 0.3844\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0010 - val_loss: 0.3842\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0010 - val_loss: 0.3840\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0010 - val_loss: 0.3838\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0010 - val_loss: 0.3836\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0010 - val_loss: 0.3835\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0010 - val_loss: 0.3834\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0010 - val_loss: 0.3833\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0010 - val_loss: 0.3831\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0010 - val_loss: 0.3828\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0010 - val_loss: 0.3827\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0010 - val_loss: 0.3825\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0010 - val_loss: 0.3824\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - val_loss: 0.3823\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 9.9993e-04 - val_loss: 0.3821\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 9.9768e-04 - val_loss: 0.3819\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.9523e-04 - val_loss: 0.3817\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.9317e-04 - val_loss: 0.3816\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 9.9065e-04 - val_loss: 0.3814\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.8853e-04 - val_loss: 0.3813\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 9.8612e-04 - val_loss: 0.3811\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 9.8387e-04 - val_loss: 0.3808\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 9.8137e-04 - val_loss: 0.3806\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.7893e-04 - val_loss: 0.3805\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 9.7668e-04 - val_loss: 0.3803\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.7428e-04 - val_loss: 0.3802\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 9.7208e-04 - val_loss: 0.3800\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 9.6983e-04 - val_loss: 0.3797\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.6723e-04 - val_loss: 0.3796\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 9.6500e-04 - val_loss: 0.3794\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 9.6271e-04 - val_loss: 0.3793\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.6053e-04 - val_loss: 0.3791\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 9.5806e-04 - val_loss: 0.3789\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 9.5608e-04 - val_loss: 0.3787\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 9.5362e-04 - val_loss: 0.3785\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.5163e-04 - val_loss: 0.3784\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 9.4925e-04 - val_loss: 0.3782\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 9.4719e-04 - val_loss: 0.3780\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 9.4470e-04 - val_loss: 0.3778\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 9.4260e-04 - val_loss: 0.3776\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.3999e-04 - val_loss: 0.3774\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.3820e-04 - val_loss: 0.3772\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 9.3603e-04 - val_loss: 0.3770\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.3360e-04 - val_loss: 0.3768\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 9.3124e-04 - val_loss: 0.3766\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 9.2926e-04 - val_loss: 0.3764\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 9.2668e-04 - val_loss: 0.3762\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 9.2442e-04 - val_loss: 0.3761\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.2244e-04 - val_loss: 0.3759\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.2021e-04 - val_loss: 0.3757\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.1759e-04 - val_loss: 0.3755\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 9.1524e-04 - val_loss: 0.3753\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9.1319e-04 - val_loss: 0.3751\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 9.1087e-04 - val_loss: 0.3748\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 9.0862e-04 - val_loss: 0.3747\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 9.0616e-04 - val_loss: 0.3744\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.0402e-04 - val_loss: 0.3742\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 9.0167e-04 - val_loss: 0.3740\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.9968e-04 - val_loss: 0.3738\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.9719e-04 - val_loss: 0.3736\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.9477e-04 - val_loss: 0.3735\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 8.9264e-04 - val_loss: 0.3732\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 8.9046e-04 - val_loss: 0.3730\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 8.8813e-04 - val_loss: 0.3728\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 8.8584e-04 - val_loss: 0.3726\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.8352e-04 - val_loss: 0.3724\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 8.8141e-04 - val_loss: 0.3722\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 8.7890e-04 - val_loss: 0.3720\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.7682e-04 - val_loss: 0.3718\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 8.7483e-04 - val_loss: 0.3716\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.7251e-04 - val_loss: 0.3714\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.7030e-04 - val_loss: 0.3712\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 8.6775e-04 - val_loss: 0.3710\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.6570e-04 - val_loss: 0.3708\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.6368e-04 - val_loss: 0.3705\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 8.6111e-04 - val_loss: 0.3703\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.5882e-04 - val_loss: 0.3701\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 8.5677e-04 - val_loss: 0.3700\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.5465e-04 - val_loss: 0.3698\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.5260e-04 - val_loss: 0.3695\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 8.5001e-04 - val_loss: 0.3693\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.4788e-04 - val_loss: 0.3690\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 8.4558e-04 - val_loss: 0.3688\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.4343e-04 - val_loss: 0.3686\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.4155e-04 - val_loss: 0.3684\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 8.3906e-04 - val_loss: 0.3682\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.3694e-04 - val_loss: 0.3680\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.3477e-04 - val_loss: 0.3677\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 8.3288e-04 - val_loss: 0.3675\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.3072e-04 - val_loss: 0.3673\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.2843e-04 - val_loss: 0.3671\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 8.2597e-04 - val_loss: 0.3669\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.2382e-04 - val_loss: 0.3667\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.2194e-04 - val_loss: 0.3664\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.1998e-04 - val_loss: 0.3662\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 8.1760e-04 - val_loss: 0.3660\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.1530e-04 - val_loss: 0.3658\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.1357e-04 - val_loss: 0.3656\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 8.1130e-04 - val_loss: 0.3653\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 8.0905e-04 - val_loss: 0.3650\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 8.0695e-04 - val_loss: 0.3648\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 8.0466e-04 - val_loss: 0.3646\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 8.0295e-04 - val_loss: 0.3644\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 8.0085e-04 - val_loss: 0.3642\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.9850e-04 - val_loss: 0.3639\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 7.9634e-04 - val_loss: 0.3637\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 7.9456e-04 - val_loss: 0.3635\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 7.9235e-04 - val_loss: 0.3633\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 7.9010e-04 - val_loss: 0.3630\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 7.8812e-04 - val_loss: 0.3628\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7.8576e-04 - val_loss: 0.3625\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 7.8380e-04 - val_loss: 0.3623\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 7.8169e-04 - val_loss: 0.3621\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.7962e-04 - val_loss: 0.3618\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 7.7760e-04 - val_loss: 0.3616\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 7.7568e-04 - val_loss: 0.3614\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 7.7336e-04 - val_loss: 0.3612\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 7.7127e-04 - val_loss: 0.3609\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 7.6930e-04 - val_loss: 0.3607\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 7.6699e-04 - val_loss: 0.3605\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.6519e-04 - val_loss: 0.3602\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 7.6327e-04 - val_loss: 0.3599\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 7.6097e-04 - val_loss: 0.3597\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 7.5934e-04 - val_loss: 0.3595\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 7.5750e-04 - val_loss: 0.3592\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 7.5511e-04 - val_loss: 0.3590\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 7.5307e-04 - val_loss: 0.3587\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 7.5129e-04 - val_loss: 0.3585\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 7.4910e-04 - val_loss: 0.3582\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.4700e-04 - val_loss: 0.3580\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 7.4467e-04 - val_loss: 0.3578\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 7.4290e-04 - val_loss: 0.3575\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 7.4100e-04 - val_loss: 0.3572\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 7.3906e-04 - val_loss: 0.3570\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 7.3707e-04 - val_loss: 0.3568\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 7.3512e-04 - val_loss: 0.3566\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 7.3288e-04 - val_loss: 0.3563\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 7.3092e-04 - val_loss: 0.3560\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 7.2893e-04 - val_loss: 0.3558\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 7.2726e-04 - val_loss: 0.3555\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 7.2498e-04 - val_loss: 0.3554\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 7.2323e-04 - val_loss: 0.3551\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 7.2098e-04 - val_loss: 0.3548\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 7.1938e-04 - val_loss: 0.3545\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 7.1755e-04 - val_loss: 0.3543\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 7.1544e-04 - val_loss: 0.3541\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 7.1333e-04 - val_loss: 0.3539\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 7.1169e-04 - val_loss: 0.3536\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 7.0945e-04 - val_loss: 0.3533\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 7.0777e-04 - val_loss: 0.3531\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 7.0557e-04 - val_loss: 0.3528\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 7.0371e-04 - val_loss: 0.3526\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 7.0192e-04 - val_loss: 0.3523\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.9991e-04 - val_loss: 0.3521\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.9815e-04 - val_loss: 0.3518\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.9576e-04 - val_loss: 0.3516\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.9417e-04 - val_loss: 0.3513\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 6.9191e-04 - val_loss: 0.3510\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.9043e-04 - val_loss: 0.3508\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.8874e-04 - val_loss: 0.3506\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6.8659e-04 - val_loss: 0.3503\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.8456e-04 - val_loss: 0.3500\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.8274e-04 - val_loss: 0.3498\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.8079e-04 - val_loss: 0.3496\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.7924e-04 - val_loss: 0.3493\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.7712e-04 - val_loss: 0.3490\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.7513e-04 - val_loss: 0.3488\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.7316e-04 - val_loss: 0.3485\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6.7127e-04 - val_loss: 0.3483\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.6935e-04 - val_loss: 0.3480\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.6758e-04 - val_loss: 0.3477\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 6.6611e-04 - val_loss: 0.3474\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 6.6413e-04 - val_loss: 0.3472\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.6232e-04 - val_loss: 0.3470\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.6015e-04 - val_loss: 0.3468\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.5834e-04 - val_loss: 0.3465\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 6.5677e-04 - val_loss: 0.3462\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.5485e-04 - val_loss: 0.3459\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.5285e-04 - val_loss: 0.3457\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.5122e-04 - val_loss: 0.3455\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.4908e-04 - val_loss: 0.3451\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.4740e-04 - val_loss: 0.3448\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.4581e-04 - val_loss: 0.3446\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.4397e-04 - val_loss: 0.3444\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.4221e-04 - val_loss: 0.3441\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.4038e-04 - val_loss: 0.3438\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 6.3845e-04 - val_loss: 0.3435\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 6.3693e-04 - val_loss: 0.3433\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6.3511e-04 - val_loss: 0.3431\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.3324e-04 - val_loss: 0.3428\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.3145e-04 - val_loss: 0.3425\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.2976e-04 - val_loss: 0.3422\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.2820e-04 - val_loss: 0.3420\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.2621e-04 - val_loss: 0.3418\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.2419e-04 - val_loss: 0.3415\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.2277e-04 - val_loss: 0.3413\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 6.2086e-04 - val_loss: 0.3410\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.1904e-04 - val_loss: 0.3407\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.1733e-04 - val_loss: 0.3404\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6.1550e-04 - val_loss: 0.3402\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.1394e-04 - val_loss: 0.3399\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 6.1231e-04 - val_loss: 0.3397\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.1043e-04 - val_loss: 0.3394\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.0854e-04 - val_loss: 0.3391\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6.0693e-04 - val_loss: 0.3389\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 6.0510e-04 - val_loss: 0.3386\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.0342e-04 - val_loss: 0.3383\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.0163e-04 - val_loss: 0.3381\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6.0001e-04 - val_loss: 0.3378\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.9798e-04 - val_loss: 0.3375\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.9655e-04 - val_loss: 0.3373\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.9494e-04 - val_loss: 0.3370\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.9330e-04 - val_loss: 0.3367\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.9159e-04 - val_loss: 0.3365\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 5.8976e-04 - val_loss: 0.3362\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.8814e-04 - val_loss: 0.3360\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 5.8627e-04 - val_loss: 0.3357\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.8460e-04 - val_loss: 0.3354\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.8320e-04 - val_loss: 0.3352\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.8150e-04 - val_loss: 0.3349\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.7988e-04 - val_loss: 0.3346\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.7828e-04 - val_loss: 0.3343\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.7633e-04 - val_loss: 0.3341\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5.7477e-04 - val_loss: 0.3338\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.7284e-04 - val_loss: 0.3336\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.7143e-04 - val_loss: 0.3333\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.6982e-04 - val_loss: 0.3330\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.6793e-04 - val_loss: 0.3327\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.6631e-04 - val_loss: 0.3325\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.6484e-04 - val_loss: 0.3323\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.6312e-04 - val_loss: 0.3320\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 5.6140e-04 - val_loss: 0.3318\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.5992e-04 - val_loss: 0.3315\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.5805e-04 - val_loss: 0.3312\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.5651e-04 - val_loss: 0.3309\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.5480e-04 - val_loss: 0.3307\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.5314e-04 - val_loss: 0.3305\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.5168e-04 - val_loss: 0.3302\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.5020e-04 - val_loss: 0.3299\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.4880e-04 - val_loss: 0.3296\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4691e-04 - val_loss: 0.3294\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.4530e-04 - val_loss: 0.3291\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.4347e-04 - val_loss: 0.3288\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 5.4219e-04 - val_loss: 0.3285\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.4044e-04 - val_loss: 0.3283\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5.3888e-04 - val_loss: 0.3280\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 5.3720e-04 - val_loss: 0.3277\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3549e-04 - val_loss: 0.3274\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.3388e-04 - val_loss: 0.3272\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.3256e-04 - val_loss: 0.3269\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.3123e-04 - val_loss: 0.3266\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.2913e-04 - val_loss: 0.3264\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.2789e-04 - val_loss: 0.3261\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.2644e-04 - val_loss: 0.3259\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.2462e-04 - val_loss: 0.3257\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.2310e-04 - val_loss: 0.3254\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5.2141e-04 - val_loss: 0.3251\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5.1992e-04 - val_loss: 0.3248\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.1842e-04 - val_loss: 0.3246\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.1690e-04 - val_loss: 0.3243\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 5.1523e-04 - val_loss: 0.3240\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.1390e-04 - val_loss: 0.3238\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.1239e-04 - val_loss: 0.3235\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.1060e-04 - val_loss: 0.3232\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.0953e-04 - val_loss: 0.3229\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.0792e-04 - val_loss: 0.3227\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 5.0604e-04 - val_loss: 0.3224\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.0457e-04 - val_loss: 0.3221\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.0299e-04 - val_loss: 0.3219\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.0175e-04 - val_loss: 0.3216\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.0022e-04 - val_loss: 0.3214\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4.9857e-04 - val_loss: 0.3211\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4.9739e-04 - val_loss: 0.3208\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 4.9563e-04 - val_loss: 0.3205\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 4.9424e-04 - val_loss: 0.3203\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4.9270e-04 - val_loss: 0.3201\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.9116e-04 - val_loss: 0.3198\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 4.8964e-04 - val_loss: 0.3195\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 4.8804e-04 - val_loss: 0.3192\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 4.8678e-04 - val_loss: 0.3190\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4.8513e-04 - val_loss: 0.3187\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 4.8366e-04 - val_loss: 0.3185\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4.8237e-04 - val_loss: 0.3182\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 4.8074e-04 - val_loss: 0.3179\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 4.7930e-04 - val_loss: 0.3176\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4.7795e-04 - val_loss: 0.3174\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4.7656e-04 - val_loss: 0.3171\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 4.7535e-04 - val_loss: 0.3168\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 4.7360e-04 - val_loss: 0.3166\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4.7209e-04 - val_loss: 0.3163\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 4.7059e-04 - val_loss: 0.3160\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 4.6914e-04 - val_loss: 0.3158\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.6788e-04 - val_loss: 0.3155\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 4.6633e-04 - val_loss: 0.3152\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4.6494e-04 - val_loss: 0.3150\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4.6369e-04 - val_loss: 0.3148\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 4.6219e-04 - val_loss: 0.3145\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 4.6067e-04 - val_loss: 0.3142\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 4.5914e-04 - val_loss: 0.3139\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 4.5791e-04 - val_loss: 0.3136\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 4.5641e-04 - val_loss: 0.3134\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 4.5479e-04 - val_loss: 0.3131\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 4.5365e-04 - val_loss: 0.3128\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 4.5224e-04 - val_loss: 0.3125\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 4.5096e-04 - val_loss: 0.3123\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 4.4932e-04 - val_loss: 0.3120\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.4811e-04 - val_loss: 0.3118\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 4.4664e-04 - val_loss: 0.3115\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.4526e-04 - val_loss: 0.3112\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 4.4396e-04 - val_loss: 0.3109\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 4.4292e-04 - val_loss: 0.3107\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 4.4131e-04 - val_loss: 0.3105\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 4.3974e-04 - val_loss: 0.3102\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 4.3851e-04 - val_loss: 0.3100\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 4.3679e-04 - val_loss: 0.3097\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 4.3591e-04 - val_loss: 0.3094\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 4.3458e-04 - val_loss: 0.3092\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 4.3303e-04 - val_loss: 0.3089\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 4.3173e-04 - val_loss: 0.3086\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 4.3037e-04 - val_loss: 0.3083\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 4.2917e-04 - val_loss: 0.3081\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 4.2774e-04 - val_loss: 0.3078\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 4.2659e-04 - val_loss: 0.3076\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 4.2501e-04 - val_loss: 0.3073\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4.2360e-04 - val_loss: 0.3070\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 4.2214e-04 - val_loss: 0.3067\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 4.2090e-04 - val_loss: 0.3065\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 4.1979e-04 - val_loss: 0.3062\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4.1815e-04 - val_loss: 0.3059\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 4.1706e-04 - val_loss: 0.3056\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.1556e-04 - val_loss: 0.3054\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4.1412e-04 - val_loss: 0.3052\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.1326e-04 - val_loss: 0.3050\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4.1173e-04 - val_loss: 0.3047\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 4.1064e-04 - val_loss: 0.3044\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4.0910e-04 - val_loss: 0.3041\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.0794e-04 - val_loss: 0.3039\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4.0671e-04 - val_loss: 0.3036\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 4.0524e-04 - val_loss: 0.3034\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.0412e-04 - val_loss: 0.3031\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.0269e-04 - val_loss: 0.3028\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.0129e-04 - val_loss: 0.3026\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.0003e-04 - val_loss: 0.3023\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 3.9890e-04 - val_loss: 0.3021\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3.9766e-04 - val_loss: 0.3018\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3.9636e-04 - val_loss: 0.3015\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3.9535e-04 - val_loss: 0.3012\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.9381e-04 - val_loss: 0.3010\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3.9249e-04 - val_loss: 0.3007\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.9147e-04 - val_loss: 0.3004\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 3.9020e-04 - val_loss: 0.3002\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.8898e-04 - val_loss: 0.2999\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3.8774e-04 - val_loss: 0.2997\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3.8644e-04 - val_loss: 0.2994\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3.8525e-04 - val_loss: 0.2991\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.8407e-04 - val_loss: 0.2989\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3.8293e-04 - val_loss: 0.2986\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 3.8161e-04 - val_loss: 0.2984\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 3.8038e-04 - val_loss: 0.2981\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.7918e-04 - val_loss: 0.2978\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3.7782e-04 - val_loss: 0.2976\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.7661e-04 - val_loss: 0.2973\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.7533e-04 - val_loss: 0.2971\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.7422e-04 - val_loss: 0.2968\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.7319e-04 - val_loss: 0.2965\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 3.7182e-04 - val_loss: 0.2963\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.7090e-04 - val_loss: 0.2960\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.6953e-04 - val_loss: 0.2958\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.6845e-04 - val_loss: 0.2955\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.6710e-04 - val_loss: 0.2952\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.6597e-04 - val_loss: 0.2949\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3.6457e-04 - val_loss: 0.2947\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 3.6348e-04 - val_loss: 0.2945\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.6234e-04 - val_loss: 0.2942\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 3.6128e-04 - val_loss: 0.2939\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 3.5989e-04 - val_loss: 0.2937\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.5889e-04 - val_loss: 0.2934\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.5757e-04 - val_loss: 0.2932\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.5648e-04 - val_loss: 0.2929\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.5519e-04 - val_loss: 0.2926\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3.5420e-04 - val_loss: 0.2924\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3.5296e-04 - val_loss: 0.2921\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3.5209e-04 - val_loss: 0.2919\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.5092e-04 - val_loss: 0.2916\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.4957e-04 - val_loss: 0.2914\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 3.4827e-04 - val_loss: 0.2911\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.4746e-04 - val_loss: 0.2908\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.4615e-04 - val_loss: 0.2906\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.4515e-04 - val_loss: 0.2903\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 3.4415e-04 - val_loss: 0.2900\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3.4290e-04 - val_loss: 0.2898\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.4189e-04 - val_loss: 0.2896\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 3.4074e-04 - val_loss: 0.2893\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.3978e-04 - val_loss: 0.2890\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.3854e-04 - val_loss: 0.2888\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.3737e-04 - val_loss: 0.2885\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.3598e-04 - val_loss: 0.2883\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.3515e-04 - val_loss: 0.2881\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.3384e-04 - val_loss: 0.2878\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 3.3314e-04 - val_loss: 0.2875\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3.3187e-04 - val_loss: 0.2873\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3.3072e-04 - val_loss: 0.2870\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3.2969e-04 - val_loss: 0.2868\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.2837e-04 - val_loss: 0.2865\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.2771e-04 - val_loss: 0.2862\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.2645e-04 - val_loss: 0.2860\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.2528e-04 - val_loss: 0.2858\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.2437e-04 - val_loss: 0.2855\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3.2329e-04 - val_loss: 0.2852\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 3.2229e-04 - val_loss: 0.2850\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.2118e-04 - val_loss: 0.2847\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.2019e-04 - val_loss: 0.2845\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.1906e-04 - val_loss: 0.2842\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 3.1797e-04 - val_loss: 0.2840\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.1704e-04 - val_loss: 0.2837\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3.1586e-04 - val_loss: 0.2835\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.1503e-04 - val_loss: 0.2832\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.1400e-04 - val_loss: 0.2829\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.1278e-04 - val_loss: 0.2827\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.1197e-04 - val_loss: 0.2825\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3.1057e-04 - val_loss: 0.2822\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.0962e-04 - val_loss: 0.2819\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3.0851e-04 - val_loss: 0.2816\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.0785e-04 - val_loss: 0.2814\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 3.0674e-04 - val_loss: 0.2812\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.0583e-04 - val_loss: 0.2809\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.0460e-04 - val_loss: 0.2807\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 3.0374e-04 - val_loss: 0.2804\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.0275e-04 - val_loss: 0.2802\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3.0174e-04 - val_loss: 0.2799\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.0078e-04 - val_loss: 0.2796\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.9983e-04 - val_loss: 0.2794\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.9867e-04 - val_loss: 0.2791\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.9780e-04 - val_loss: 0.2789\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.9679e-04 - val_loss: 0.2787\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.9585e-04 - val_loss: 0.2784\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2.9501e-04 - val_loss: 0.2781\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.9378e-04 - val_loss: 0.2779\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.9291e-04 - val_loss: 0.2777\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.9207e-04 - val_loss: 0.2774\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.9094e-04 - val_loss: 0.2771\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.9017e-04 - val_loss: 0.2769\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.8911e-04 - val_loss: 0.2766\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.8808e-04 - val_loss: 0.2764\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2.8708e-04 - val_loss: 0.2761\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.8631e-04 - val_loss: 0.2759\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.8548e-04 - val_loss: 0.2757\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.8460e-04 - val_loss: 0.2754\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.8351e-04 - val_loss: 0.2751\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.8248e-04 - val_loss: 0.2749\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.8181e-04 - val_loss: 0.2747\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.8086e-04 - val_loss: 0.2744\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.8004e-04 - val_loss: 0.2742\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.7902e-04 - val_loss: 0.2739\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.7822e-04 - val_loss: 0.2737\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.7722e-04 - val_loss: 0.2734\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.7634e-04 - val_loss: 0.2732\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.7547e-04 - val_loss: 0.2730\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.7449e-04 - val_loss: 0.2727\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.7345e-04 - val_loss: 0.2724\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.7270e-04 - val_loss: 0.2722\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.7174e-04 - val_loss: 0.2720\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.7093e-04 - val_loss: 0.2718\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.6992e-04 - val_loss: 0.2715\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.6906e-04 - val_loss: 0.2712\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.6815e-04 - val_loss: 0.2710\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.6756e-04 - val_loss: 0.2708\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.6654e-04 - val_loss: 0.2706\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 2.6550e-04 - val_loss: 0.2703\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.6491e-04 - val_loss: 0.2700\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.6384e-04 - val_loss: 0.2698\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.6309e-04 - val_loss: 0.2696\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.6220e-04 - val_loss: 0.2693\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.6131e-04 - val_loss: 0.2691\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.6033e-04 - val_loss: 0.2688\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.5952e-04 - val_loss: 0.2686\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.5888e-04 - val_loss: 0.2684\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 2.5793e-04 - val_loss: 0.2681\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 2.5711e-04 - val_loss: 0.2679\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.5616e-04 - val_loss: 0.2677\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.5544e-04 - val_loss: 0.2674\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.5452e-04 - val_loss: 0.2672\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.5387e-04 - val_loss: 0.2669\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.5279e-04 - val_loss: 0.2667\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.5214e-04 - val_loss: 0.2665\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.5121e-04 - val_loss: 0.2662\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 2.5036e-04 - val_loss: 0.2659\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.4962e-04 - val_loss: 0.2657\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.4886e-04 - val_loss: 0.2655\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.4798e-04 - val_loss: 0.2653\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.4718e-04 - val_loss: 0.2650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions1 = model1.predict(X_test).flatten()\n",
        "print(X_test)\n",
        "print(test_predictions1)\n",
        "test_results1 = pd.DataFrame(data={'Test Predictions':test_predictions1, 'Actuals':y_test})\n",
        "test_results1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "pz1804itVZIc",
        "outputId": "aa76c7b8-ccea-45c6-e8e0-4c441d988fee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 852ms/step\n",
            "[[[264]\n",
            "  [276]\n",
            "  [288]]\n",
            "\n",
            " [[276]\n",
            "  [288]\n",
            "  [300]]\n",
            "\n",
            " [[288]\n",
            "  [300]\n",
            "  [312]]\n",
            "\n",
            " [[300]\n",
            "  [312]\n",
            "  [324]]\n",
            "\n",
            " [[312]\n",
            "  [324]\n",
            "  [336]]\n",
            "\n",
            " [[324]\n",
            "  [336]\n",
            "  [348]]]\n",
            "[301.1811  313.5309  325.91922 338.34442 350.80453 363.29807]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Test Predictions  Actuals\n",
              "0        301.181091      300\n",
              "1        313.530914      312\n",
              "2        325.919220      324\n",
              "3        338.344421      336\n",
              "4        350.804535      348\n",
              "5        363.298065      360"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-095088e8-4d5c-4e85-9179-c0380d57cd0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Predictions</th>\n",
              "      <th>Actuals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>301.181091</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>313.530914</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>325.919220</td>\n",
              "      <td>324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>338.344421</td>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>350.804535</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>363.298065</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-095088e8-4d5c-4e85-9179-c0380d57cd0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-095088e8-4d5c-4e85-9179-c0380d57cd0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-095088e8-4d5c-4e85-9179-c0380d57cd0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-95cfbff9-f687-4af7-af92-e0989bf04bba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95cfbff9-f687-4af7-af92-e0989bf04bba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-95cfbff9-f687-4af7-af92-e0989bf04bba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6018eabd-f640-4536-b658-20109d36b55c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_results1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6018eabd-f640-4536-b658-20109d36b55c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_results1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_results1",
              "summary": "{\n  \"name\": \"test_results1\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Test Predictions\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          301.18109130859375,\n          313.5309143066406,\n          363.2980651855469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actuals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 300,\n        \"max\": 360,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          300,\n          312,\n          360\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_results1['Test Predictions'],color='blue',marker='o')\n",
        "plt.plot(test_results1['Actuals'],color='red',marker='s')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "fGQUr6_UVkiV",
        "outputId": "6f1d72b6-e9c0-40d1-981b-e9f6dfc4197c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7a1590727310>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6jwesbNBVunf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(3, 1)))\n",
        "model2.add(Dense(1))\n",
        "model2.compile(optimizer='adam', loss='mse')\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb543ffc-da00-4b4b-9cc4-eb7256060588",
        "id": "9gF2wJ14V59B"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirection  (None, 100)               20800     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20901 (81.64 KB)\n",
            "Trainable params: 20901 (81.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8bcb96a-e8b1-4b77-ea0f-9ab7742e62ad",
        "id": "ETI2FyYgV59I"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 23627.5352 - val_loss: 79708.9531\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 23062.4863 - val_loss: 77266.8828\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 22476.3535 - val_loss: 74719.6406\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 21874.0039 - val_loss: 72155.3906\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 21256.4219 - val_loss: 69578.8750\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 20621.6211 - val_loss: 66907.6875\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 19972.2051 - val_loss: 64165.6055\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 19326.6133 - val_loss: 61638.8359\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 18716.5547 - val_loss: 59535.6953\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 18163.8945 - val_loss: 57810.5391\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 17667.3125 - val_loss: 56288.2109\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 17210.9375 - val_loss: 54841.3984\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 16777.7129 - val_loss: 53425.4141\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 16354.8213 - val_loss: 52014.5859\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 15932.4600 - val_loss: 50567.2500\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 15501.6309 - val_loss: 49028.2656\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 15053.4346 - val_loss: 47333.1172\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 14579.5332 - val_loss: 45428.2578\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 14075.6045 - val_loss: 43244.5195\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 13538.1768 - val_loss: 40762.7070\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 12961.0469 - val_loss: 38118.6328\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 12351.7236 - val_loss: 35586.3125\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11728.5732 - val_loss: 33355.7891\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11109.7109 - val_loss: 31386.2910\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 10503.9170 - val_loss: 29515.6992\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 9908.5713 - val_loss: 27534.6250\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 9311.4443 - val_loss: 25350.2383\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8699.5850 - val_loss: 23327.7637\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8080.9414 - val_loss: 21423.1270\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7468.6436 - val_loss: 19387.1660\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6851.6582 - val_loss: 17347.5723\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6224.5039 - val_loss: 15436.6660\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5597.5117 - val_loss: 13574.6514\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4976.9058 - val_loss: 11786.2285\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 4361.5898 - val_loss: 9974.7197\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3741.6189 - val_loss: 7892.5820\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3100.3081 - val_loss: 5733.5903\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2441.8093 - val_loss: 3935.3481\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1814.4540 - val_loss: 2485.6484\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1265.4598 - val_loss: 1263.9703\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 809.0623 - val_loss: 401.6773\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 459.7052 - val_loss: 27.8049\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 233.3725 - val_loss: 71.0906\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 131.3159 - val_loss: 440.0507\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 138.9614 - val_loss: 993.6242\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 228.6741 - val_loss: 1493.5117\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 334.1534 - val_loss: 1798.9470\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 399.6005 - val_loss: 1916.8092\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 414.7859 - val_loss: 1890.3105\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 392.0208 - val_loss: 1755.4988\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 346.4890 - val_loss: 1545.0323\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 290.2799 - val_loss: 1295.7343\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 232.1638 - val_loss: 1045.9126\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 178.4133 - val_loss: 823.6471\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 132.9571 - val_loss: 639.5014\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 97.3099 - val_loss: 491.2991\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 71.0264 - val_loss: 372.8220\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 52.5989 - val_loss: 278.4758\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 40.2604 - val_loss: 204.1260\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 32.4306 - val_loss: 146.5896\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 27.8069 - val_loss: 103.1365\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 25.3861 - val_loss: 71.2420\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 24.4343 - val_loss: 48.5552\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 24.4623 - val_loss: 32.9546\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 25.1435 - val_loss: 22.6386\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 26.0231 - val_loss: 16.2064\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26.4178 - val_loss: 13.6363\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25.7334 - val_loss: 14.8232\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 23.9794 - val_loss: 21.6395\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 21.9995 - val_loss: 36.3315\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 20.6160 - val_loss: 46.9873\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 18.7679 - val_loss: 44.8148\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 15.8758 - val_loss: 34.6209\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13.0341 - val_loss: 23.5216\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 11.1361 - val_loss: 15.4772\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 10.1833 - val_loss: 11.0175\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 9.5540 - val_loss: 9.2280\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.7083 - val_loss: 9.3509\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.6868 - val_loss: 11.6240\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.9526 - val_loss: 14.4838\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.8851 - val_loss: 15.2931\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.0285 - val_loss: 12.4453\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.5215 - val_loss: 8.1364\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.6900 - val_loss: 4.9299\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.2573 - val_loss: 3.3284\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.1635 - val_loss: 2.8603\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.9423 - val_loss: 3.1838\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.4536 - val_loss: 4.2442\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.9720 - val_loss: 5.8304\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.7860 - val_loss: 6.9374\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.7677 - val_loss: 6.5149\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.5600 - val_loss: 4.9672\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.2091 - val_loss: 3.4282\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9972 - val_loss: 2.4850\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.9627 - val_loss: 2.1441\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9127 - val_loss: 2.2865\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7332 - val_loss: 2.8908\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.5126 - val_loss: 3.8894\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3871 - val_loss: 4.8611\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3367 - val_loss: 5.1329\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2147 - val_loss: 4.5650\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.0099 - val_loss: 3.7105\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8530 - val_loss: 3.1296\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.7810 - val_loss: 3.0590\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.7045 - val_loss: 3.5728\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5767 - val_loss: 4.6664\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.4593 - val_loss: 6.0010\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4087 - val_loss: 6.7606\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.3718 - val_loss: 6.4109\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2880 - val_loss: 5.3598\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.1995 - val_loss: 4.3550\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1.1506 - val_loss: 3.8310\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.1093 - val_loss: 3.8518\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.0373 - val_loss: 4.2788\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.9583 - val_loss: 4.7823\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.9078 - val_loss: 4.9055\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8694 - val_loss: 4.4360\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8136 - val_loss: 3.6315\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.7556 - val_loss: 2.9123\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7188 - val_loss: 2.5103\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6904 - val_loss: 2.4488\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6517 - val_loss: 2.6336\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6107 - val_loss: 2.8861\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5827 - val_loss: 2.9808\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5588 - val_loss: 2.8059\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5257 - val_loss: 2.4671\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4915 - val_loss: 2.1667\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4669 - val_loss: 2.0392\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4450 - val_loss: 2.1146\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4180 - val_loss: 2.3379\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3922 - val_loss: 2.5752\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3739 - val_loss: 2.6680\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3569 - val_loss: 2.5590\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.3364 - val_loss: 2.3416\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3176 - val_loss: 2.1625\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3033 - val_loss: 2.1135\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2885 - val_loss: 2.2001\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2713 - val_loss: 2.3524\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2561 - val_loss: 2.4550\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2437 - val_loss: 2.4226\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2303 - val_loss: 2.2744\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2163 - val_loss: 2.1168\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2046 - val_loss: 2.0277\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1947 - val_loss: 2.0498\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.1840 - val_loss: 2.1550\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.1736 - val_loss: 2.2700\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.1651 - val_loss: 2.3214\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.1571 - val_loss: 2.2952\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.1485 - val_loss: 2.2264\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.1405 - val_loss: 2.1846\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.1337 - val_loss: 2.2190\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.1268 - val_loss: 2.3247\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1198 - val_loss: 2.4551\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1136 - val_loss: 2.5484\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1082 - val_loss: 2.5724\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.1026 - val_loss: 2.5472\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0973 - val_loss: 2.5231\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0928 - val_loss: 2.5448\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0886 - val_loss: 2.6193\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0842 - val_loss: 2.7147\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0806 - val_loss: 2.7803\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0776 - val_loss: 2.7818\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0746 - val_loss: 2.7290\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0716 - val_loss: 2.6658\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0690 - val_loss: 2.6341\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0667 - val_loss: 2.6461\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0642 - val_loss: 2.6799\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0620 - val_loss: 2.6980\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0601 - val_loss: 2.6758\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0581 - val_loss: 2.6206\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0562 - val_loss: 2.5631\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0545 - val_loss: 2.5326\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0529 - val_loss: 2.5359\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0512 - val_loss: 2.5558\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0496 - val_loss: 2.5644\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0482 - val_loss: 2.5449\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0468 - val_loss: 2.5029\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0454 - val_loss: 2.4604\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0441 - val_loss: 2.4366\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0432 - val_loss: 2.4313\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0422 - val_loss: 2.4330\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0414 - val_loss: 2.4276\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0406 - val_loss: 2.4088\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0398 - val_loss: 2.3825\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0390 - val_loss: 2.3601\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0382 - val_loss: 2.3496\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0375 - val_loss: 2.3494\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0368 - val_loss: 2.3506\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0361 - val_loss: 2.3445\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0355 - val_loss: 2.3299\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0348 - val_loss: 2.3133\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0342 - val_loss: 2.3032\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0336 - val_loss: 2.3032\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0331 - val_loss: 2.3097\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0325 - val_loss: 2.3154\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0320 - val_loss: 2.3151\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0315 - val_loss: 2.3103\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0310 - val_loss: 2.3068\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0305 - val_loss: 2.3094\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0300 - val_loss: 2.3183\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0296 - val_loss: 2.3285\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0291 - val_loss: 2.3346\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0288 - val_loss: 2.3345\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0284 - val_loss: 2.3274\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0280 - val_loss: 2.3149\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0276 - val_loss: 2.2999\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0272 - val_loss: 2.2834\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0268 - val_loss: 2.2686\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0265 - val_loss: 2.2577\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0261 - val_loss: 2.2507\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0258 - val_loss: 2.2449\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0255 - val_loss: 2.2378\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0251 - val_loss: 2.2292\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0248 - val_loss: 2.2208\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0245 - val_loss: 2.2150\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0242 - val_loss: 2.2123\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0239 - val_loss: 2.2111\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0236 - val_loss: 2.2090\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0233 - val_loss: 2.2054\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0230 - val_loss: 2.2012\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0227 - val_loss: 2.1983\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0224 - val_loss: 2.1974\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0222 - val_loss: 2.1975\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0219 - val_loss: 2.1967\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0216 - val_loss: 2.1944\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0214 - val_loss: 2.1912\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0212 - val_loss: 2.1842\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0209 - val_loss: 2.1705\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0207 - val_loss: 2.1544\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0204 - val_loss: 2.1426\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0202 - val_loss: 2.1381\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0200 - val_loss: 2.1373\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0197 - val_loss: 2.1340\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0195 - val_loss: 2.1256\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0193 - val_loss: 2.1148\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0191 - val_loss: 2.1068\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0189 - val_loss: 2.1041\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0186 - val_loss: 2.1039\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0184 - val_loss: 2.1017\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0182 - val_loss: 2.0951\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0180 - val_loss: 2.0867\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0178 - val_loss: 2.0803\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0176 - val_loss: 2.0775\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0174 - val_loss: 2.0762\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0172 - val_loss: 2.0729\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0170 - val_loss: 2.0664\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0169 - val_loss: 2.0586\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0166 - val_loss: 2.0484\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0165 - val_loss: 2.0329\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0163 - val_loss: 2.0155\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0161 - val_loss: 2.0024\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0159 - val_loss: 1.9951\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0157 - val_loss: 1.9901\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0156 - val_loss: 1.9825\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0154 - val_loss: 1.9710\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0152 - val_loss: 1.9586\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0150 - val_loss: 1.9495\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0149 - val_loss: 1.9443\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0147 - val_loss: 1.9400\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0145 - val_loss: 1.9329\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0144 - val_loss: 1.9228\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0142 - val_loss: 1.9128\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0140 - val_loss: 1.9054\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0139 - val_loss: 1.9005\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0137 - val_loss: 1.8954\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0136 - val_loss: 1.8881\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0134 - val_loss: 1.8790\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0132 - val_loss: 1.8706\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0131 - val_loss: 1.8644\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0129 - val_loss: 1.8596\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0128 - val_loss: 1.8543\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0126 - val_loss: 1.8472\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0125 - val_loss: 1.8393\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0123 - val_loss: 1.8323\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0122 - val_loss: 1.8271\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0121 - val_loss: 1.8224\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0119 - val_loss: 1.8168\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0118 - val_loss: 1.8099\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0116 - val_loss: 1.8028\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0115 - val_loss: 1.7966\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0114 - val_loss: 1.7915\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0112 - val_loss: 1.7862\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0111 - val_loss: 1.7802\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0110 - val_loss: 1.7693\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0108 - val_loss: 1.7558\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0107 - val_loss: 1.7449\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0106 - val_loss: 1.7387\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0104 - val_loss: 1.7346\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0103 - val_loss: 1.7280\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0102 - val_loss: 1.7179\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0101 - val_loss: 1.7075\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0099 - val_loss: 1.7002\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0098 - val_loss: 1.6959\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0097 - val_loss: 1.6913\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0096 - val_loss: 1.6841\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0095 - val_loss: 1.6750\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0094 - val_loss: 1.6670\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0092 - val_loss: 1.6617\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0091 - val_loss: 1.6576\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0090 - val_loss: 1.6521\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0089 - val_loss: 1.6446\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0088 - val_loss: 1.6370\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0087 - val_loss: 1.6274\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0086 - val_loss: 1.6169\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0085 - val_loss: 1.6081\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0084 - val_loss: 1.6018\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0083 - val_loss: 1.5962\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0082 - val_loss: 1.5895\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0081 - val_loss: 1.5815\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0080 - val_loss: 1.5738\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0079 - val_loss: 1.5678\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0078 - val_loss: 1.5630\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0077 - val_loss: 1.5578\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0076 - val_loss: 1.5513\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0075 - val_loss: 1.5444\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0074 - val_loss: 1.5384\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0073 - val_loss: 1.5336\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0072 - val_loss: 1.5290\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0071 - val_loss: 1.5236\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - val_loss: 1.5175\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0070 - val_loss: 1.5117\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0069 - val_loss: 1.5070\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0068 - val_loss: 1.4995\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0067 - val_loss: 1.4895\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0066 - val_loss: 1.4807\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0066 - val_loss: 1.4754\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0065 - val_loss: 1.4719\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0064 - val_loss: 1.4670\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0063 - val_loss: 1.4597\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0062 - val_loss: 1.4522\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0062 - val_loss: 1.4469\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - val_loss: 1.4436\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - val_loss: 1.4399\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - val_loss: 1.4341\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0059 - val_loss: 1.4276\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0058 - val_loss: 1.4223\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0057 - val_loss: 1.4188\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - val_loss: 1.4157\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0056 - val_loss: 1.4079\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0055 - val_loss: 1.3973\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0055 - val_loss: 1.3892\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - val_loss: 1.3857\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0053 - val_loss: 1.3838\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0053 - val_loss: 1.3788\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - val_loss: 1.3709\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0052 - val_loss: 1.3640\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0051 - val_loss: 1.3605\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - val_loss: 1.3588\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0050 - val_loss: 1.3553\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - val_loss: 1.3491\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - val_loss: 1.3430\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 1.3392\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - val_loss: 1.3374\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - val_loss: 1.3317\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - val_loss: 1.3221\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0046 - val_loss: 1.3140\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - val_loss: 1.3106\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - val_loss: 1.3093\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 1.3056\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - val_loss: 1.2986\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 1.2919\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - val_loss: 1.2887\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 1.2875\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - val_loss: 1.2848\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 1.2794\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0041 - val_loss: 1.2737\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - val_loss: 1.2705\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - val_loss: 1.2664\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - val_loss: 1.2600\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 1.2533\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - val_loss: 1.2487\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - val_loss: 1.2462\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0038 - val_loss: 1.2432\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - val_loss: 1.2385\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - val_loss: 1.2332\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - val_loss: 1.2294\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - val_loss: 1.2273\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - val_loss: 1.2251\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 1.2213\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - val_loss: 1.2144\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - val_loss: 1.2071\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - val_loss: 1.2029\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - val_loss: 1.2013\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 1.1987\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - val_loss: 1.1935\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - val_loss: 1.1879\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 1.1846\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - val_loss: 1.1832\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - val_loss: 1.1812\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - val_loss: 1.1770\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - val_loss: 1.1725\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - val_loss: 1.1698\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 1.1661\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - val_loss: 1.1605\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - val_loss: 1.1553\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 1.1521\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - val_loss: 1.1501\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - val_loss: 1.1473\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 1.1431\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - val_loss: 1.1391\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - val_loss: 1.1367\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - val_loss: 1.1351\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 1.1329\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 1.1270\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - val_loss: 1.1202\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - val_loss: 1.1164\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0027 - val_loss: 1.1156\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - val_loss: 1.1139\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0027 - val_loss: 1.1093\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0027 - val_loss: 1.1042\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 1.1015\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0026 - val_loss: 1.1009\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0026 - val_loss: 1.0994\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - val_loss: 1.0957\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0025 - val_loss: 1.0919\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0025 - val_loss: 1.0876\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - val_loss: 1.0836\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0025 - val_loss: 1.0805\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0025 - val_loss: 1.0780\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - val_loss: 1.0752\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - val_loss: 1.0720\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0024 - val_loss: 1.0691\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - val_loss: 1.0669\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0024 - val_loss: 1.0650\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - val_loss: 1.0627\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - val_loss: 1.0603\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0023 - val_loss: 1.0557\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0023 - val_loss: 1.0507\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0023 - val_loss: 1.0477\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - val_loss: 1.0464\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - val_loss: 1.0444\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0022 - val_loss: 1.0408\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0022 - val_loss: 1.0373\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0022 - val_loss: 1.0353\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0022 - val_loss: 1.0344\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0022 - val_loss: 1.0326\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0021 - val_loss: 1.0297\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0021 - val_loss: 1.0270\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0021 - val_loss: 1.0236\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0021 - val_loss: 1.0197\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0021 - val_loss: 1.0168\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0021 - val_loss: 1.0149\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0021 - val_loss: 1.0129\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0020 - val_loss: 1.0103\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - val_loss: 1.0075\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - val_loss: 1.0056\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0020 - val_loss: 1.0042\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - val_loss: 1.0026\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0020 - val_loss: 0.9983\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0020 - val_loss: 0.9933\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - val_loss: 0.9907\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - val_loss: 0.9902\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0019 - val_loss: 0.9887\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0019 - val_loss: 0.9851\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0019 - val_loss: 0.9817\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0019 - val_loss: 0.9803\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - val_loss: 0.9800\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.9784\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - val_loss: 0.9754\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - val_loss: 0.9731\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.9704\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.9672\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - val_loss: 0.9645\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - val_loss: 0.9626\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.9611\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - val_loss: 0.9590\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - val_loss: 0.9566\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - val_loss: 0.9549\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - val_loss: 0.9537\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.9524\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.9486\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - val_loss: 0.9442\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.9420\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.9416\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.9402\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - val_loss: 0.9370\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - val_loss: 0.9342\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.9332\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - val_loss: 0.9329\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.9313\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.9288\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.9251\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.9221\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - val_loss: 0.9208\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.9197\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.9176\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.9148\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - val_loss: 0.9131\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - val_loss: 0.9124\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.9115\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - val_loss: 0.9095\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 0.9076\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - val_loss: 0.9048\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.9019\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - val_loss: 0.9000\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.8989\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.8973\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - val_loss: 0.8951\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.8932\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.8922\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.8914\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.8900\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.8883\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - val_loss: 0.8852\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.8822\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - val_loss: 0.8807\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.8800\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - val_loss: 0.8784\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.8760\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.8743\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.8737\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0014 - val_loss: 0.8730\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - val_loss: 0.8714\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.8678\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.8646\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.8637\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.8634\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.8615\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.8587\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - val_loss: 0.8571\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - val_loss: 0.8570\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - val_loss: 0.8565\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0014 - val_loss: 0.8545\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - val_loss: 0.8527\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - val_loss: 0.8504\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.8481\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - val_loss: 0.8465\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - val_loss: 0.8454\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.8440\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.8423\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.8409\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.8401\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 0.8393\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.8380\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.8368\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.8342\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - val_loss: 0.8315\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - val_loss: 0.8302\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.8297\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 0.8284\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - val_loss: 0.8262\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - val_loss: 0.8248\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - val_loss: 0.8244\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - val_loss: 0.8239\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - val_loss: 0.8224\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.8210\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.8187\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - val_loss: 0.8164\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - val_loss: 0.8152\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0012 - val_loss: 0.8144\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0012 - val_loss: 0.8130\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.8113\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.8101\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.8096\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.8088\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.8077\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - val_loss: 0.8048\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - val_loss: 0.8021\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.8014\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - val_loss: 0.8012\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - val_loss: 0.7995\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - val_loss: 0.7973\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.7963\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.7962\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - val_loss: 0.7955\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - val_loss: 0.7938\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - val_loss: 0.7926\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - val_loss: 0.7925\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.7907\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.7876\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.7861\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.7863\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - val_loss: 0.7856\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.7835\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.7818\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.7818\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - val_loss: 0.7818\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.7805\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.7772\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.7749\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.7749\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.7747\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.7726\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.7703\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - val_loss: 0.7700\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - val_loss: 0.7703\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.7692\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - val_loss: 0.7672\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - val_loss: 0.7665\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.7669\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.7649\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - val_loss: 0.7616\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - val_loss: 0.7604\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - val_loss: 0.7611\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - val_loss: 0.7604\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - val_loss: 0.7579\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - val_loss: 0.7564\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - val_loss: 0.7569\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 0.7570\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - val_loss: 0.7554\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 0.7522\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 0.7504\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 0.7507\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 0.7501\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - val_loss: 0.7478\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - val_loss: 0.7461\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 0.7462\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - val_loss: 0.7462\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 0.7448\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - val_loss: 0.7432\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - val_loss: 0.7431\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - val_loss: 0.7433\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - val_loss: 0.7409\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.9920e-04 - val_loss: 0.7378\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.9654e-04 - val_loss: 0.7374\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.9332e-04 - val_loss: 0.7380\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.9057e-04 - val_loss: 0.7368\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.8759e-04 - val_loss: 0.7344\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.8444e-04 - val_loss: 0.7336\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.8161e-04 - val_loss: 0.7343\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.7856e-04 - val_loss: 0.7338\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9.7576e-04 - val_loss: 0.7321\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.7288e-04 - val_loss: 0.7294\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.7021e-04 - val_loss: 0.7282\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.6749e-04 - val_loss: 0.7281\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.6480e-04 - val_loss: 0.7272\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 9.6202e-04 - val_loss: 0.7253\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.5936e-04 - val_loss: 0.7241\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 9.5625e-04 - val_loss: 0.7241\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.5360e-04 - val_loss: 0.7238\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.5073e-04 - val_loss: 0.7224\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.4791e-04 - val_loss: 0.7213\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.4508e-04 - val_loss: 0.7213\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.4212e-04 - val_loss: 0.7213\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.4000e-04 - val_loss: 0.7187\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9.3713e-04 - val_loss: 0.7161\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.3469e-04 - val_loss: 0.7160\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.3176e-04 - val_loss: 0.7165\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.2945e-04 - val_loss: 0.7149\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.2671e-04 - val_loss: 0.7128\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.2429e-04 - val_loss: 0.7125\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.2126e-04 - val_loss: 0.7132\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.1890e-04 - val_loss: 0.7123\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9.1608e-04 - val_loss: 0.7105\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.1372e-04 - val_loss: 0.7101\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.1077e-04 - val_loss: 0.7092\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 9.0855e-04 - val_loss: 0.7071\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 9.0604e-04 - val_loss: 0.7057\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 9.0372e-04 - val_loss: 0.7055\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 9.0097e-04 - val_loss: 0.7051\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 8.9888e-04 - val_loss: 0.7037\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 8.9594e-04 - val_loss: 0.7025\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 8.9366e-04 - val_loss: 0.7024\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 8.9098e-04 - val_loss: 0.7023\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 8.8847e-04 - val_loss: 0.7012\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.8579e-04 - val_loss: 0.7003\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 8.8456e-04 - val_loss: 0.7002\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 8.8130e-04 - val_loss: 0.6987\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.7890e-04 - val_loss: 0.6964\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 8.7647e-04 - val_loss: 0.6956\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 8.7411e-04 - val_loss: 0.6958\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 8.7189e-04 - val_loss: 0.6950\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 8.6956e-04 - val_loss: 0.6932\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 8.6717e-04 - val_loss: 0.6926\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 8.6470e-04 - val_loss: 0.6928\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 8.6229e-04 - val_loss: 0.6923\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.6002e-04 - val_loss: 0.6910\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 8.5855e-04 - val_loss: 0.6905\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 8.5549e-04 - val_loss: 0.6892\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 8.5333e-04 - val_loss: 0.6874\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 8.5104e-04 - val_loss: 0.6865\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 8.4892e-04 - val_loss: 0.6863\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 8.4665e-04 - val_loss: 0.6855\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 8.4432e-04 - val_loss: 0.6842\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 8.4220e-04 - val_loss: 0.6835\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 8.3994e-04 - val_loss: 0.6834\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 8.3770e-04 - val_loss: 0.6829\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 8.3544e-04 - val_loss: 0.6819\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 8.3302e-04 - val_loss: 0.6814\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8.3217e-04 - val_loss: 0.6814\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 8.2916e-04 - val_loss: 0.6795\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 8.2682e-04 - val_loss: 0.6774\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 8.2480e-04 - val_loss: 0.6771\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 8.2269e-04 - val_loss: 0.6773\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 8.2068e-04 - val_loss: 0.6760\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 8.1844e-04 - val_loss: 0.6744\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 8.1651e-04 - val_loss: 0.6743\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 8.1429e-04 - val_loss: 0.6746\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 8.1207e-04 - val_loss: 0.6737\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 8.0988e-04 - val_loss: 0.6724\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 8.0864e-04 - val_loss: 0.6723\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 8.0581e-04 - val_loss: 0.6711\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 8.0402e-04 - val_loss: 0.6691\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 8.0201e-04 - val_loss: 0.6682\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7.9994e-04 - val_loss: 0.6683\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 7.9809e-04 - val_loss: 0.6675\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 7.9604e-04 - val_loss: 0.6660\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 7.9402e-04 - val_loss: 0.6654\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 7.9190e-04 - val_loss: 0.6656\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.9000e-04 - val_loss: 0.6651\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.8782e-04 - val_loss: 0.6640\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 7.8585e-04 - val_loss: 0.6635\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.8460e-04 - val_loss: 0.6638\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.8219e-04 - val_loss: 0.6619\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.8025e-04 - val_loss: 0.6597\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.7864e-04 - val_loss: 0.6596\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.7638e-04 - val_loss: 0.6599\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.7475e-04 - val_loss: 0.6586\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.7269e-04 - val_loss: 0.6569\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.7098e-04 - val_loss: 0.6570\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.6893e-04 - val_loss: 0.6574\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.6702e-04 - val_loss: 0.6563\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.6503e-04 - val_loss: 0.6551\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.6311e-04 - val_loss: 0.6552\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 7.6200e-04 - val_loss: 0.6556\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.5983e-04 - val_loss: 0.6532\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.5780e-04 - val_loss: 0.6510\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.5642e-04 - val_loss: 0.6514\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.5418e-04 - val_loss: 0.6518\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.5267e-04 - val_loss: 0.6499\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 7.5068e-04 - val_loss: 0.6484\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.4914e-04 - val_loss: 0.6489\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.4715e-04 - val_loss: 0.6493\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.4549e-04 - val_loss: 0.6478\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.4338e-04 - val_loss: 0.6466\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.4174e-04 - val_loss: 0.6472\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.4070e-04 - val_loss: 0.6475\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.3874e-04 - val_loss: 0.6448\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.3677e-04 - val_loss: 0.6427\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 7.3547e-04 - val_loss: 0.6435\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.3335e-04 - val_loss: 0.6437\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.3185e-04 - val_loss: 0.6416\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.3009e-04 - val_loss: 0.6402\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 7.2863e-04 - val_loss: 0.6411\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.2667e-04 - val_loss: 0.6413\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.2509e-04 - val_loss: 0.6395\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.2322e-04 - val_loss: 0.6386\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.2152e-04 - val_loss: 0.6394\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 7.2019e-04 - val_loss: 0.6395\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.1895e-04 - val_loss: 0.6365\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.1683e-04 - val_loss: 0.6347\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.1564e-04 - val_loss: 0.6358\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.1372e-04 - val_loss: 0.6358\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.1241e-04 - val_loss: 0.6335\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.1063e-04 - val_loss: 0.6324\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.0900e-04 - val_loss: 0.6334\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.0741e-04 - val_loss: 0.6333\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.0571e-04 - val_loss: 0.6315\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.0414e-04 - val_loss: 0.6309\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.0246e-04 - val_loss: 0.6318\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0085e-04 - val_loss: 0.6316\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.0025e-04 - val_loss: 0.6301\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.9789e-04 - val_loss: 0.6283\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.9648e-04 - val_loss: 0.6280\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.9482e-04 - val_loss: 0.6279\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.9356e-04 - val_loss: 0.6267\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.9186e-04 - val_loss: 0.6256\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6.9063e-04 - val_loss: 0.6256\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.8881e-04 - val_loss: 0.6256\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.8741e-04 - val_loss: 0.6246\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.8594e-04 - val_loss: 0.6239\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 6.8431e-04 - val_loss: 0.6240\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.8291e-04 - val_loss: 0.6239\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.8203e-04 - val_loss: 0.6232\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.8015e-04 - val_loss: 0.6212\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.7880e-04 - val_loss: 0.6202\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.7751e-04 - val_loss: 0.6204\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.7616e-04 - val_loss: 0.6198\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7471e-04 - val_loss: 0.6184\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.7319e-04 - val_loss: 0.6179\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.7189e-04 - val_loss: 0.6182\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.7038e-04 - val_loss: 0.6176\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.6886e-04 - val_loss: 0.6166\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.6753e-04 - val_loss: 0.6164\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.6603e-04 - val_loss: 0.6166\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 6.6469e-04 - val_loss: 0.6161\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.6364e-04 - val_loss: 0.6154\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 6.6196e-04 - val_loss: 0.6139\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.6063e-04 - val_loss: 0.6130\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.5945e-04 - val_loss: 0.6128\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.5803e-04 - val_loss: 0.6123\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.5679e-04 - val_loss: 0.6113\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.5551e-04 - val_loss: 0.6108\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.5411e-04 - val_loss: 0.6107\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.5277e-04 - val_loss: 0.6103\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.5153e-04 - val_loss: 0.6096\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.5007e-04 - val_loss: 0.6093\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.4874e-04 - val_loss: 0.6092\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.4744e-04 - val_loss: 0.6089\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.4710e-04 - val_loss: 0.6083\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.4508e-04 - val_loss: 0.6068\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.4376e-04 - val_loss: 0.6057\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.4267e-04 - val_loss: 0.6057\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.4120e-04 - val_loss: 0.6053\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6.4015e-04 - val_loss: 0.6041\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.3897e-04 - val_loss: 0.6036\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.3768e-04 - val_loss: 0.6038\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.3641e-04 - val_loss: 0.6033\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.3518e-04 - val_loss: 0.6024\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.3383e-04 - val_loss: 0.6023\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.3260e-04 - val_loss: 0.6024\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.3146e-04 - val_loss: 0.6019\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6.3041e-04 - val_loss: 0.5999\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.2921e-04 - val_loss: 0.5989\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.2812e-04 - val_loss: 0.5993\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.2708e-04 - val_loss: 0.5987\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.2592e-04 - val_loss: 0.5972\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.2461e-04 - val_loss: 0.5969\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.2345e-04 - val_loss: 0.5974\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.2236e-04 - val_loss: 0.5966\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.2105e-04 - val_loss: 0.5955\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.2009e-04 - val_loss: 0.5956\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 6.1871e-04 - val_loss: 0.5960\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.1766e-04 - val_loss: 0.5951\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.1631e-04 - val_loss: 0.5944\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.1553e-04 - val_loss: 0.5948\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1425e-04 - val_loss: 0.5935\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.1323e-04 - val_loss: 0.5918\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1200e-04 - val_loss: 0.5918\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.1096e-04 - val_loss: 0.5922\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.0988e-04 - val_loss: 0.5909\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.0881e-04 - val_loss: 0.5898\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.0777e-04 - val_loss: 0.5903\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.0657e-04 - val_loss: 0.5903\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.0553e-04 - val_loss: 0.5891\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.0434e-04 - val_loss: 0.5886\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.0328e-04 - val_loss: 0.5892\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.0215e-04 - val_loss: 0.5888\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.0128e-04 - val_loss: 0.5879\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.0012e-04 - val_loss: 0.5865\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.9913e-04 - val_loss: 0.5859\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.9807e-04 - val_loss: 0.5859\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.9714e-04 - val_loss: 0.5851\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.9618e-04 - val_loss: 0.5842\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.9514e-04 - val_loss: 0.5841\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.9421e-04 - val_loss: 0.5840\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.9295e-04 - val_loss: 0.5833\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.9195e-04 - val_loss: 0.5828\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.9080e-04 - val_loss: 0.5828\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.8994e-04 - val_loss: 0.5827\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.8890e-04 - val_loss: 0.5820\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.8781e-04 - val_loss: 0.5818\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.8741e-04 - val_loss: 0.5819\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.8585e-04 - val_loss: 0.5803\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.8501e-04 - val_loss: 0.5790\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.8417e-04 - val_loss: 0.5793\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.8309e-04 - val_loss: 0.5793\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.8227e-04 - val_loss: 0.5779\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.8127e-04 - val_loss: 0.5773\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5.8018e-04 - val_loss: 0.5779\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.7922e-04 - val_loss: 0.5774\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.7828e-04 - val_loss: 0.5763\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.7734e-04 - val_loss: 0.5763\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.7627e-04 - val_loss: 0.5767\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.7537e-04 - val_loss: 0.5760\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.7468e-04 - val_loss: 0.5754\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.7369e-04 - val_loss: 0.5742\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.7257e-04 - val_loss: 0.5735\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.7188e-04 - val_loss: 0.5733\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.7084e-04 - val_loss: 0.5728\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.7002e-04 - val_loss: 0.5720\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.6923e-04 - val_loss: 0.5717\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.6828e-04 - val_loss: 0.5716\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.6744e-04 - val_loss: 0.5712\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.6652e-04 - val_loss: 0.5706\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.6554e-04 - val_loss: 0.5706\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.6465e-04 - val_loss: 0.5704\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.6374e-04 - val_loss: 0.5699\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 5.6298e-04 - val_loss: 0.5697\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.6197e-04 - val_loss: 0.5698\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.6135e-04 - val_loss: 0.5682\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.6034e-04 - val_loss: 0.5670\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.5970e-04 - val_loss: 0.5675\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.5884e-04 - val_loss: 0.5672\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.5811e-04 - val_loss: 0.5658\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.5712e-04 - val_loss: 0.5655\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5.5635e-04 - val_loss: 0.5661\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5.5555e-04 - val_loss: 0.5654\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 5.5459e-04 - val_loss: 0.5644\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5.5369e-04 - val_loss: 0.5647\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 5.5293e-04 - val_loss: 0.5648\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 5.5195e-04 - val_loss: 0.5639\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 5.5112e-04 - val_loss: 0.5635\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 5.5033e-04 - val_loss: 0.5640\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 5.5011e-04 - val_loss: 0.5638\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5.4894e-04 - val_loss: 0.5618\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.4810e-04 - val_loss: 0.5612\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 5.4738e-04 - val_loss: 0.5619\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.4665e-04 - val_loss: 0.5611\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.4569e-04 - val_loss: 0.5598\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.4524e-04 - val_loss: 0.5600\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.4430e-04 - val_loss: 0.5604\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.4361e-04 - val_loss: 0.5593\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 5.4257e-04 - val_loss: 0.5586\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.4199e-04 - val_loss: 0.5592\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 5.4115e-04 - val_loss: 0.5589\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5.4032e-04 - val_loss: 0.5580\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5.3950e-04 - val_loss: 0.5580\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 5.3928e-04 - val_loss: 0.5585\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 5.3837e-04 - val_loss: 0.5566\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.3744e-04 - val_loss: 0.5553\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.3693e-04 - val_loss: 0.5562\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.3600e-04 - val_loss: 0.5559\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 5.3523e-04 - val_loss: 0.5542\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 5.3474e-04 - val_loss: 0.5542\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 5.3390e-04 - val_loss: 0.5549\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 5.3325e-04 - val_loss: 0.5540\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.3246e-04 - val_loss: 0.5530\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 5.3171e-04 - val_loss: 0.5535\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 5.3091e-04 - val_loss: 0.5536\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5.3022e-04 - val_loss: 0.5525\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 5.2957e-04 - val_loss: 0.5524\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5.2869e-04 - val_loss: 0.5530\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 5.2865e-04 - val_loss: 0.5526\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 5.2756e-04 - val_loss: 0.5506\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5.2677e-04 - val_loss: 0.5503\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 5.2607e-04 - val_loss: 0.5510\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 5.2553e-04 - val_loss: 0.5499\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 5.2470e-04 - val_loss: 0.5487\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 5.2422e-04 - val_loss: 0.5493\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 5.2342e-04 - val_loss: 0.5493\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5.2278e-04 - val_loss: 0.5480\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.2213e-04 - val_loss: 0.5478\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 5.2129e-04 - val_loss: 0.5484\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 5.2068e-04 - val_loss: 0.5477\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 5.2005e-04 - val_loss: 0.5470\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 5.1935e-04 - val_loss: 0.5474\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.1861e-04 - val_loss: 0.5476\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.1844e-04 - val_loss: 0.5468\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 5.1741e-04 - val_loss: 0.5454\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 5.1685e-04 - val_loss: 0.5453\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 5.1605e-04 - val_loss: 0.5453\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 5.1569e-04 - val_loss: 0.5443\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5.1505e-04 - val_loss: 0.5437\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5.1440e-04 - val_loss: 0.5440\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5.1381e-04 - val_loss: 0.5436\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 5.1310e-04 - val_loss: 0.5428\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5.1247e-04 - val_loss: 0.5428\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 5.1173e-04 - val_loss: 0.5429\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5.1123e-04 - val_loss: 0.5423\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.1055e-04 - val_loss: 0.5420\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5.0992e-04 - val_loss: 0.5422\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 5.0923e-04 - val_loss: 0.5420\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.0880e-04 - val_loss: 0.5417\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.0811e-04 - val_loss: 0.5404\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.0754e-04 - val_loss: 0.5399\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.0696e-04 - val_loss: 0.5401\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5.0653e-04 - val_loss: 0.5394\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.0580e-04 - val_loss: 0.5386\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.0533e-04 - val_loss: 0.5387\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.0477e-04 - val_loss: 0.5386\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.0416e-04 - val_loss: 0.5378\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.0351e-04 - val_loss: 0.5376\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.0297e-04 - val_loss: 0.5378\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 5.0240e-04 - val_loss: 0.5374\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 5.0174e-04 - val_loss: 0.5369\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.0126e-04 - val_loss: 0.5371\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.0052e-04 - val_loss: 0.5371\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.9994e-04 - val_loss: 0.5366\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.9976e-04 - val_loss: 0.5367\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.9891e-04 - val_loss: 0.5355\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.9845e-04 - val_loss: 0.5347\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4.9790e-04 - val_loss: 0.5350\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.9730e-04 - val_loss: 0.5346\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4.9685e-04 - val_loss: 0.5336\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4.9635e-04 - val_loss: 0.5335\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.9577e-04 - val_loss: 0.5337\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.9515e-04 - val_loss: 0.5330\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4.9453e-04 - val_loss: 0.5325\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.9412e-04 - val_loss: 0.5328\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.9347e-04 - val_loss: 0.5326\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 4.9296e-04 - val_loss: 0.5320\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.9246e-04 - val_loss: 0.5321\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.9188e-04 - val_loss: 0.5322\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.9128e-04 - val_loss: 0.5318\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4.9123e-04 - val_loss: 0.5317\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.9039e-04 - val_loss: 0.5306\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4.8995e-04 - val_loss: 0.5300\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4.8949e-04 - val_loss: 0.5302\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4.8890e-04 - val_loss: 0.5296\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.8842e-04 - val_loss: 0.5289\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.8793e-04 - val_loss: 0.5289\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.8746e-04 - val_loss: 0.5288\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.8699e-04 - val_loss: 0.5282\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4.8643e-04 - val_loss: 0.5280\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.8596e-04 - val_loss: 0.5281\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.8537e-04 - val_loss: 0.5277\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4.8491e-04 - val_loss: 0.5273\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.8440e-04 - val_loss: 0.5275\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.8384e-04 - val_loss: 0.5274\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4.8352e-04 - val_loss: 0.5270\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.8313e-04 - val_loss: 0.5271\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.8244e-04 - val_loss: 0.5259\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.8200e-04 - val_loss: 0.5252\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.8159e-04 - val_loss: 0.5256\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.8117e-04 - val_loss: 0.5250\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.8067e-04 - val_loss: 0.5241\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.8012e-04 - val_loss: 0.5243\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.7963e-04 - val_loss: 0.5243\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4.7919e-04 - val_loss: 0.5234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions2 = model2.predict(X_test).flatten()\n",
        "print(X_test)\n",
        "print(test_predictions2)\n",
        "test_results2 = pd.DataFrame(data={'Test Predictions':test_predictions2, 'Actuals':y_test})\n",
        "test_results2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "43af52f9-e112-4be8-d6b7-e425f061b23e",
        "id": "kbG-YXJTV59I"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 292ms/step\n",
            "[[[264]\n",
            "  [276]\n",
            "  [288]]\n",
            "\n",
            " [[276]\n",
            "  [288]\n",
            "  [300]]\n",
            "\n",
            " [[288]\n",
            "  [300]\n",
            "  [312]]\n",
            "\n",
            " [[300]\n",
            "  [312]\n",
            "  [324]]\n",
            "\n",
            " [[312]\n",
            "  [324]\n",
            "  [336]]\n",
            "\n",
            " [[324]\n",
            "  [336]\n",
            "  [348]]]\n",
            "[301.49387 313.8596  326.24704 338.65436 351.07974 363.52164]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Test Predictions  Actuals\n",
              "0        301.493866      300\n",
              "1        313.859589      312\n",
              "2        326.247040      324\n",
              "3        338.654358      336\n",
              "4        351.079742      348\n",
              "5        363.521637      360"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88b49882-30c8-4393-90a7-54126e2e6551\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Predictions</th>\n",
              "      <th>Actuals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>301.493866</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>313.859589</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>326.247040</td>\n",
              "      <td>324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>338.654358</td>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>351.079742</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>363.521637</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88b49882-30c8-4393-90a7-54126e2e6551')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88b49882-30c8-4393-90a7-54126e2e6551 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88b49882-30c8-4393-90a7-54126e2e6551');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24a434af-9af9-4fdb-8251-ba4d37dc630d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24a434af-9af9-4fdb-8251-ba4d37dc630d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24a434af-9af9-4fdb-8251-ba4d37dc630d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a1b44a9d-11ed-4bd3-b86f-8bac5cca1d51\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_results2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a1b44a9d-11ed-4bd3-b86f-8bac5cca1d51 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_results2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_results2",
              "summary": "{\n  \"name\": \"test_results2\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Test Predictions\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          301.4938659667969,\n          313.8595886230469,\n          363.5216369628906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actuals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 300,\n        \"max\": 360,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          300,\n          312,\n          360\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_results2['Test Predictions'],color='blue',marker='o')\n",
        "plt.plot(test_results2['Actuals'],color='red',marker='s')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "8426f30a-53c0-4aec-9c43-3d51b154221d",
        "id": "Mq-xDg8oV59I"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7a157f26cfa0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}