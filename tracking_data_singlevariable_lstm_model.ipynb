{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOM5Xx0sbhHCN7ldhlDFi8e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manideep-0503/RF-drone-detection-using-lstm-model/blob/main/tracking_data_singlevariable_lstm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BBH1eJ_w9pmh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/tracking_data.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KR0jSHE9Af8M",
        "outputId": "3ae952a8-9cab-41df-cda4-161fdc79eda5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Time      Angle\n",
              "0     1.716894e+09  -0.899008\n",
              "1     1.716894e+09  -1.803182\n",
              "2     1.716894e+09  -2.730930\n",
              "3     1.716894e+09  -3.676353\n",
              "4     1.716894e+09  -4.634019\n",
              "...            ...        ...\n",
              "1431  1.716894e+09 -24.261825\n",
              "1432  1.716894e+09 -24.130108\n",
              "1433  1.716894e+09 -23.986863\n",
              "1434  1.716894e+09 -23.870179\n",
              "1435  1.716894e+09 -23.741146\n",
              "\n",
              "[1436 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8ccf80e-1bf9-494d-9def-dfe9360690ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-0.899008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-1.803182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-2.730930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-3.676353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-4.634019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-24.261825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1432</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-24.130108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1433</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-23.986863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1434</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-23.870179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>1.716894e+09</td>\n",
              "      <td>-23.741146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1436 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8ccf80e-1bf9-494d-9def-dfe9360690ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8ccf80e-1bf9-494d-9def-dfe9360690ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8ccf80e-1bf9-494d-9def-dfe9360690ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a9b2dbd-49c6-4b6d-be78-d784948362b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a9b2dbd-49c6-4b6d-be78-d784948362b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a9b2dbd-49c6-4b6d-be78-d784948362b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b4a9a704-17ff-41be-8051-b534cf3b2e3d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b4a9a704-17ff-41be-8051-b534cf3b2e3d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1436,\n  \"fields\": [\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8833280792312226,\n        \"min\": 1716894002.3100777,\n        \"max\": 1716894012.2998226,\n        \"num_unique_values\": 1342,\n        \"samples\": [\n          1716894008.444301,\n          1716894006.6292634,\n          1716894006.7904246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.94560861103776,\n        \"min\": -88.2040732700681,\n        \"max\": -0.8990084400090171,\n        \"num_unique_values\": 1436,\n        \"samples\": [\n          -19.18563079231958,\n          -44.573138397962,\n          -25.024847280498246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***generating linear sequence of the angle.***\n",
        "\n",
        "1.   creating samples of 3 timesteps each\n",
        "2.   each sample contains 3 timesteps of one feauture only.\n",
        "\n",
        "***X_array and y ***\n",
        "\n",
        "\n",
        "1.   X_array has consecutive samples [0.12.24],[12,24,36],[24,36,48]....\n",
        "2.   y has the output [36,48,60,....]\n",
        "\n"
      ],
      "metadata": {
        "id": "I4GOJ3A1-3DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(df['Angle'])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lOu-qbo_ArwJ",
        "outputId": "f0d6ed4c-1fd8-4d4c-a78c-ba7a805b03b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -0.89900844,  -1.8031817 ,  -2.73092994, ..., -23.9868629 ,\n",
              "       -23.87017888, -23.74114588])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6JQEW2SA-B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[i for i in range(0,360,12)]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUPdbd3S-grl",
        "outputId": "d041a0d7-e30a-439e-d3ce-e94063118b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 12, 24, 36, 48, 60, 72, 84, 96, 108, 120, 132, 144, 156, 168, 180, 192, 204, 216, 228, 240, 252, 264, 276, 288, 300, 312, 324, 336, 348]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "for i in range(len(x) - 2):\n",
        "    sample = x[i:i+3]\n",
        "    X.append(sample)\n",
        "\n",
        "X_array = np.array(X)\n",
        "\n",
        "print(len(X_array))\n",
        "X_array=X_array.reshape(478,9,1)\n",
        "print(X_array.shape)\n",
        "print(X_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o1W23JBG_Y6_",
        "outputId": "df8f2108-0fa4-464a-e6b1-5f2dbe0335a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1434\n",
            "(478, 9, 1)\n",
            "[[[ -0.89900844]\n",
            "  [ -1.8031817 ]\n",
            "  [ -2.73092994]\n",
            "  ...\n",
            "  [ -2.73092994]\n",
            "  [ -3.67635322]\n",
            "  [ -4.63401883]]\n",
            "\n",
            " [[ -3.67635322]\n",
            "  [ -4.63401883]\n",
            "  [ -5.59899574]\n",
            "  ...\n",
            "  [ -5.59899574]\n",
            "  [ -6.56687031]\n",
            "  [ -7.53374596]]\n",
            "\n",
            " [[ -6.56687031]\n",
            "  [ -7.53374596]\n",
            "  [ -8.46359029]\n",
            "  ...\n",
            "  [ -8.46359029]\n",
            "  [ -9.38683252]\n",
            "  [-10.30109292]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-24.97637812]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  ...\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.48777984]]\n",
            "\n",
            " [[-24.5804586 ]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  ...\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.13010756]]\n",
            "\n",
            " [[-24.2618252 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  ...\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.74114588]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array([X_array[i+1,2,0] for i in range(X_array.shape[0]-1)])\n",
        "y=np.append(y,y[len(y)-1])\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "An0nbVOUCBRu",
        "outputId": "8eab0b6b-3415-4149-db9d-776a4976acef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ -5.59899574  -8.46359029 -11.20439274 -13.79759601 -16.04377003\n",
            " -18.10008487 -19.97033818 -21.55983054 -22.97603703 -24.28044857\n",
            " -25.56270818 -26.70931025 -27.77691905 -28.74018941 -29.6970667\n",
            " -30.68814594 -31.66703172 -32.47629945 -33.13732905 -33.71422206\n",
            " -34.14471071 -34.44256838 -34.59496962 -34.5808866  -34.4715992\n",
            " -34.36175664 -34.36610392 -34.39203675 -34.51198996 -34.67390898\n",
            " -34.95557493 -35.29401865 -35.68364253 -36.11995929 -36.63434267\n",
            " -37.13304599 -37.49017808 -37.85603847 -38.01370968 -38.21533956\n",
            " -38.36195782 -38.37781649 -38.28877262 -38.19048281 -38.04520687\n",
            " -37.82168535 -37.53075432 -37.34616704 -37.08619169 -36.72766275\n",
            " -36.48508057 -36.42431667 -36.35028653 -36.1842193  -35.90568237\n",
            " -35.5687805  -35.14841648 -34.6934573  -34.1349757  -33.56940377\n",
            " -33.07044239 -32.55586072 -32.14017522 -31.73213466 -31.29099705\n",
            " -30.74990552 -30.16501814 -29.65240728 -29.08859614 -28.44808428\n",
            " -27.85664271 -27.29866176 -26.77721927 -26.39084872 -26.18924924\n",
            " -25.92826638 -25.79846937 -25.59814374 -25.33660707 -25.09966823\n",
            " -24.84557398 -24.53934714 -24.15787894 -23.74495388 -23.23736297\n",
            " -22.68777081 -22.17106274 -21.64547413 -21.04535896 -20.48655523\n",
            " -19.96274532 -19.36555529 -18.74320737 -18.13026017 -17.56139054\n",
            " -17.09971235 -16.69462893 -16.36749031 -16.07223951 -15.87771183\n",
            " -15.76069185 -15.61069358 -15.40078799 -15.2084185  -14.99117517\n",
            " -14.75680849 -14.47610084 -14.15459505 -13.79686837 -13.34347622\n",
            " -13.01457453 -12.75160106 -12.41017071 -12.07526692 -11.73840359\n",
            " -11.47240118 -11.23287357 -10.97663521 -10.81406087 -10.72690678\n",
            " -10.63467271 -10.57536342 -10.60713843 -10.58371192 -10.68318349\n",
            " -10.78209077 -10.95163039 -11.1453737  -11.2903083  -11.4314817\n",
            " -11.49643929 -11.50463752 -11.49287274 -11.50162458 -11.45484266\n",
            " -11.29983468 -11.08333469 -10.8187613  -10.6453568  -10.48031335\n",
            " -10.39477857 -10.33733492 -10.33900761 -10.35720062 -10.35578974\n",
            " -10.33976894 -10.37647149 -10.45399663 -10.43756098 -10.3047718\n",
            " -10.14626098 -10.05868767  -9.9346231   -9.8836551   -9.78675925\n",
            "  -9.65861293  -9.70062327  -9.68222227  -9.65186128  -9.57614261\n",
            "  -9.63095408  -9.6233672   -9.46684067  -9.28839999  -9.28765138\n",
            "  -9.26846572  -9.27081133  -9.38783095  -9.46811401  -9.38568032\n",
            "  -9.36983177  -9.50685231  -9.77347506 -10.15009277 -10.62019119\n",
            " -11.16987052 -11.71734834 -12.3011671  -12.84567471 -13.35705704\n",
            " -13.94376859 -14.59495115 -15.30149398 -15.95072274 -16.65691202\n",
            " -17.26905345 -17.83902085 -18.19547152 -18.33921947 -18.51692956\n",
            " -18.61078048 -18.64173305 -18.72013051 -18.83478848 -18.8463767\n",
            " -18.94536536 -19.14956548 -19.23448518 -19.4309657  -19.75573597\n",
            " -20.01040065 -20.35170995 -20.80074829 -21.3420513  -21.96264003\n",
            " -22.6516406  -23.28894217 -23.99412322 -24.75831615 -25.57414329\n",
            " -26.32050485 -27.08302111 -27.82605733 -28.50768176 -29.14642218\n",
            " -29.86315171 -30.64815623 -31.32906837 -32.00763091 -32.7647778\n",
            " -33.50542458 -34.27984824 -34.86640832 -35.30401839 -35.65052181\n",
            " -36.04751749 -36.23487467 -36.46007008 -36.75243033 -36.89261303\n",
            " -36.95344586 -37.10640166 -37.3851886  -37.72457312 -38.16440653\n",
            " -38.64240168 -39.11212828 -39.53357434 -39.86497226 -40.25574009\n",
            " -40.56620605 -41.030865   -41.49183582 -41.95020353 -42.45079574\n",
            " -42.94405655 -43.38709525 -43.73502275 -44.05528692 -44.34667936\n",
            " -44.71493494 -45.14417087 -45.48239671 -45.59724557 -45.77138706\n",
            " -45.84137856 -45.78478097 -45.76053739 -45.81100182 -45.78268821\n",
            " -45.68839847 -45.72629776 -45.73747432 -45.81808257 -46.0033029\n",
            " -46.2813915  -46.64283061 -46.97012391 -47.32191859 -47.64442601\n",
            " -47.84132289 -48.18815729 -48.71586924 -49.40447528 -50.23819664\n",
            " -51.20506508 -52.16915916 -52.95304115 -53.58185521 -54.21144933\n",
            " -54.83641436 -55.32935412 -55.6532721  -56.14913623 -56.86277425\n",
            " -57.77899343 -58.8894975  -59.94600703 -60.95124194 -61.67873897\n",
            " -62.42428598 -63.18007982 -63.94896297 -64.82058936 -65.91354115\n",
            " -67.36211801 -68.64040671 -69.66571688 -70.86946439 -72.31249529\n",
            " -74.32795798 -76.13499661 -77.55712697 -79.48852167 -81.12012343\n",
            " -81.87287561 -81.70782036 -81.68510763 -81.54919791 -80.9835461\n",
            " -80.28106805 -79.49950359 -78.76485592 -78.08222092 -77.56756522\n",
            " -77.47039153 -77.46268994 -77.24050567 -77.13492281 -77.27225905\n",
            " -78.51786245 -80.30013086 -81.80575386 -83.07767261 -84.15216292\n",
            " -85.0598698  -85.82668155 -86.47446805 -87.0217045  -87.48399839\n",
            " -87.87453457 -87.87408702 -88.20407327 -87.17300593 -85.50979398\n",
            " -83.54245682 -81.6177396  -79.74680152 -78.20979117 -76.86783811\n",
            " -75.50216532 -74.05554501 -72.957825   -72.24733612 -71.34314692\n",
            " -70.22461952 -69.02641146 -68.1224967  -67.46987343 -66.95255927\n",
            " -66.63913364 -66.40824626 -65.94384697 -65.44240977 -64.77714687\n",
            " -64.31867292 -63.75665674 -63.05479847 -62.30006137 -61.63448668\n",
            " -61.10724073 -60.56182464 -60.00959603 -59.39676136 -58.79119244\n",
            " -58.24766343 -57.5334041  -56.74114394 -56.10216115 -55.75164452\n",
            " -55.3723182  -54.96968639 -54.71173636 -54.46348736 -54.06718075\n",
            " -53.76233127 -53.75053823 -53.65148732 -53.48598778 -53.21470702\n",
            " -52.9621931  -52.93366321 -52.71881691 -52.40880473 -52.28138373\n",
            " -52.19708277 -51.93938281 -51.64434586 -51.27060332 -50.77768569\n",
            " -50.4412057  -50.27953438 -50.17130609 -50.25672098 -50.30020584\n",
            " -50.42099494 -50.43898103 -50.48284716 -50.59837468 -50.56570706\n",
            " -50.61601886 -50.5806125  -50.47360941 -50.40609122 -50.32617749\n",
            " -50.28154382 -50.06910474 -49.81481913 -49.6277962  -49.38987667\n",
            " -49.02067969 -48.73037414 -48.36743261 -48.03446342 -47.5415315\n",
            " -47.05567539 -46.58146936 -46.3398108  -45.97157665 -45.45677753\n",
            " -44.95493276 -44.33280112 -43.83140617 -43.29917727 -43.00461577\n",
            " -42.82186619 -42.86846005 -42.83532967 -42.69837299 -42.64933764\n",
            " -42.45071042 -42.35393857 -42.20116348 -41.87646063 -41.53775011\n",
            " -41.10512319 -40.8909529  -40.68616932 -40.62049654 -40.41271457\n",
            " -40.26077389 -39.98189651 -39.68808208 -39.3725901  -39.08756591\n",
            " -38.95106031 -38.73146638 -38.44030529 -38.01049674 -37.54861931\n",
            " -37.01624715 -36.51141489 -36.02120779 -35.55248099 -35.134647\n",
            " -34.79911931 -34.38107685 -33.92889771 -33.37413534 -32.84833182\n",
            " -32.35146259 -31.87072445 -31.37254329 -30.85815006 -30.44019749\n",
            " -29.91981494 -29.31449652 -28.63892018 -27.90539128 -27.19780615\n",
            " -26.58015804 -26.00870589 -25.50606509 -25.09731619 -24.69845566\n",
            " -24.38130152 -23.9868629  -23.9868629 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_index=int(len(X_array) * 0.8)\n",
        "\n",
        "X_train = X_array[:split_index]\n",
        "X_test = X_array[split_index:]\n",
        "y_train = y[:split_index]\n",
        "y_test = y[split_index:]"
      ],
      "metadata": {
        "id": "UBi3u957C4ds"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n",
        "print(X_test)\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "O51i3kfRNO9u",
        "outputId": "f0987c6c-9912-4cd8-a7fc-897fcfcb11f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ -0.89900844]\n",
            "  [ -1.8031817 ]\n",
            "  [ -2.73092994]\n",
            "  ...\n",
            "  [ -2.73092994]\n",
            "  [ -3.67635322]\n",
            "  [ -4.63401883]]\n",
            "\n",
            " [[ -3.67635322]\n",
            "  [ -4.63401883]\n",
            "  [ -5.59899574]\n",
            "  ...\n",
            "  [ -5.59899574]\n",
            "  [ -6.56687031]\n",
            "  [ -7.53374596]]\n",
            "\n",
            " [[ -6.56687031]\n",
            "  [ -7.53374596]\n",
            "  [ -8.46359029]\n",
            "  ...\n",
            "  [ -8.46359029]\n",
            "  [ -9.38683252]\n",
            "  [-10.30109292]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-53.62298049]\n",
            "  [-53.56720263]\n",
            "  [-53.48598778]\n",
            "  ...\n",
            "  [-53.48598778]\n",
            "  [-53.38105542]\n",
            "  [-53.3100182 ]]\n",
            "\n",
            " [[-53.38105542]\n",
            "  [-53.3100182 ]\n",
            "  [-53.21470702]\n",
            "  ...\n",
            "  [-53.21470702]\n",
            "  [-53.09676447]\n",
            "  [-53.01311298]]\n",
            "\n",
            " [[-53.09676447]\n",
            "  [-53.01311298]\n",
            "  [-52.9621931 ]\n",
            "  ...\n",
            "  [-52.9621931 ]\n",
            "  [-52.94254394]\n",
            "  [-52.95279873]]]\n",
            "[[[-52.94254394]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.81489992]]\n",
            "\n",
            " [[-52.88708726]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.51608985]]\n",
            "\n",
            " [[-52.60044764]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.29292731]]\n",
            "\n",
            " [[-52.33492506]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.23353711]]\n",
            "\n",
            " [[-52.24231336]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.04834217]]\n",
            "\n",
            " [[-52.13477904]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.76476912]]\n",
            "\n",
            " [[-51.86362927]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.39765302]]\n",
            "\n",
            " [[-51.50380818]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-50.95934366]]\n",
            "\n",
            " [[-51.12406141]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.52028511]]\n",
            "\n",
            " [[-50.63190611]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.32102036]]\n",
            "\n",
            " [[-50.39314855]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.17800432]]\n",
            "\n",
            " [[-50.21361806]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.23953497]]\n",
            "\n",
            " [[-50.19222253]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.31435931]]\n",
            "\n",
            " [[-50.30050696]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.35472481]]\n",
            "\n",
            " [[-50.31407465]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.46116092]]\n",
            "\n",
            " [[-50.4557992 ]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.47873973]]\n",
            "\n",
            " [[-50.44526228]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.57181662]]\n",
            "\n",
            " [[-50.51426964]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.56639203]]\n",
            "\n",
            " [[-50.59594105]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.5904813 ]]\n",
            "\n",
            " [[-50.59259916]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.58215956]]\n",
            "\n",
            " [[-50.61262053]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.49779211]]\n",
            "\n",
            " [[-50.55190157]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.45489693]]\n",
            "\n",
            " [[-50.47799735]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.3418331 ]]\n",
            "\n",
            " [[-50.38692228]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32314603]]\n",
            "\n",
            " [[-50.3386263 ]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.12666277]]\n",
            "\n",
            " [[-50.21551764]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-49.88563774]]\n",
            "\n",
            " [[-49.98825503]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.65983005]]\n",
            "\n",
            " [[-49.72168448]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.49126724]]\n",
            "\n",
            " [[-49.57107513]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.12791664]]\n",
            "\n",
            " [[-49.268317  ]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-48.84778164]]\n",
            "\n",
            " [[-48.9450186 ]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.49057878]]\n",
            "\n",
            " [[-48.59411711]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.16485851]]\n",
            "\n",
            " [[-48.2762883 ]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-47.72166797]]\n",
            "\n",
            " [[-47.88634427]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.23339338]]\n",
            "\n",
            " [[-47.39570791]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-46.70607824]]\n",
            "\n",
            " [[-46.8635764 ]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.42456394]]\n",
            "\n",
            " [[-46.48813738]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.11208461]]\n",
            "\n",
            " [[-46.23522767]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.64289674]]\n",
            "\n",
            " [[-45.81482812]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.13680959]]\n",
            "\n",
            " [[-45.30442265]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.55207459]]\n",
            "\n",
            " [[-44.75972774]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-43.99737766]]\n",
            "\n",
            " [[-44.14849027]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.45866853]]\n",
            "\n",
            " [[-43.6515354 ]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.07369114]]\n",
            "\n",
            " [[-43.17138003]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-42.85558873]]\n",
            "\n",
            " [[-42.91604475]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82949152]]\n",
            "\n",
            " [[-42.81357566]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.8698309 ]]\n",
            "\n",
            " [[-42.88137509]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.74973605]]\n",
            "\n",
            " [[-42.77928676]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.67308156]]\n",
            "\n",
            " [[-42.67324626]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.53682594]]\n",
            "\n",
            " [[-42.60346389]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.36059734]]\n",
            "\n",
            " [[-42.3924243 ]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.27284582]]\n",
            "\n",
            " [[-42.32421582]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.00182017]]\n",
            "\n",
            " [[-42.11042659]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.66737955]]\n",
            "\n",
            " [[-41.78064636]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.23345086]]\n",
            "\n",
            " [[-41.39278482]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-40.93530953]]\n",
            "\n",
            " [[-41.00623524]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.74268538]]\n",
            "\n",
            " [[-40.82633027]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.64921066]]\n",
            "\n",
            " [[-40.65543448]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.50099505]]\n",
            "\n",
            " [[-40.57066117]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.31654622]]\n",
            "\n",
            " [[-40.35168421]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.09229517]]\n",
            "\n",
            " [[-40.18562754]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.75803577]]\n",
            "\n",
            " [[-39.85548689]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.49426632]]\n",
            "\n",
            " [[-39.59978385]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.16956091]]\n",
            "\n",
            " [[-39.27949443]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.00183798]]\n",
            "\n",
            " [[-39.03210104]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.79286547]]\n",
            "\n",
            " [[-38.88101188]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.55408711]]\n",
            "\n",
            " [[-38.65149641]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.16758928]]\n",
            "\n",
            " [[-38.31115667]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-37.70150032]]\n",
            "\n",
            " [[-37.84072128]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.2052172 ]]\n",
            "\n",
            " [[-37.38292544]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-36.64899535]]\n",
            "\n",
            " [[-36.81672447]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.19671571]]\n",
            "\n",
            " [[-36.36037863]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-35.67888299]]\n",
            "\n",
            " [[-35.8345917 ]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.25887846]]\n",
            "\n",
            " [[-35.41219674]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-34.92584627]]\n",
            "\n",
            " [[-35.03800122]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.50543465]]\n",
            "\n",
            " [[-34.65870424]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.09199801]]\n",
            "\n",
            " [[-34.2429866 ]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.56928687]]\n",
            "\n",
            " [[-33.7544275 ]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.03429144]]\n",
            "\n",
            " [[-33.20978726]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.4874653 ]]\n",
            "\n",
            " [[-32.6525533 ]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.04235085]]\n",
            "\n",
            " [[-32.20283678]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.53634936]]\n",
            "\n",
            " [[-31.68863635]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.01312605]]\n",
            "\n",
            " [[-31.19791608]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.59185077]]\n",
            "\n",
            " [[-30.73142468]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.1035144 ]]\n",
            "\n",
            " [[-30.27719051]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.52474784]]\n",
            "\n",
            " [[-29.72670125]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-28.8711147 ]]\n",
            "\n",
            " [[-29.09645822]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.15566643]]\n",
            "\n",
            " [[-28.40030288]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.4272172 ]]\n",
            "\n",
            " [[-27.64983596]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-26.79385472]]\n",
            "\n",
            " [[-26.99990222]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.16934236]]\n",
            "\n",
            " [[-26.35927849]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-25.65763892]]\n",
            "\n",
            " [[-25.8379374 ]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.245207  ]]\n",
            "\n",
            " [[-25.38169345]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-24.84318559]]\n",
            "\n",
            " [[-24.97637812]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.48777984]]\n",
            "\n",
            " [[-24.5804586 ]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.13010756]]\n",
            "\n",
            " [[-24.2618252 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.74114588]]]\n",
            "[ -5.59899574  -8.46359029 -11.20439274 -13.79759601 -16.04377003\n",
            " -18.10008487 -19.97033818 -21.55983054 -22.97603703 -24.28044857\n",
            " -25.56270818 -26.70931025 -27.77691905 -28.74018941 -29.6970667\n",
            " -30.68814594 -31.66703172 -32.47629945 -33.13732905 -33.71422206\n",
            " -34.14471071 -34.44256838 -34.59496962 -34.5808866  -34.4715992\n",
            " -34.36175664 -34.36610392 -34.39203675 -34.51198996 -34.67390898\n",
            " -34.95557493 -35.29401865 -35.68364253 -36.11995929 -36.63434267\n",
            " -37.13304599 -37.49017808 -37.85603847 -38.01370968 -38.21533956\n",
            " -38.36195782 -38.37781649 -38.28877262 -38.19048281 -38.04520687\n",
            " -37.82168535 -37.53075432 -37.34616704 -37.08619169 -36.72766275\n",
            " -36.48508057 -36.42431667 -36.35028653 -36.1842193  -35.90568237\n",
            " -35.5687805  -35.14841648 -34.6934573  -34.1349757  -33.56940377\n",
            " -33.07044239 -32.55586072 -32.14017522 -31.73213466 -31.29099705\n",
            " -30.74990552 -30.16501814 -29.65240728 -29.08859614 -28.44808428\n",
            " -27.85664271 -27.29866176 -26.77721927 -26.39084872 -26.18924924\n",
            " -25.92826638 -25.79846937 -25.59814374 -25.33660707 -25.09966823\n",
            " -24.84557398 -24.53934714 -24.15787894 -23.74495388 -23.23736297\n",
            " -22.68777081 -22.17106274 -21.64547413 -21.04535896 -20.48655523\n",
            " -19.96274532 -19.36555529 -18.74320737 -18.13026017 -17.56139054\n",
            " -17.09971235 -16.69462893 -16.36749031 -16.07223951 -15.87771183\n",
            " -15.76069185 -15.61069358 -15.40078799 -15.2084185  -14.99117517\n",
            " -14.75680849 -14.47610084 -14.15459505 -13.79686837 -13.34347622\n",
            " -13.01457453 -12.75160106 -12.41017071 -12.07526692 -11.73840359\n",
            " -11.47240118 -11.23287357 -10.97663521 -10.81406087 -10.72690678\n",
            " -10.63467271 -10.57536342 -10.60713843 -10.58371192 -10.68318349\n",
            " -10.78209077 -10.95163039 -11.1453737  -11.2903083  -11.4314817\n",
            " -11.49643929 -11.50463752 -11.49287274 -11.50162458 -11.45484266\n",
            " -11.29983468 -11.08333469 -10.8187613  -10.6453568  -10.48031335\n",
            " -10.39477857 -10.33733492 -10.33900761 -10.35720062 -10.35578974\n",
            " -10.33976894 -10.37647149 -10.45399663 -10.43756098 -10.3047718\n",
            " -10.14626098 -10.05868767  -9.9346231   -9.8836551   -9.78675925\n",
            "  -9.65861293  -9.70062327  -9.68222227  -9.65186128  -9.57614261\n",
            "  -9.63095408  -9.6233672   -9.46684067  -9.28839999  -9.28765138\n",
            "  -9.26846572  -9.27081133  -9.38783095  -9.46811401  -9.38568032\n",
            "  -9.36983177  -9.50685231  -9.77347506 -10.15009277 -10.62019119\n",
            " -11.16987052 -11.71734834 -12.3011671  -12.84567471 -13.35705704\n",
            " -13.94376859 -14.59495115 -15.30149398 -15.95072274 -16.65691202\n",
            " -17.26905345 -17.83902085 -18.19547152 -18.33921947 -18.51692956\n",
            " -18.61078048 -18.64173305 -18.72013051 -18.83478848 -18.8463767\n",
            " -18.94536536 -19.14956548 -19.23448518 -19.4309657  -19.75573597\n",
            " -20.01040065 -20.35170995 -20.80074829 -21.3420513  -21.96264003\n",
            " -22.6516406  -23.28894217 -23.99412322 -24.75831615 -25.57414329\n",
            " -26.32050485 -27.08302111 -27.82605733 -28.50768176 -29.14642218\n",
            " -29.86315171 -30.64815623 -31.32906837 -32.00763091 -32.7647778\n",
            " -33.50542458 -34.27984824 -34.86640832 -35.30401839 -35.65052181\n",
            " -36.04751749 -36.23487467 -36.46007008 -36.75243033 -36.89261303\n",
            " -36.95344586 -37.10640166 -37.3851886  -37.72457312 -38.16440653\n",
            " -38.64240168 -39.11212828 -39.53357434 -39.86497226 -40.25574009\n",
            " -40.56620605 -41.030865   -41.49183582 -41.95020353 -42.45079574\n",
            " -42.94405655 -43.38709525 -43.73502275 -44.05528692 -44.34667936\n",
            " -44.71493494 -45.14417087 -45.48239671 -45.59724557 -45.77138706\n",
            " -45.84137856 -45.78478097 -45.76053739 -45.81100182 -45.78268821\n",
            " -45.68839847 -45.72629776 -45.73747432 -45.81808257 -46.0033029\n",
            " -46.2813915  -46.64283061 -46.97012391 -47.32191859 -47.64442601\n",
            " -47.84132289 -48.18815729 -48.71586924 -49.40447528 -50.23819664\n",
            " -51.20506508 -52.16915916 -52.95304115 -53.58185521 -54.21144933\n",
            " -54.83641436 -55.32935412 -55.6532721  -56.14913623 -56.86277425\n",
            " -57.77899343 -58.8894975  -59.94600703 -60.95124194 -61.67873897\n",
            " -62.42428598 -63.18007982 -63.94896297 -64.82058936 -65.91354115\n",
            " -67.36211801 -68.64040671 -69.66571688 -70.86946439 -72.31249529\n",
            " -74.32795798 -76.13499661 -77.55712697 -79.48852167 -81.12012343\n",
            " -81.87287561 -81.70782036 -81.68510763 -81.54919791 -80.9835461\n",
            " -80.28106805 -79.49950359 -78.76485592 -78.08222092 -77.56756522\n",
            " -77.47039153 -77.46268994 -77.24050567 -77.13492281 -77.27225905\n",
            " -78.51786245 -80.30013086 -81.80575386 -83.07767261 -84.15216292\n",
            " -85.0598698  -85.82668155 -86.47446805 -87.0217045  -87.48399839\n",
            " -87.87453457 -87.87408702 -88.20407327 -87.17300593 -85.50979398\n",
            " -83.54245682 -81.6177396  -79.74680152 -78.20979117 -76.86783811\n",
            " -75.50216532 -74.05554501 -72.957825   -72.24733612 -71.34314692\n",
            " -70.22461952 -69.02641146 -68.1224967  -67.46987343 -66.95255927\n",
            " -66.63913364 -66.40824626 -65.94384697 -65.44240977 -64.77714687\n",
            " -64.31867292 -63.75665674 -63.05479847 -62.30006137 -61.63448668\n",
            " -61.10724073 -60.56182464 -60.00959603 -59.39676136 -58.79119244\n",
            " -58.24766343 -57.5334041  -56.74114394 -56.10216115 -55.75164452\n",
            " -55.3723182  -54.96968639 -54.71173636 -54.46348736 -54.06718075\n",
            " -53.76233127 -53.75053823 -53.65148732 -53.48598778 -53.21470702\n",
            " -52.9621931  -52.93366321]\n",
            "[-52.71881691 -52.40880473 -52.28138373 -52.19708277 -51.93938281\n",
            " -51.64434586 -51.27060332 -50.77768569 -50.4412057  -50.27953438\n",
            " -50.17130609 -50.25672098 -50.30020584 -50.42099494 -50.43898103\n",
            " -50.48284716 -50.59837468 -50.56570706 -50.61601886 -50.5806125\n",
            " -50.47360941 -50.40609122 -50.32617749 -50.28154382 -50.06910474\n",
            " -49.81481913 -49.6277962  -49.38987667 -49.02067969 -48.73037414\n",
            " -48.36743261 -48.03446342 -47.5415315  -47.05567539 -46.58146936\n",
            " -46.3398108  -45.97157665 -45.45677753 -44.95493276 -44.33280112\n",
            " -43.83140617 -43.29917727 -43.00461577 -42.82186619 -42.86846005\n",
            " -42.83532967 -42.69837299 -42.64933764 -42.45071042 -42.35393857\n",
            " -42.20116348 -41.87646063 -41.53775011 -41.10512319 -40.8909529\n",
            " -40.68616932 -40.62049654 -40.41271457 -40.26077389 -39.98189651\n",
            " -39.68808208 -39.3725901  -39.08756591 -38.95106031 -38.73146638\n",
            " -38.44030529 -38.01049674 -37.54861931 -37.01624715 -36.51141489\n",
            " -36.02120779 -35.55248099 -35.134647   -34.79911931 -34.38107685\n",
            " -33.92889771 -33.37413534 -32.84833182 -32.35146259 -31.87072445\n",
            " -31.37254329 -30.85815006 -30.44019749 -29.91981494 -29.31449652\n",
            " -28.63892018 -27.90539128 -27.19780615 -26.58015804 -26.00870589\n",
            " -25.50606509 -25.09731619 -24.69845566 -24.38130152 -23.9868629\n",
            " -23.9868629 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A_sFGT1DNOmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa75C7lfETAY",
        "outputId": "b9be84e5-ad81-4317-992d-a7433138881f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense"
      ],
      "metadata": {
        "id": "mRgrD5HsDe0W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(9, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3DaTaq6uFAqN",
        "outputId": "39f2de0e-9d6a-42a3-8fa2-2311a42f697c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 50)                10400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10451 (40.82 KB)\n",
            "Trainable params: 10451 (40.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wxubhTH7FI97",
        "outputId": "6aee5f7c-217a-4be9-f49f-dd0eb1b6a865"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "10/10 [==============================] - 2s 66ms/step - loss: 184.9834 - val_loss: 385.2210\n",
            "Epoch 2/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 20.0973 - val_loss: 21.2585\n",
            "Epoch 3/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 2.8432 - val_loss: 17.0376\n",
            "Epoch 4/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1.2053 - val_loss: 1.4384\n",
            "Epoch 5/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.7603 - val_loss: 4.0997\n",
            "Epoch 6/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4752 - val_loss: 1.1610\n",
            "Epoch 7/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.4185 - val_loss: 1.4725\n",
            "Epoch 8/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4077 - val_loss: 0.9341\n",
            "Epoch 9/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.4043 - val_loss: 2.1577\n",
            "Epoch 10/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.3982 - val_loss: 2.2660\n",
            "Epoch 11/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3808 - val_loss: 3.5947\n",
            "Epoch 12/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3732 - val_loss: 1.6201\n",
            "Epoch 13/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3637 - val_loss: 1.4355\n",
            "Epoch 14/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3503 - val_loss: 1.2095\n",
            "Epoch 15/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3532 - val_loss: 1.4607\n",
            "Epoch 16/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.3409 - val_loss: 2.1451\n",
            "Epoch 17/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3341 - val_loss: 1.4380\n",
            "Epoch 18/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3288 - val_loss: 2.3666\n",
            "Epoch 19/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3308 - val_loss: 2.0672\n",
            "Epoch 20/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3250 - val_loss: 2.2897\n",
            "Epoch 21/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3216 - val_loss: 1.1947\n",
            "Epoch 22/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3222 - val_loss: 1.3773\n",
            "Epoch 23/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3033 - val_loss: 0.9653\n",
            "Epoch 24/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3046 - val_loss: 0.9380\n",
            "Epoch 25/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2936 - val_loss: 1.5139\n",
            "Epoch 26/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2818 - val_loss: 1.7983\n",
            "Epoch 27/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2805 - val_loss: 1.0109\n",
            "Epoch 28/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2765 - val_loss: 1.6635\n",
            "Epoch 29/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2769 - val_loss: 2.2764\n",
            "Epoch 30/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2633 - val_loss: 2.0529\n",
            "Epoch 31/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2432 - val_loss: 2.8701\n",
            "Epoch 32/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2476 - val_loss: 2.4479\n",
            "Epoch 33/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2264 - val_loss: 1.8412\n",
            "Epoch 34/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2267 - val_loss: 1.8912\n",
            "Epoch 35/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2285 - val_loss: 0.9066\n",
            "Epoch 36/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2556 - val_loss: 0.4070\n",
            "Epoch 37/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2652 - val_loss: 1.9464\n",
            "Epoch 38/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2181 - val_loss: 1.5573\n",
            "Epoch 39/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2092 - val_loss: 2.7733\n",
            "Epoch 40/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2171 - val_loss: 4.2221\n",
            "Epoch 41/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2278 - val_loss: 2.9960\n",
            "Epoch 42/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2131 - val_loss: 0.9306\n",
            "Epoch 43/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2199 - val_loss: 0.9227\n",
            "Epoch 44/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2268 - val_loss: 2.7268\n",
            "Epoch 45/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2352 - val_loss: 4.0589\n",
            "Epoch 46/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2281 - val_loss: 3.0178\n",
            "Epoch 47/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2005 - val_loss: 2.8019\n",
            "Epoch 48/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1971 - val_loss: 1.3361\n",
            "Epoch 49/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1928 - val_loss: 1.6157\n",
            "Epoch 50/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1896 - val_loss: 1.3835\n",
            "Epoch 51/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1957 - val_loss: 2.1230\n",
            "Epoch 52/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1916 - val_loss: 2.9503\n",
            "Epoch 53/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2055 - val_loss: 2.0927\n",
            "Epoch 54/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1928 - val_loss: 0.9757\n",
            "Epoch 55/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1919 - val_loss: 2.0422\n",
            "Epoch 56/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1859 - val_loss: 2.0276\n",
            "Epoch 57/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1887 - val_loss: 1.4702\n",
            "Epoch 58/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1729 - val_loss: 3.4341\n",
            "Epoch 59/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1761 - val_loss: 1.5289\n",
            "Epoch 60/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1660 - val_loss: 1.3713\n",
            "Epoch 61/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1660 - val_loss: 2.3742\n",
            "Epoch 62/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1659 - val_loss: 1.5630\n",
            "Epoch 63/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1621 - val_loss: 1.7409\n",
            "Epoch 64/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1646 - val_loss: 2.6423\n",
            "Epoch 65/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1627 - val_loss: 0.8417\n",
            "Epoch 66/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1644 - val_loss: 2.8993\n",
            "Epoch 67/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1611 - val_loss: 1.4818\n",
            "Epoch 68/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1412 - val_loss: 1.0094\n",
            "Epoch 69/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1409 - val_loss: 1.6992\n",
            "Epoch 70/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1421 - val_loss: 0.6223\n",
            "Epoch 71/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1615 - val_loss: 3.0947\n",
            "Epoch 72/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1472 - val_loss: 0.8279\n",
            "Epoch 73/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2180 - val_loss: 2.2974\n",
            "Epoch 74/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1644 - val_loss: 2.8341\n",
            "Epoch 75/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1585 - val_loss: 0.3365\n",
            "Epoch 76/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1393 - val_loss: 1.5147\n",
            "Epoch 77/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1211 - val_loss: 0.6188\n",
            "Epoch 78/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1221 - val_loss: 1.9053\n",
            "Epoch 79/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1155 - val_loss: 1.1479\n",
            "Epoch 80/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0903 - val_loss: 1.1919\n",
            "Epoch 81/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0754 - val_loss: 1.5448\n",
            "Epoch 82/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0688 - val_loss: 1.9494\n",
            "Epoch 83/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0618 - val_loss: 1.8171\n",
            "Epoch 84/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0983 - val_loss: 0.9088\n",
            "Epoch 85/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0638 - val_loss: 1.2633\n",
            "Epoch 86/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0427 - val_loss: 1.2977\n",
            "Epoch 87/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0426 - val_loss: 0.8291\n",
            "Epoch 88/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0391 - val_loss: 1.3027\n",
            "Epoch 89/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0372 - val_loss: 0.8648\n",
            "Epoch 90/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0283 - val_loss: 1.9611\n",
            "Epoch 91/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0505 - val_loss: 1.8498\n",
            "Epoch 92/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0387 - val_loss: 1.0957\n",
            "Epoch 93/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 1.2185\n",
            "Epoch 94/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 1.8256\n",
            "Epoch 95/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0367 - val_loss: 1.9376\n",
            "Epoch 96/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0421 - val_loss: 0.4008\n",
            "Epoch 97/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0399 - val_loss: 1.6747\n",
            "Epoch 98/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0216 - val_loss: 0.9832\n",
            "Epoch 99/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0136 - val_loss: 1.0626\n",
            "Epoch 100/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 1.5070\n",
            "Epoch 101/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0172 - val_loss: 2.2052\n",
            "Epoch 102/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0250 - val_loss: 0.7770\n",
            "Epoch 103/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0246 - val_loss: 1.4678\n",
            "Epoch 104/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0164 - val_loss: 0.8914\n",
            "Epoch 105/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0154 - val_loss: 0.7729\n",
            "Epoch 106/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 1.2965\n",
            "Epoch 107/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 1.0004\n",
            "Epoch 108/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 1.7101\n",
            "Epoch 109/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 1.1132\n",
            "Epoch 110/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 1.1883\n",
            "Epoch 111/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0156 - val_loss: 1.1509\n",
            "Epoch 112/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.9440\n",
            "Epoch 113/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 1.1319\n",
            "Epoch 114/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0169 - val_loss: 0.8446\n",
            "Epoch 115/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 1.0780\n",
            "Epoch 116/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 1.2934\n",
            "Epoch 117/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 1.0484\n",
            "Epoch 118/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 1.0834\n",
            "Epoch 119/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0220 - val_loss: 1.1398\n",
            "Epoch 120/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0247 - val_loss: 0.8424\n",
            "Epoch 121/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0447 - val_loss: 1.2914\n",
            "Epoch 122/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0386 - val_loss: 1.3026\n",
            "Epoch 123/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0227 - val_loss: 0.6503\n",
            "Epoch 124/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0208 - val_loss: 0.6917\n",
            "Epoch 125/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0188 - val_loss: 1.3033\n",
            "Epoch 126/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.7329\n",
            "Epoch 127/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 1.1501\n",
            "Epoch 128/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 1.4611\n",
            "Epoch 129/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.6705\n",
            "Epoch 130/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0152 - val_loss: 1.4239\n",
            "Epoch 131/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 1.6415\n",
            "Epoch 132/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0179 - val_loss: 1.1995\n",
            "Epoch 133/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 1.1532\n",
            "Epoch 134/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0145 - val_loss: 1.0107\n",
            "Epoch 135/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.7927\n",
            "Epoch 136/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 1.0288\n",
            "Epoch 137/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.7782\n",
            "Epoch 138/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 1.8699\n",
            "Epoch 139/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0300 - val_loss: 0.6175\n",
            "Epoch 140/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 1.2422\n",
            "Epoch 141/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 1.2543\n",
            "Epoch 142/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 1.0365\n",
            "Epoch 143/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0067 - val_loss: 1.3258\n",
            "Epoch 144/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 1.0387\n",
            "Epoch 145/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.8982\n",
            "Epoch 146/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 1.1297\n",
            "Epoch 147/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 1.0680\n",
            "Epoch 148/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.8754\n",
            "Epoch 149/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 1.3338\n",
            "Epoch 150/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0202 - val_loss: 0.8793\n",
            "Epoch 151/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0290 - val_loss: 1.1452\n",
            "Epoch 152/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0232 - val_loss: 0.7205\n",
            "Epoch 153/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 1.2541\n",
            "Epoch 154/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 1.1781\n",
            "Epoch 155/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.8107\n",
            "Epoch 156/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.5621\n",
            "Epoch 157/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0199 - val_loss: 1.5768\n",
            "Epoch 158/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0185 - val_loss: 0.9433\n",
            "Epoch 159/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0311 - val_loss: 1.0417\n",
            "Epoch 160/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 1.4115\n",
            "Epoch 161/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0201 - val_loss: 0.8297\n",
            "Epoch 162/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 1.2858\n",
            "Epoch 163/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.8444\n",
            "Epoch 164/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 1.2285\n",
            "Epoch 165/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 1.2809\n",
            "Epoch 166/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 1.2939\n",
            "Epoch 167/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 1.6417\n",
            "Epoch 168/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0119 - val_loss: 1.0797\n",
            "Epoch 169/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0146 - val_loss: 1.0718\n",
            "Epoch 170/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.9558\n",
            "Epoch 171/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 1.5077\n",
            "Epoch 172/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.9503\n",
            "Epoch 173/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 1.4355\n",
            "Epoch 174/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0140 - val_loss: 1.0412\n",
            "Epoch 175/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 1.0277\n",
            "Epoch 176/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 1.2545\n",
            "Epoch 177/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.8984\n",
            "Epoch 178/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.9565\n",
            "Epoch 179/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 1.1047\n",
            "Epoch 180/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.9246\n",
            "Epoch 181/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 1.0696\n",
            "Epoch 182/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.8923\n",
            "Epoch 183/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 1.1800\n",
            "Epoch 184/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 1.1099\n",
            "Epoch 185/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 1.1435\n",
            "Epoch 186/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 1.1999\n",
            "Epoch 187/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 1.1707\n",
            "Epoch 188/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 1.1726\n",
            "Epoch 189/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.9808\n",
            "Epoch 190/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.5863\n",
            "Epoch 191/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 1.2524\n",
            "Epoch 192/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 1.4316\n",
            "Epoch 193/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 1.5086\n",
            "Epoch 194/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 1.6353\n",
            "Epoch 195/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.6417\n",
            "Epoch 196/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.7020\n",
            "Epoch 197/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0083 - val_loss: 1.3187\n",
            "Epoch 198/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0083 - val_loss: 0.7033\n",
            "Epoch 199/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 1.0302\n",
            "Epoch 200/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 1.1455\n",
            "Epoch 201/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 1.2388\n",
            "Epoch 202/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0139 - val_loss: 0.9246\n",
            "Epoch 203/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 1.5634\n",
            "Epoch 204/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.5655\n",
            "Epoch 205/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.8964\n",
            "Epoch 206/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 1.0322\n",
            "Epoch 207/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 1.0353\n",
            "Epoch 208/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 1.2451\n",
            "Epoch 209/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 0.9081\n",
            "Epoch 210/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 1.4770\n",
            "Epoch 211/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 1.1809\n",
            "Epoch 212/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.7079\n",
            "Epoch 213/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0227 - val_loss: 0.6335\n",
            "Epoch 214/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0384 - val_loss: 0.5810\n",
            "Epoch 215/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0594 - val_loss: 0.9133\n",
            "Epoch 216/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0732 - val_loss: 1.1354\n",
            "Epoch 217/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0436 - val_loss: 1.9389\n",
            "Epoch 218/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0252 - val_loss: 0.7296\n",
            "Epoch 219/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0232 - val_loss: 0.6766\n",
            "Epoch 220/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 2.2483\n",
            "Epoch 221/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0181 - val_loss: 0.9002\n",
            "Epoch 222/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0104 - val_loss: 1.0475\n",
            "Epoch 223/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 1.0043\n",
            "Epoch 224/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 0.9527\n",
            "Epoch 225/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 1.3078\n",
            "Epoch 226/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0130 - val_loss: 1.0108\n",
            "Epoch 227/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.9787\n",
            "Epoch 228/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0151 - val_loss: 0.6604\n",
            "Epoch 229/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.7718\n",
            "Epoch 230/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0264 - val_loss: 1.6161\n",
            "Epoch 231/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0344 - val_loss: 0.5553\n",
            "Epoch 232/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0415 - val_loss: 1.4865\n",
            "Epoch 233/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0524 - val_loss: 1.7561\n",
            "Epoch 234/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0219 - val_loss: 1.1083\n",
            "Epoch 235/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0132 - val_loss: 0.9942\n",
            "Epoch 236/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.9685\n",
            "Epoch 237/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.4604\n",
            "Epoch 238/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0263 - val_loss: 1.5007\n",
            "Epoch 239/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.6262\n",
            "Epoch 240/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0118 - val_loss: 0.7562\n",
            "Epoch 241/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 1.2199\n",
            "Epoch 242/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.8729\n",
            "Epoch 243/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.7138\n",
            "Epoch 244/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0122 - val_loss: 0.5271\n",
            "Epoch 245/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 1.0157\n",
            "Epoch 246/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 1.5733\n",
            "Epoch 247/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0442 - val_loss: 0.7544\n",
            "Epoch 248/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0280 - val_loss: 1.7045\n",
            "Epoch 249/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.8731\n",
            "Epoch 250/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 0.9912\n",
            "Epoch 251/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.6669\n",
            "Epoch 252/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 1.0346\n",
            "Epoch 253/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0380 - val_loss: 0.8214\n",
            "Epoch 254/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 1.1256\n",
            "Epoch 255/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.3667\n",
            "Epoch 256/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 1.1829\n",
            "Epoch 257/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 1.0093\n",
            "Epoch 258/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.4889\n",
            "Epoch 259/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.7572\n",
            "Epoch 260/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0072 - val_loss: 1.0912\n",
            "Epoch 261/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 1.1375\n",
            "Epoch 262/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.9276\n",
            "Epoch 263/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.7529\n",
            "Epoch 264/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.8652\n",
            "Epoch 265/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 1.0355\n",
            "Epoch 266/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 1.3937\n",
            "Epoch 267/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 0.8310\n",
            "Epoch 268/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0107 - val_loss: 0.9887\n",
            "Epoch 269/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.9442\n",
            "Epoch 270/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0126 - val_loss: 1.4672\n",
            "Epoch 271/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.7900\n",
            "Epoch 272/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.6769\n",
            "Epoch 273/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.8128\n",
            "Epoch 274/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0125 - val_loss: 1.0555\n",
            "Epoch 275/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 1.4548\n",
            "Epoch 276/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0167 - val_loss: 0.7635\n",
            "Epoch 277/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.7592\n",
            "Epoch 278/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.7863\n",
            "Epoch 279/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.8019\n",
            "Epoch 280/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.6321\n",
            "Epoch 281/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 0.9790\n",
            "Epoch 282/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 1.0056\n",
            "Epoch 283/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 1.2483\n",
            "Epoch 284/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 1.2434\n",
            "Epoch 285/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 1.1156\n",
            "Epoch 286/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.9347\n",
            "Epoch 287/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.7814\n",
            "Epoch 288/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.6216\n",
            "Epoch 289/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.6148\n",
            "Epoch 290/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0166 - val_loss: 0.5509\n",
            "Epoch 291/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.8104\n",
            "Epoch 292/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 1.0635\n",
            "Epoch 293/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 1.2155\n",
            "Epoch 294/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.7506\n",
            "Epoch 295/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0079 - val_loss: 0.8851\n",
            "Epoch 296/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 0.5671\n",
            "Epoch 297/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0341 - val_loss: 2.4528\n",
            "Epoch 298/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0494 - val_loss: 1.4914\n",
            "Epoch 299/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 1.0622\n",
            "Epoch 300/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0424 - val_loss: 1.3769\n",
            "Epoch 301/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0348 - val_loss: 1.1368\n",
            "Epoch 302/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0382 - val_loss: 1.2859\n",
            "Epoch 303/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.5715\n",
            "Epoch 304/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 1.0471\n",
            "Epoch 305/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 1.1891\n",
            "Epoch 306/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.5981\n",
            "Epoch 307/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 1.0971\n",
            "Epoch 308/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.9397\n",
            "Epoch 309/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.6984\n",
            "Epoch 310/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0251 - val_loss: 1.0596\n",
            "Epoch 311/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 1.0166\n",
            "Epoch 312/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.7255\n",
            "Epoch 313/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.6135\n",
            "Epoch 314/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.8522\n",
            "Epoch 315/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 1.2463\n",
            "Epoch 316/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 1.0610\n",
            "Epoch 317/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.7915\n",
            "Epoch 318/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.6433\n",
            "Epoch 319/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.8574\n",
            "Epoch 320/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.7188\n",
            "Epoch 321/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.8714\n",
            "Epoch 322/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0111 - val_loss: 0.7429\n",
            "Epoch 323/1000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0073 - val_loss: 0.4828\n",
            "Epoch 324/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.7451\n",
            "Epoch 325/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.7227\n",
            "Epoch 326/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.8382\n",
            "Epoch 327/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.6617\n",
            "Epoch 328/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.8775\n",
            "Epoch 329/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 0.7022\n",
            "Epoch 330/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.5061\n",
            "Epoch 331/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.7892\n",
            "Epoch 332/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0161 - val_loss: 0.2536\n",
            "Epoch 333/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0382 - val_loss: 0.4295\n",
            "Epoch 334/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0281 - val_loss: 0.9967\n",
            "Epoch 335/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0300 - val_loss: 1.1449\n",
            "Epoch 336/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0189 - val_loss: 1.0520\n",
            "Epoch 337/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.3642\n",
            "Epoch 338/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.6913\n",
            "Epoch 339/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0280 - val_loss: 1.0316\n",
            "Epoch 340/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0568 - val_loss: 0.5625\n",
            "Epoch 341/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0395 - val_loss: 0.8921\n",
            "Epoch 342/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0117 - val_loss: 0.6168\n",
            "Epoch 343/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0165 - val_loss: 0.7448\n",
            "Epoch 344/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 1.1514\n",
            "Epoch 345/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 1.3384\n",
            "Epoch 346/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.6998\n",
            "Epoch 347/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0136 - val_loss: 0.3568\n",
            "Epoch 348/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.4320\n",
            "Epoch 349/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0246 - val_loss: 1.4404\n",
            "Epoch 350/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0273 - val_loss: 0.5622\n",
            "Epoch 351/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.7684\n",
            "Epoch 352/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.5693\n",
            "Epoch 353/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.6225\n",
            "Epoch 354/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0156 - val_loss: 0.5578\n",
            "Epoch 355/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0223 - val_loss: 1.0810\n",
            "Epoch 356/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 1.9990\n",
            "Epoch 357/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0505 - val_loss: 0.6759\n",
            "Epoch 358/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0415 - val_loss: 1.1998\n",
            "Epoch 359/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0246 - val_loss: 0.7018\n",
            "Epoch 360/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.9484\n",
            "Epoch 361/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.6928\n",
            "Epoch 362/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.6362\n",
            "Epoch 363/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.7999\n",
            "Epoch 364/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.6888\n",
            "Epoch 365/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.7624\n",
            "Epoch 366/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.8673\n",
            "Epoch 367/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0132 - val_loss: 0.7155\n",
            "Epoch 368/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0263 - val_loss: 1.9910\n",
            "Epoch 369/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0614 - val_loss: 0.8065\n",
            "Epoch 370/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 1.0059\n",
            "Epoch 371/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 1.2473\n",
            "Epoch 372/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.7702\n",
            "Epoch 373/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0192 - val_loss: 0.6402\n",
            "Epoch 374/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.8673\n",
            "Epoch 375/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 1.3129\n",
            "Epoch 376/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.6854\n",
            "Epoch 377/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.1594\n",
            "Epoch 378/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0506 - val_loss: 2.3724\n",
            "Epoch 379/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0831 - val_loss: 0.5058\n",
            "Epoch 380/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0830 - val_loss: 1.5638\n",
            "Epoch 381/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0552 - val_loss: 1.9620\n",
            "Epoch 382/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.6308\n",
            "Epoch 383/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0276 - val_loss: 1.5475\n",
            "Epoch 384/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0140 - val_loss: 1.1087\n",
            "Epoch 385/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 1.2510\n",
            "Epoch 386/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.5599\n",
            "Epoch 387/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 1.0679\n",
            "Epoch 388/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.8874\n",
            "Epoch 389/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.8490\n",
            "Epoch 390/1000\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0066 - val_loss: 0.9280\n",
            "Epoch 391/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0063 - val_loss: 1.1307\n",
            "Epoch 392/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.6283\n",
            "Epoch 393/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0147 - val_loss: 0.4415\n",
            "Epoch 394/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0244 - val_loss: 0.9554\n",
            "Epoch 395/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0077 - val_loss: 0.8882\n",
            "Epoch 396/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0126 - val_loss: 0.5874\n",
            "Epoch 397/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 0.7615\n",
            "Epoch 398/1000\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.0143 - val_loss: 1.2734\n",
            "Epoch 399/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0224 - val_loss: 1.7838\n",
            "Epoch 400/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0209 - val_loss: 0.6267\n",
            "Epoch 401/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0326 - val_loss: 0.1829\n",
            "Epoch 402/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0977 - val_loss: 3.4087\n",
            "Epoch 403/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1063 - val_loss: 0.3431\n",
            "Epoch 404/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0397 - val_loss: 0.9606\n",
            "Epoch 405/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0421 - val_loss: 0.7438\n",
            "Epoch 406/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0577 - val_loss: 1.5324\n",
            "Epoch 407/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0478 - val_loss: 1.1467\n",
            "Epoch 408/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.6032\n",
            "Epoch 409/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0209 - val_loss: 0.3233\n",
            "Epoch 410/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0447 - val_loss: 1.3666\n",
            "Epoch 411/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0427 - val_loss: 1.3093\n",
            "Epoch 412/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0186 - val_loss: 1.2139\n",
            "Epoch 413/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0285 - val_loss: 1.1411\n",
            "Epoch 414/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0466 - val_loss: 1.8680\n",
            "Epoch 415/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 1.0826\n",
            "Epoch 416/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0134 - val_loss: 0.8881\n",
            "Epoch 417/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0111 - val_loss: 0.5554\n",
            "Epoch 418/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 1.0528\n",
            "Epoch 419/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0134 - val_loss: 1.8555\n",
            "Epoch 420/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0185 - val_loss: 0.8861\n",
            "Epoch 421/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0070 - val_loss: 1.0053\n",
            "Epoch 422/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.6060\n",
            "Epoch 423/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0283 - val_loss: 0.8336\n",
            "Epoch 424/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 1.0682\n",
            "Epoch 425/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0171 - val_loss: 1.5115\n",
            "Epoch 426/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.5791\n",
            "Epoch 427/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0143 - val_loss: 0.9137\n",
            "Epoch 428/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.7668\n",
            "Epoch 429/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 1.1053\n",
            "Epoch 430/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 1.3729\n",
            "Epoch 431/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.4861\n",
            "Epoch 432/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0137 - val_loss: 0.6202\n",
            "Epoch 433/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.8499\n",
            "Epoch 434/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.6842\n",
            "Epoch 435/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.9213\n",
            "Epoch 436/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.8494\n",
            "Epoch 437/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 1.1411\n",
            "Epoch 438/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0075 - val_loss: 1.3457\n",
            "Epoch 439/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0109 - val_loss: 0.8700\n",
            "Epoch 440/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 1.1111\n",
            "Epoch 441/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0068 - val_loss: 0.7436\n",
            "Epoch 442/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 1.3204\n",
            "Epoch 443/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0151 - val_loss: 0.9133\n",
            "Epoch 444/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 1.1175\n",
            "Epoch 445/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 1.4382\n",
            "Epoch 446/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0187 - val_loss: 0.8012\n",
            "Epoch 447/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0123 - val_loss: 0.4449\n",
            "Epoch 448/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.6848\n",
            "Epoch 449/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.6510\n",
            "Epoch 450/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.5458\n",
            "Epoch 451/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0058 - val_loss: 0.6395\n",
            "Epoch 452/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.8753\n",
            "Epoch 453/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 1.0222\n",
            "Epoch 454/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 1.3151\n",
            "Epoch 455/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 1.2965\n",
            "Epoch 456/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0349 - val_loss: 0.2887\n",
            "Epoch 457/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0737 - val_loss: 1.3200\n",
            "Epoch 458/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0383 - val_loss: 0.7660\n",
            "Epoch 459/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0225 - val_loss: 0.8888\n",
            "Epoch 460/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 1.5142\n",
            "Epoch 461/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 1.0538\n",
            "Epoch 462/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.8608\n",
            "Epoch 463/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.7941\n",
            "Epoch 464/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.6548\n",
            "Epoch 465/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 1.2572\n",
            "Epoch 466/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0183 - val_loss: 1.0142\n",
            "Epoch 467/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0306 - val_loss: 1.3451\n",
            "Epoch 468/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0698 - val_loss: 0.1293\n",
            "Epoch 469/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0730 - val_loss: 1.8641\n",
            "Epoch 470/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0347 - val_loss: 1.0816\n",
            "Epoch 471/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0199 - val_loss: 1.0613\n",
            "Epoch 472/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0311 - val_loss: 0.6167\n",
            "Epoch 473/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0446 - val_loss: 0.1281\n",
            "Epoch 474/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1065 - val_loss: 3.7692\n",
            "Epoch 475/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1258 - val_loss: 0.2277\n",
            "Epoch 476/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1549 - val_loss: 0.1551\n",
            "Epoch 477/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1328 - val_loss: 0.6618\n",
            "Epoch 478/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0876 - val_loss: 2.5184\n",
            "Epoch 479/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0708 - val_loss: 0.2439\n",
            "Epoch 480/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0839 - val_loss: 0.4388\n",
            "Epoch 481/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0406 - val_loss: 0.7521\n",
            "Epoch 482/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0212 - val_loss: 1.1983\n",
            "Epoch 483/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0197 - val_loss: 0.4858\n",
            "Epoch 484/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 1.9865\n",
            "Epoch 485/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 1.1466\n",
            "Epoch 486/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.8599\n",
            "Epoch 487/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0189 - val_loss: 1.2179\n",
            "Epoch 488/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.6660\n",
            "Epoch 489/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.8176\n",
            "Epoch 490/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 1.0580\n",
            "Epoch 491/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0449 - val_loss: 1.5381\n",
            "Epoch 492/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0149 - val_loss: 2.3858\n",
            "Epoch 493/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 0.6265\n",
            "Epoch 494/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.5930\n",
            "Epoch 495/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 1.0471\n",
            "Epoch 496/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.7046\n",
            "Epoch 497/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 1.0772\n",
            "Epoch 498/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.7712\n",
            "Epoch 499/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0150 - val_loss: 0.5121\n",
            "Epoch 500/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.8926\n",
            "Epoch 501/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 0.6230\n",
            "Epoch 502/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 1.1406\n",
            "Epoch 503/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 1.2677\n",
            "Epoch 504/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.7848\n",
            "Epoch 505/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 0.5152\n",
            "Epoch 506/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.9226\n",
            "Epoch 507/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.4461\n",
            "Epoch 508/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.7614\n",
            "Epoch 509/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 1.2571\n",
            "Epoch 510/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.8085\n",
            "Epoch 511/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 0.9579\n",
            "Epoch 512/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.3465\n",
            "Epoch 513/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0143 - val_loss: 0.3760\n",
            "Epoch 514/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 1.1734\n",
            "Epoch 515/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 1.4716\n",
            "Epoch 516/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0159 - val_loss: 0.3449\n",
            "Epoch 517/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0691 - val_loss: 2.6508\n",
            "Epoch 518/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0635 - val_loss: 1.2750\n",
            "Epoch 519/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.4716\n",
            "Epoch 520/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0227 - val_loss: 0.8222\n",
            "Epoch 521/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 1.2656\n",
            "Epoch 522/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0326 - val_loss: 0.8243\n",
            "Epoch 523/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0285 - val_loss: 2.0260\n",
            "Epoch 524/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0171 - val_loss: 0.8236\n",
            "Epoch 525/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 0.7405\n",
            "Epoch 526/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0128 - val_loss: 0.8097\n",
            "Epoch 527/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 1.3890\n",
            "Epoch 528/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0152 - val_loss: 0.5847\n",
            "Epoch 529/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0135 - val_loss: 1.0929\n",
            "Epoch 530/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.4471\n",
            "Epoch 531/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 1.2762\n",
            "Epoch 532/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0166 - val_loss: 0.8036\n",
            "Epoch 533/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0129 - val_loss: 0.6109\n",
            "Epoch 534/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 1.1348\n",
            "Epoch 535/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.7068\n",
            "Epoch 536/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0073 - val_loss: 0.3742\n",
            "Epoch 537/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0107 - val_loss: 1.2809\n",
            "Epoch 538/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 1.0322\n",
            "Epoch 539/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0134 - val_loss: 0.3727\n",
            "Epoch 540/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0145 - val_loss: 1.1936\n",
            "Epoch 541/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0207 - val_loss: 0.7156\n",
            "Epoch 542/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0178 - val_loss: 0.3108\n",
            "Epoch 543/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0193 - val_loss: 0.6345\n",
            "Epoch 544/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 1.0855\n",
            "Epoch 545/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 0.6147\n",
            "Epoch 546/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.7345\n",
            "Epoch 547/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0147 - val_loss: 0.2292\n",
            "Epoch 548/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 1.2802\n",
            "Epoch 549/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.3734\n",
            "Epoch 550/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.7464\n",
            "Epoch 551/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0071 - val_loss: 0.3533\n",
            "Epoch 552/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.2817\n",
            "Epoch 553/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.2871\n",
            "Epoch 554/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 0.3446\n",
            "Epoch 555/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.5052\n",
            "Epoch 556/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0178 - val_loss: 0.6217\n",
            "Epoch 557/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0196 - val_loss: 0.8423\n",
            "Epoch 558/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0136 - val_loss: 0.5310\n",
            "Epoch 559/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.4511\n",
            "Epoch 560/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.2979\n",
            "Epoch 561/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0061 - val_loss: 0.5482\n",
            "Epoch 562/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.9258\n",
            "Epoch 563/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.3701\n",
            "Epoch 564/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.5475\n",
            "Epoch 565/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.6800\n",
            "Epoch 566/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0127 - val_loss: 0.7913\n",
            "Epoch 567/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.6256\n",
            "Epoch 568/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.6072\n",
            "Epoch 569/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.6733\n",
            "Epoch 570/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.3095\n",
            "Epoch 571/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0065 - val_loss: 0.5544\n",
            "Epoch 572/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 1.2598\n",
            "Epoch 573/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.6935\n",
            "Epoch 574/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.4688\n",
            "Epoch 575/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.5785\n",
            "Epoch 576/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.2614\n",
            "Epoch 577/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.3780\n",
            "Epoch 578/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.3871\n",
            "Epoch 579/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.6364\n",
            "Epoch 580/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.3460\n",
            "Epoch 581/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0415 - val_loss: 1.0762\n",
            "Epoch 582/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1074 - val_loss: 0.4321\n",
            "Epoch 583/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1474 - val_loss: 2.9806\n",
            "Epoch 584/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2369 - val_loss: 0.1942\n",
            "Epoch 585/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1154 - val_loss: 0.1061\n",
            "Epoch 586/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0519 - val_loss: 1.1754\n",
            "Epoch 587/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0318 - val_loss: 1.3786\n",
            "Epoch 588/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0507 - val_loss: 0.3607\n",
            "Epoch 589/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0466 - val_loss: 0.4221\n",
            "Epoch 590/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0364 - val_loss: 1.3124\n",
            "Epoch 591/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 1.0883\n",
            "Epoch 592/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.9584\n",
            "Epoch 593/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0298 - val_loss: 0.5497\n",
            "Epoch 594/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0425 - val_loss: 1.2327\n",
            "Epoch 595/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0258 - val_loss: 1.3658\n",
            "Epoch 596/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 1.0045\n",
            "Epoch 597/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0200 - val_loss: 2.1510\n",
            "Epoch 598/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 0.9477\n",
            "Epoch 599/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0223 - val_loss: 0.7606\n",
            "Epoch 600/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0385 - val_loss: 1.4779\n",
            "Epoch 601/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0298 - val_loss: 0.2508\n",
            "Epoch 602/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0352 - val_loss: 0.5955\n",
            "Epoch 603/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 1.2456\n",
            "Epoch 604/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0162 - val_loss: 0.4504\n",
            "Epoch 605/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0149 - val_loss: 0.6526\n",
            "Epoch 606/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.6491\n",
            "Epoch 607/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0334 - val_loss: 0.2256\n",
            "Epoch 608/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0298 - val_loss: 0.6813\n",
            "Epoch 609/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0147 - val_loss: 0.5778\n",
            "Epoch 610/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.2990\n",
            "Epoch 611/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.6642\n",
            "Epoch 612/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.6380\n",
            "Epoch 613/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.6071\n",
            "Epoch 614/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.4951\n",
            "Epoch 615/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.7833\n",
            "Epoch 616/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.4211\n",
            "Epoch 617/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0110 - val_loss: 0.9799\n",
            "Epoch 618/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.3423\n",
            "Epoch 619/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.4959\n",
            "Epoch 620/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 0.4190\n",
            "Epoch 621/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.6647\n",
            "Epoch 622/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.5139\n",
            "Epoch 623/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 0.8296\n",
            "Epoch 624/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.4281\n",
            "Epoch 625/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.4200\n",
            "Epoch 626/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.7187\n",
            "Epoch 627/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0067 - val_loss: 0.5739\n",
            "Epoch 628/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.3918\n",
            "Epoch 629/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.7986\n",
            "Epoch 630/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0068 - val_loss: 0.3152\n",
            "Epoch 631/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.4667\n",
            "Epoch 632/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.6111\n",
            "Epoch 633/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.5060\n",
            "Epoch 634/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.4297\n",
            "Epoch 635/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0137 - val_loss: 1.3977\n",
            "Epoch 636/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0229 - val_loss: 0.0999\n",
            "Epoch 637/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0249 - val_loss: 1.1392\n",
            "Epoch 638/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0207 - val_loss: 0.4075\n",
            "Epoch 639/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.6387\n",
            "Epoch 640/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.3373\n",
            "Epoch 641/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.8040\n",
            "Epoch 642/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 0.3535\n",
            "Epoch 643/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.7976\n",
            "Epoch 644/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.6460\n",
            "Epoch 645/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.6272\n",
            "Epoch 646/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 1.0518\n",
            "Epoch 647/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.5277\n",
            "Epoch 648/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.4838\n",
            "Epoch 649/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.6870\n",
            "Epoch 650/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.2195\n",
            "Epoch 651/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0105 - val_loss: 0.8621\n",
            "Epoch 652/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0163 - val_loss: 0.3041\n",
            "Epoch 653/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.8996\n",
            "Epoch 654/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0179 - val_loss: 0.8044\n",
            "Epoch 655/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0381 - val_loss: 0.9587\n",
            "Epoch 656/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0541 - val_loss: 0.2262\n",
            "Epoch 657/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0288 - val_loss: 0.9628\n",
            "Epoch 658/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 0.3244\n",
            "Epoch 659/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0142 - val_loss: 0.1531\n",
            "Epoch 660/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.2661\n",
            "Epoch 661/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.1341\n",
            "Epoch 662/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0270 - val_loss: 0.6531\n",
            "Epoch 663/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0189 - val_loss: 0.3190\n",
            "Epoch 664/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0429 - val_loss: 1.8964\n",
            "Epoch 665/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1103 - val_loss: 0.5753\n",
            "Epoch 666/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0924 - val_loss: 0.1955\n",
            "Epoch 667/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0975 - val_loss: 0.1870\n",
            "Epoch 668/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0475 - val_loss: 0.9557\n",
            "Epoch 669/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0262 - val_loss: 0.8616\n",
            "Epoch 670/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0299 - val_loss: 0.3328\n",
            "Epoch 671/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0393 - val_loss: 0.6886\n",
            "Epoch 672/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 1.0653\n",
            "Epoch 673/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0203 - val_loss: 0.1440\n",
            "Epoch 674/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.3953\n",
            "Epoch 675/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0057 - val_loss: 0.7094\n",
            "Epoch 676/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.5724\n",
            "Epoch 677/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.3547\n",
            "Epoch 678/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.4213\n",
            "Epoch 679/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.7210\n",
            "Epoch 680/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.6078\n",
            "Epoch 681/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.1615\n",
            "Epoch 682/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0189 - val_loss: 0.7645\n",
            "Epoch 683/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.3384\n",
            "Epoch 684/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.6090\n",
            "Epoch 685/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.3165\n",
            "Epoch 686/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.5195\n",
            "Epoch 687/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0064 - val_loss: 0.4793\n",
            "Epoch 688/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.4276\n",
            "Epoch 689/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.2543\n",
            "Epoch 690/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.3982\n",
            "Epoch 691/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.3772\n",
            "Epoch 692/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.4270\n",
            "Epoch 693/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.5091\n",
            "Epoch 694/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.2680\n",
            "Epoch 695/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.4603\n",
            "Epoch 696/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.4281\n",
            "Epoch 697/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.2947\n",
            "Epoch 698/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.2915\n",
            "Epoch 699/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0074 - val_loss: 0.6263\n",
            "Epoch 700/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.6955\n",
            "Epoch 701/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.1363\n",
            "Epoch 702/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.4775\n",
            "Epoch 703/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.3893\n",
            "Epoch 704/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.7836\n",
            "Epoch 705/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.3558\n",
            "Epoch 706/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.4687\n",
            "Epoch 707/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.3154\n",
            "Epoch 708/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.2060\n",
            "Epoch 709/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.6123\n",
            "Epoch 710/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.4440\n",
            "Epoch 711/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.2855\n",
            "Epoch 712/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0253 - val_loss: 0.6300\n",
            "Epoch 713/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0187 - val_loss: 1.0974\n",
            "Epoch 714/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0447 - val_loss: 0.4200\n",
            "Epoch 715/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0521 - val_loss: 1.1231\n",
            "Epoch 716/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0297 - val_loss: 0.5815\n",
            "Epoch 717/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.4924\n",
            "Epoch 718/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0069 - val_loss: 0.4617\n",
            "Epoch 719/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.3417\n",
            "Epoch 720/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.4573\n",
            "Epoch 721/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.2747\n",
            "Epoch 722/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.1589\n",
            "Epoch 723/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.3817\n",
            "Epoch 724/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.2188\n",
            "Epoch 725/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0082 - val_loss: 0.2245\n",
            "Epoch 726/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.8596\n",
            "Epoch 727/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0076 - val_loss: 0.3877\n",
            "Epoch 728/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.5442\n",
            "Epoch 729/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.4781\n",
            "Epoch 730/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.2950\n",
            "Epoch 731/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.3167\n",
            "Epoch 732/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 1.0034\n",
            "Epoch 733/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0150 - val_loss: 0.4889\n",
            "Epoch 734/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.5472\n",
            "Epoch 735/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.5895\n",
            "Epoch 736/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.3766\n",
            "Epoch 737/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0033 - val_loss: 0.3745\n",
            "Epoch 738/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.5351\n",
            "Epoch 739/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.5064\n",
            "Epoch 740/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.4516\n",
            "Epoch 741/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.3829\n",
            "Epoch 742/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 0.1197\n",
            "Epoch 743/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.4581\n",
            "Epoch 744/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0108 - val_loss: 0.1109\n",
            "Epoch 745/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0174 - val_loss: 0.2818\n",
            "Epoch 746/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.6516\n",
            "Epoch 747/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 0.2262\n",
            "Epoch 748/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0212 - val_loss: 0.9885\n",
            "Epoch 749/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0317 - val_loss: 0.7341\n",
            "Epoch 750/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.6398\n",
            "Epoch 751/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 0.0733\n",
            "Epoch 752/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0250 - val_loss: 0.1367\n",
            "Epoch 753/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.5315\n",
            "Epoch 754/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.2049\n",
            "Epoch 755/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0168 - val_loss: 0.8367\n",
            "Epoch 756/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0241 - val_loss: 0.3237\n",
            "Epoch 757/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0139 - val_loss: 0.8032\n",
            "Epoch 758/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0118 - val_loss: 0.3338\n",
            "Epoch 759/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.6516\n",
            "Epoch 760/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0236 - val_loss: 0.1259\n",
            "Epoch 761/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0138 - val_loss: 1.0717\n",
            "Epoch 762/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0284 - val_loss: 0.4856\n",
            "Epoch 763/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0181 - val_loss: 0.5128\n",
            "Epoch 764/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0147 - val_loss: 0.4119\n",
            "Epoch 765/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0083 - val_loss: 0.4993\n",
            "Epoch 766/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.2808\n",
            "Epoch 767/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.5738\n",
            "Epoch 768/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.1978\n",
            "Epoch 769/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0106 - val_loss: 0.2387\n",
            "Epoch 770/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.5784\n",
            "Epoch 771/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.4204\n",
            "Epoch 772/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.2183\n",
            "Epoch 773/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 0.2739\n",
            "Epoch 774/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 0.5559\n",
            "Epoch 775/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.5397\n",
            "Epoch 776/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0273 - val_loss: 0.5125\n",
            "Epoch 777/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0257 - val_loss: 0.7172\n",
            "Epoch 778/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0278 - val_loss: 0.9639\n",
            "Epoch 779/1000\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.0709 - val_loss: 1.9822\n",
            "Epoch 780/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0530 - val_loss: 0.4209\n",
            "Epoch 781/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0501 - val_loss: 0.1515\n",
            "Epoch 782/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1486 - val_loss: 1.6215\n",
            "Epoch 783/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1082 - val_loss: 1.1007\n",
            "Epoch 784/1000\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.0831 - val_loss: 0.7220\n",
            "Epoch 785/1000\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0576 - val_loss: 0.5493\n",
            "Epoch 786/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0599 - val_loss: 2.5587\n",
            "Epoch 787/1000\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0640 - val_loss: 2.6192\n",
            "Epoch 788/1000\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0534 - val_loss: 0.5783\n",
            "Epoch 789/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 1.0249\n",
            "Epoch 790/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.5283\n",
            "Epoch 791/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 0.3041\n",
            "Epoch 792/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.4258\n",
            "Epoch 793/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 0.9000\n",
            "Epoch 794/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.2561\n",
            "Epoch 795/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.4543\n",
            "Epoch 796/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.6761\n",
            "Epoch 797/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.5230\n",
            "Epoch 798/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 0.4002\n",
            "Epoch 799/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0129 - val_loss: 0.6273\n",
            "Epoch 800/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0060 - val_loss: 0.3602\n",
            "Epoch 801/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.2038\n",
            "Epoch 802/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.7371\n",
            "Epoch 803/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.4538\n",
            "Epoch 804/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.3848\n",
            "Epoch 805/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.2802\n",
            "Epoch 806/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0118 - val_loss: 0.3207\n",
            "Epoch 807/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.8418\n",
            "Epoch 808/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.7187\n",
            "Epoch 809/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.2433\n",
            "Epoch 810/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0077 - val_loss: 0.2448\n",
            "Epoch 811/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0130 - val_loss: 0.6669\n",
            "Epoch 812/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.3814\n",
            "Epoch 813/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.3253\n",
            "Epoch 814/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.3226\n",
            "Epoch 815/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.4345\n",
            "Epoch 816/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 0.9042\n",
            "Epoch 817/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0293 - val_loss: 0.2171\n",
            "Epoch 818/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0327 - val_loss: 0.0922\n",
            "Epoch 819/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0384 - val_loss: 1.6070\n",
            "Epoch 820/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0338 - val_loss: 0.9319\n",
            "Epoch 821/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0151 - val_loss: 0.2194\n",
            "Epoch 822/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.7182\n",
            "Epoch 823/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.4493\n",
            "Epoch 824/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0049 - val_loss: 0.5979\n",
            "Epoch 825/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.4613\n",
            "Epoch 826/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.2464\n",
            "Epoch 827/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.2843\n",
            "Epoch 828/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.4280\n",
            "Epoch 829/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.2239\n",
            "Epoch 830/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.3064\n",
            "Epoch 831/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.1983\n",
            "Epoch 832/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0062 - val_loss: 0.2551\n",
            "Epoch 833/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0041 - val_loss: 0.3863\n",
            "Epoch 834/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.3325\n",
            "Epoch 835/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.2223\n",
            "Epoch 836/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.5385\n",
            "Epoch 837/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.3285\n",
            "Epoch 838/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0042 - val_loss: 0.3183\n",
            "Epoch 839/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.4184\n",
            "Epoch 840/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.3216\n",
            "Epoch 841/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0056 - val_loss: 0.3250\n",
            "Epoch 842/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.8406\n",
            "Epoch 843/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.6276\n",
            "Epoch 844/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.4473\n",
            "Epoch 845/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 0.3061\n",
            "Epoch 846/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0182 - val_loss: 0.8081\n",
            "Epoch 847/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0155 - val_loss: 0.6302\n",
            "Epoch 848/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0184 - val_loss: 0.3716\n",
            "Epoch 849/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0249 - val_loss: 0.2946\n",
            "Epoch 850/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0267 - val_loss: 1.3309\n",
            "Epoch 851/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.5887\n",
            "Epoch 852/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.5398\n",
            "Epoch 853/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 0.2107\n",
            "Epoch 854/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.5395\n",
            "Epoch 855/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0238 - val_loss: 0.1111\n",
            "Epoch 856/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0147 - val_loss: 0.6456\n",
            "Epoch 857/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0155 - val_loss: 0.2094\n",
            "Epoch 858/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0204 - val_loss: 0.3509\n",
            "Epoch 859/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.5079\n",
            "Epoch 860/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.5143\n",
            "Epoch 861/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.3517\n",
            "Epoch 862/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.1122\n",
            "Epoch 863/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.4042\n",
            "Epoch 864/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.4017\n",
            "Epoch 865/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.3464\n",
            "Epoch 866/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.2696\n",
            "Epoch 867/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.2868\n",
            "Epoch 868/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.2551\n",
            "Epoch 869/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.4050\n",
            "Epoch 870/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.0919\n",
            "Epoch 871/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.6264\n",
            "Epoch 872/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.2035\n",
            "Epoch 873/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.2281\n",
            "Epoch 874/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.5042\n",
            "Epoch 875/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.4228\n",
            "Epoch 876/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0058 - val_loss: 0.1543\n",
            "Epoch 877/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.3185\n",
            "Epoch 878/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.4412\n",
            "Epoch 879/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0816\n",
            "Epoch 880/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.4760\n",
            "Epoch 881/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.4062\n",
            "Epoch 882/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 0.2481\n",
            "Epoch 883/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 0.2389\n",
            "Epoch 884/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.2444\n",
            "Epoch 885/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.5748\n",
            "Epoch 886/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.3579\n",
            "Epoch 887/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0154 - val_loss: 0.0742\n",
            "Epoch 888/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.6789\n",
            "Epoch 889/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.4304\n",
            "Epoch 890/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.1961\n",
            "Epoch 891/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0175 - val_loss: 0.7943\n",
            "Epoch 892/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.1499\n",
            "Epoch 893/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0135 - val_loss: 1.1798\n",
            "Epoch 894/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0175 - val_loss: 0.1606\n",
            "Epoch 895/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0156 - val_loss: 0.1840\n",
            "Epoch 896/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.2644\n",
            "Epoch 897/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 1.1048\n",
            "Epoch 898/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0554 - val_loss: 0.4204\n",
            "Epoch 899/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 0.2657\n",
            "Epoch 900/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0043 - val_loss: 0.3431\n",
            "Epoch 901/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.1462\n",
            "Epoch 902/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.1144\n",
            "Epoch 903/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0067 - val_loss: 0.3201\n",
            "Epoch 904/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.1113\n",
            "Epoch 905/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 1.1034\n",
            "Epoch 906/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0168 - val_loss: 0.2572\n",
            "Epoch 907/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.5328\n",
            "Epoch 908/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.1636\n",
            "Epoch 909/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.3421\n",
            "Epoch 910/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.2631\n",
            "Epoch 911/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.3635\n",
            "Epoch 912/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.1358\n",
            "Epoch 913/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.7278\n",
            "Epoch 914/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0226 - val_loss: 0.2015\n",
            "Epoch 915/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0173 - val_loss: 0.4122\n",
            "Epoch 916/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.2651\n",
            "Epoch 917/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 0.4780\n",
            "Epoch 918/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.1263\n",
            "Epoch 919/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0116 - val_loss: 0.8483\n",
            "Epoch 920/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0223 - val_loss: 0.3804\n",
            "Epoch 921/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 0.7614\n",
            "Epoch 922/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.5169\n",
            "Epoch 923/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0055 - val_loss: 0.3562\n",
            "Epoch 924/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.2287\n",
            "Epoch 925/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.3482\n",
            "Epoch 926/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0819\n",
            "Epoch 927/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 1.1420\n",
            "Epoch 928/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0370 - val_loss: 0.1315\n",
            "Epoch 929/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.2557\n",
            "Epoch 930/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0322 - val_loss: 0.6628\n",
            "Epoch 931/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 0.0786\n",
            "Epoch 932/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 1.4396\n",
            "Epoch 933/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0414 - val_loss: 0.4516\n",
            "Epoch 934/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.2248\n",
            "Epoch 935/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.6278\n",
            "Epoch 936/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.2771\n",
            "Epoch 937/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.1380\n",
            "Epoch 938/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 0.8113\n",
            "Epoch 939/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0141 - val_loss: 0.0946\n",
            "Epoch 940/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 0.9753\n",
            "Epoch 941/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0550 - val_loss: 0.2326\n",
            "Epoch 942/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0445 - val_loss: 0.0866\n",
            "Epoch 943/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0446 - val_loss: 0.5607\n",
            "Epoch 944/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.3450\n",
            "Epoch 945/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0721\n",
            "Epoch 946/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 0.4441\n",
            "Epoch 947/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 0.6897\n",
            "Epoch 948/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0071 - val_loss: 0.3163\n",
            "Epoch 949/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0753\n",
            "Epoch 950/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 0.3545\n",
            "Epoch 951/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 0.3849\n",
            "Epoch 952/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 0.0712\n",
            "Epoch 953/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0103 - val_loss: 0.4081\n",
            "Epoch 954/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.3123\n",
            "Epoch 955/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.1709\n",
            "Epoch 956/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.1463\n",
            "Epoch 957/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.7775\n",
            "Epoch 958/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0087 - val_loss: 0.2152\n",
            "Epoch 959/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.3318\n",
            "Epoch 960/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.3289\n",
            "Epoch 961/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.2681\n",
            "Epoch 962/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.5521\n",
            "Epoch 963/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.2374\n",
            "Epoch 964/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.5291\n",
            "Epoch 965/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.2972\n",
            "Epoch 966/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.1594\n",
            "Epoch 967/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0078 - val_loss: 0.4907\n",
            "Epoch 968/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.2122\n",
            "Epoch 969/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.5947\n",
            "Epoch 970/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0736\n",
            "Epoch 971/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 0.3045\n",
            "Epoch 972/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.1641\n",
            "Epoch 973/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.5438\n",
            "Epoch 974/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.1762\n",
            "Epoch 975/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.4471\n",
            "Epoch 976/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.4806\n",
            "Epoch 977/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.3702\n",
            "Epoch 978/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.1745\n",
            "Epoch 979/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0120 - val_loss: 0.8241\n",
            "Epoch 980/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0738\n",
            "Epoch 981/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0464 - val_loss: 0.6154\n",
            "Epoch 982/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0346 - val_loss: 0.2886\n",
            "Epoch 983/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 1.8065\n",
            "Epoch 984/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0553 - val_loss: 0.4313\n",
            "Epoch 985/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1525 - val_loss: 1.1525\n",
            "Epoch 986/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0948 - val_loss: 0.3030\n",
            "Epoch 987/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0821 - val_loss: 1.2008\n",
            "Epoch 988/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1366 - val_loss: 1.2873\n",
            "Epoch 989/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0449 - val_loss: 1.7872\n",
            "Epoch 990/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1323 - val_loss: 0.9654\n",
            "Epoch 991/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1466 - val_loss: 2.3685\n",
            "Epoch 992/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1140 - val_loss: 2.0834\n",
            "Epoch 993/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0436 - val_loss: 1.3254\n",
            "Epoch 994/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0312 - val_loss: 0.8195\n",
            "Epoch 995/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0459 - val_loss: 0.3619\n",
            "Epoch 996/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0380 - val_loss: 1.3671\n",
            "Epoch 997/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0230 - val_loss: 0.4737\n",
            "Epoch 998/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0122 - val_loss: 0.4236\n",
            "Epoch 999/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.1691\n",
            "Epoch 1000/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.5841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(X_test).flatten()\n",
        "print(X_test)\n",
        "print(test_predictions)\n",
        "test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test})\n",
        "test_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17359
        },
        "id": "QDgQzgCEFs_H",
        "outputId": "e3f95209-b111-4006-baec-c8e8f1e2d77d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step\n",
            "[[[-52.94254394]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.81489992]]\n",
            "\n",
            " [[-52.88708726]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.51608985]]\n",
            "\n",
            " [[-52.60044764]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.29292731]]\n",
            "\n",
            " [[-52.33492506]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.23353711]]\n",
            "\n",
            " [[-52.24231336]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.04834217]]\n",
            "\n",
            " [[-52.13477904]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.76476912]]\n",
            "\n",
            " [[-51.86362927]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.39765302]]\n",
            "\n",
            " [[-51.50380818]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-50.95934366]]\n",
            "\n",
            " [[-51.12406141]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.52028511]]\n",
            "\n",
            " [[-50.63190611]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.32102036]]\n",
            "\n",
            " [[-50.39314855]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.17800432]]\n",
            "\n",
            " [[-50.21361806]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.23953497]]\n",
            "\n",
            " [[-50.19222253]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.31435931]]\n",
            "\n",
            " [[-50.30050696]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.35472481]]\n",
            "\n",
            " [[-50.31407465]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.46116092]]\n",
            "\n",
            " [[-50.4557992 ]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.47873973]]\n",
            "\n",
            " [[-50.44526228]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.57181662]]\n",
            "\n",
            " [[-50.51426964]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.56639203]]\n",
            "\n",
            " [[-50.59594105]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.5904813 ]]\n",
            "\n",
            " [[-50.59259916]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.58215956]]\n",
            "\n",
            " [[-50.61262053]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.49779211]]\n",
            "\n",
            " [[-50.55190157]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.45489693]]\n",
            "\n",
            " [[-50.47799735]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.3418331 ]]\n",
            "\n",
            " [[-50.38692228]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32314603]]\n",
            "\n",
            " [[-50.3386263 ]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.12666277]]\n",
            "\n",
            " [[-50.21551764]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-49.88563774]]\n",
            "\n",
            " [[-49.98825503]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.65983005]]\n",
            "\n",
            " [[-49.72168448]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.49126724]]\n",
            "\n",
            " [[-49.57107513]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.12791664]]\n",
            "\n",
            " [[-49.268317  ]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-48.84778164]]\n",
            "\n",
            " [[-48.9450186 ]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.49057878]]\n",
            "\n",
            " [[-48.59411711]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.16485851]]\n",
            "\n",
            " [[-48.2762883 ]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-47.72166797]]\n",
            "\n",
            " [[-47.88634427]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.23339338]]\n",
            "\n",
            " [[-47.39570791]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-46.70607824]]\n",
            "\n",
            " [[-46.8635764 ]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.42456394]]\n",
            "\n",
            " [[-46.48813738]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.11208461]]\n",
            "\n",
            " [[-46.23522767]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.64289674]]\n",
            "\n",
            " [[-45.81482812]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.13680959]]\n",
            "\n",
            " [[-45.30442265]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.55207459]]\n",
            "\n",
            " [[-44.75972774]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-43.99737766]]\n",
            "\n",
            " [[-44.14849027]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.45866853]]\n",
            "\n",
            " [[-43.6515354 ]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.07369114]]\n",
            "\n",
            " [[-43.17138003]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-42.85558873]]\n",
            "\n",
            " [[-42.91604475]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82949152]]\n",
            "\n",
            " [[-42.81357566]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.8698309 ]]\n",
            "\n",
            " [[-42.88137509]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.74973605]]\n",
            "\n",
            " [[-42.77928676]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.67308156]]\n",
            "\n",
            " [[-42.67324626]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.53682594]]\n",
            "\n",
            " [[-42.60346389]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.36059734]]\n",
            "\n",
            " [[-42.3924243 ]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.27284582]]\n",
            "\n",
            " [[-42.32421582]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.00182017]]\n",
            "\n",
            " [[-42.11042659]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.66737955]]\n",
            "\n",
            " [[-41.78064636]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.23345086]]\n",
            "\n",
            " [[-41.39278482]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-40.93530953]]\n",
            "\n",
            " [[-41.00623524]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.74268538]]\n",
            "\n",
            " [[-40.82633027]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.64921066]]\n",
            "\n",
            " [[-40.65543448]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.50099505]]\n",
            "\n",
            " [[-40.57066117]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.31654622]]\n",
            "\n",
            " [[-40.35168421]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.09229517]]\n",
            "\n",
            " [[-40.18562754]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.75803577]]\n",
            "\n",
            " [[-39.85548689]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.49426632]]\n",
            "\n",
            " [[-39.59978385]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.16956091]]\n",
            "\n",
            " [[-39.27949443]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.00183798]]\n",
            "\n",
            " [[-39.03210104]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.79286547]]\n",
            "\n",
            " [[-38.88101188]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.55408711]]\n",
            "\n",
            " [[-38.65149641]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.16758928]]\n",
            "\n",
            " [[-38.31115667]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-37.70150032]]\n",
            "\n",
            " [[-37.84072128]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.2052172 ]]\n",
            "\n",
            " [[-37.38292544]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-36.64899535]]\n",
            "\n",
            " [[-36.81672447]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.19671571]]\n",
            "\n",
            " [[-36.36037863]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-35.67888299]]\n",
            "\n",
            " [[-35.8345917 ]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.25887846]]\n",
            "\n",
            " [[-35.41219674]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-34.92584627]]\n",
            "\n",
            " [[-35.03800122]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.50543465]]\n",
            "\n",
            " [[-34.65870424]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.09199801]]\n",
            "\n",
            " [[-34.2429866 ]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.56928687]]\n",
            "\n",
            " [[-33.7544275 ]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.03429144]]\n",
            "\n",
            " [[-33.20978726]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.4874653 ]]\n",
            "\n",
            " [[-32.6525533 ]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.04235085]]\n",
            "\n",
            " [[-32.20283678]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.53634936]]\n",
            "\n",
            " [[-31.68863635]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.01312605]]\n",
            "\n",
            " [[-31.19791608]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.59185077]]\n",
            "\n",
            " [[-30.73142468]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.1035144 ]]\n",
            "\n",
            " [[-30.27719051]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.52474784]]\n",
            "\n",
            " [[-29.72670125]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-28.8711147 ]]\n",
            "\n",
            " [[-29.09645822]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.15566643]]\n",
            "\n",
            " [[-28.40030288]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.4272172 ]]\n",
            "\n",
            " [[-27.64983596]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-26.79385472]]\n",
            "\n",
            " [[-26.99990222]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.16934236]]\n",
            "\n",
            " [[-26.35927849]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-25.65763892]]\n",
            "\n",
            " [[-25.8379374 ]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.245207  ]]\n",
            "\n",
            " [[-25.38169345]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-24.84318559]]\n",
            "\n",
            " [[-24.97637812]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.48777984]]\n",
            "\n",
            " [[-24.5804586 ]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.13010756]]\n",
            "\n",
            " [[-24.2618252 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.74114588]]]\n",
            "[-52.952736 -52.63546  -52.42096  -52.372887 -52.168755 -51.874584\n",
            " -51.490036 -51.03327  -50.59461  -50.418407 -50.276978 -50.370453\n",
            " -50.446854 -50.48505  -50.593254 -50.607784 -50.711437 -50.686413\n",
            " -50.71917  -50.70132  -50.60642  -50.57352  -50.450848 -50.443142\n",
            " -50.216793 -49.9661   -49.740948 -49.575615 -49.18214  -48.91463\n",
            " -48.538006 -48.21696  -47.74468  -47.24969  -46.703457 -46.462006\n",
            " -46.133987 -45.634094 -45.123257 -44.510384 -43.961773 -43.411446\n",
            " -43.057392 -42.8594   -42.878063 -42.92447  -42.77162  -42.7114\n",
            " -42.555485 -42.37746  -42.2986   -41.990005 -41.649506 -41.182804\n",
            " -40.916775 -40.736988 -40.6709   -40.503555 -40.317585 -40.07618\n",
            " -39.713795 -39.46561  -39.13616  -38.99904  -38.772953 -38.52593\n",
            " -38.10418  -37.614243 -37.111195 -36.534695 -36.108383 -35.565144\n",
            " -35.16931  -34.866764 -34.40865  -33.99293  -33.436466 -32.90421\n",
            " -32.33199  -31.916525 -31.384014 -30.858255 -30.475471 -29.95428\n",
            " -29.3463   -28.668022 -27.932135 -27.188303 -26.596579 -25.952677\n",
            " -25.48183  -25.10948  -24.710217 -24.360943 -24.001583 -23.609732]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Test Predictions    Actuals\n",
              "0         -52.952736 -52.718817\n",
              "1         -52.635460 -52.408805\n",
              "2         -52.420959 -52.281384\n",
              "3         -52.372887 -52.197083\n",
              "4         -52.168755 -51.939383\n",
              "..               ...        ...\n",
              "91        -25.109480 -25.097316\n",
              "92        -24.710217 -24.698456\n",
              "93        -24.360943 -24.381302\n",
              "94        -24.001583 -23.986863\n",
              "95        -23.609732 -23.986863\n",
              "\n",
              "[96 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbbbdf2d-11b3-4267-812e-9ce497aa70b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Predictions</th>\n",
              "      <th>Actuals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-52.952736</td>\n",
              "      <td>-52.718817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-52.635460</td>\n",
              "      <td>-52.408805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-52.420959</td>\n",
              "      <td>-52.281384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-52.372887</td>\n",
              "      <td>-52.197083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-52.168755</td>\n",
              "      <td>-51.939383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>-25.109480</td>\n",
              "      <td>-25.097316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>-24.710217</td>\n",
              "      <td>-24.698456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>-24.360943</td>\n",
              "      <td>-24.381302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>-24.001583</td>\n",
              "      <td>-23.986863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>-23.609732</td>\n",
              "      <td>-23.986863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbbbdf2d-11b3-4267-812e-9ce497aa70b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bbbbdf2d-11b3-4267-812e-9ce497aa70b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bbbbdf2d-11b3-4267-812e-9ce497aa70b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7eb7183-df4b-4c0a-9492-5b14633a0c4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7eb7183-df4b-4c0a-9492-5b14633a0c4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7eb7183-df4b-4c0a-9492-5b14633a0c4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_35a61410-6979-4560-9eb3-43cbbfcb8a04\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_35a61410-6979-4560-9eb3-43cbbfcb8a04 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_results",
              "summary": "{\n  \"name\": \"test_results\",\n  \"rows\": 96,\n  \"fields\": [\n    {\n      \"column\": \"Test Predictions\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          -31.384014129638672,\n          -32.90420913696289,\n          -34.866764068603516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actuals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.490652520995768,\n        \"min\": -52.71881690914811,\n        \"max\": -23.986862897951863,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          -37.01624714653313,\n          -50.3261774912853,\n          -35.134646999199404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_results['Test Predictions'],color='blue',marker='o')\n",
        "plt.plot(test_results['Actuals'],color='red',marker='s')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "yxhSPGqTCSCE",
        "outputId": "20941909-b776-46c2-8822-db98995783f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x792b2955e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(9, 1)))\n",
        "model1.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model1.add(LSTM(50, activation='relu', return_sequences=True))\n",
        "model1.add(LSTM(25, activation='relu'))\n",
        "model1.add(Dense(20, activation='relu'))\n",
        "model1.add(Dense(10, activation='relu'))\n",
        "model1.add(Dense(1))\n",
        "model1.compile(optimizer='adam', loss='mse')\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zsKPYbPEU7tH",
        "outputId": "322947d9-0118-4d0b-83bf-4fc16aea243f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_5 (LSTM)               (None, 9, 200)            161600    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 9, 100)            120400    \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 9, 50)             30200     \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 25)                7600      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                520       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320541 (1.22 MB)\n",
            "Trainable params: 320541 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_FkLCMruVQSk",
        "outputId": "6e9318ca-4a6a-4aa5-e358-563616d239a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "10/10 [==============================] - 9s 209ms/step - loss: 663.6692 - val_loss: 129.0867\n",
            "Epoch 2/1000\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 71.0440 - val_loss: 99.6522\n",
            "Epoch 3/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 12.1545 - val_loss: 1.0322\n",
            "Epoch 4/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 2.4936 - val_loss: 22.5551\n",
            "Epoch 5/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9726 - val_loss: 18.1292\n",
            "Epoch 6/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8807 - val_loss: 8.1008\n",
            "Epoch 7/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7999 - val_loss: 10.0537\n",
            "Epoch 8/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.7204 - val_loss: 8.1100\n",
            "Epoch 9/1000\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6871 - val_loss: 6.3402\n",
            "Epoch 10/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.6676 - val_loss: 6.7999\n",
            "Epoch 11/1000\n",
            "10/10 [==============================] - 1s 48ms/step - loss: 0.6608 - val_loss: 8.5119\n",
            "Epoch 12/1000\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.6406 - val_loss: 7.5972\n",
            "Epoch 13/1000\n",
            "10/10 [==============================] - 1s 86ms/step - loss: 0.6165 - val_loss: 10.0420\n",
            "Epoch 14/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6445 - val_loss: 8.2185\n",
            "Epoch 15/1000\n",
            "10/10 [==============================] - 1s 86ms/step - loss: 0.5813 - val_loss: 6.7125\n",
            "Epoch 16/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.5768 - val_loss: 6.1785\n",
            "Epoch 17/1000\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.5278 - val_loss: 7.5502\n",
            "Epoch 18/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.5088 - val_loss: 12.8027\n",
            "Epoch 19/1000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.6379 - val_loss: 12.1026\n",
            "Epoch 20/1000\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.5676 - val_loss: 10.6227\n",
            "Epoch 21/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5061 - val_loss: 6.1295\n",
            "Epoch 22/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5142 - val_loss: 7.9317\n",
            "Epoch 23/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5035 - val_loss: 7.0529\n",
            "Epoch 24/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4836 - val_loss: 7.1373\n",
            "Epoch 25/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4938 - val_loss: 7.0522\n",
            "Epoch 26/1000\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5497 - val_loss: 4.0681\n",
            "Epoch 27/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5165 - val_loss: 6.7211\n",
            "Epoch 28/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4910 - val_loss: 4.1039\n",
            "Epoch 29/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4975 - val_loss: 8.2442\n",
            "Epoch 30/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4802 - val_loss: 7.2609\n",
            "Epoch 31/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4667 - val_loss: 5.8163\n",
            "Epoch 32/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4628 - val_loss: 6.7166\n",
            "Epoch 33/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4722 - val_loss: 9.0432\n",
            "Epoch 34/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4898 - val_loss: 9.3325\n",
            "Epoch 35/1000\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4672 - val_loss: 8.8406\n",
            "Epoch 36/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4759 - val_loss: 8.7959\n",
            "Epoch 37/1000\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 0.4493 - val_loss: 7.3734\n",
            "Epoch 38/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.4523 - val_loss: 6.4542\n",
            "Epoch 39/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4473 - val_loss: 6.3646\n",
            "Epoch 40/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.4308 - val_loss: 7.6009\n",
            "Epoch 41/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.4475 - val_loss: 8.5999\n",
            "Epoch 42/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.4440 - val_loss: 8.3018\n",
            "Epoch 43/1000\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 0.4590 - val_loss: 8.2984\n",
            "Epoch 44/1000\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.4414 - val_loss: 4.6532\n",
            "Epoch 45/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4371 - val_loss: 7.1918\n",
            "Epoch 46/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4346 - val_loss: 5.8564\n",
            "Epoch 47/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.4168 - val_loss: 7.7446\n",
            "Epoch 48/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.4193 - val_loss: 8.0870\n",
            "Epoch 49/1000\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.4099 - val_loss: 5.5951\n",
            "Epoch 50/1000\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 0.4107 - val_loss: 8.9798\n",
            "Epoch 51/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.4161 - val_loss: 6.5377\n",
            "Epoch 52/1000\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4276 - val_loss: 5.6310\n",
            "Epoch 53/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.5154 - val_loss: 9.7716\n",
            "Epoch 54/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5164 - val_loss: 8.2377\n",
            "Epoch 55/1000\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4519 - val_loss: 4.3072\n",
            "Epoch 56/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4471 - val_loss: 6.6814\n",
            "Epoch 57/1000\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.4154 - val_loss: 7.1024\n",
            "Epoch 58/1000\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4154 - val_loss: 8.0373\n",
            "Epoch 59/1000\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4072 - val_loss: 8.2776\n",
            "Epoch 60/1000\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.4305 - val_loss: 8.0437\n",
            "Epoch 61/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.4095 - val_loss: 6.1885\n",
            "Epoch 62/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4182 - val_loss: 5.7281\n",
            "Epoch 63/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4162 - val_loss: 6.1740\n",
            "Epoch 64/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3943 - val_loss: 5.6892\n",
            "Epoch 65/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3816 - val_loss: 7.3734\n",
            "Epoch 66/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3989 - val_loss: 8.5837\n",
            "Epoch 67/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4264 - val_loss: 5.2701\n",
            "Epoch 68/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4034 - val_loss: 7.0241\n",
            "Epoch 69/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4021 - val_loss: 8.7750\n",
            "Epoch 70/1000\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 0.4652 - val_loss: 3.2192\n",
            "Epoch 71/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4872 - val_loss: 6.8712\n",
            "Epoch 72/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4804 - val_loss: 9.1678\n",
            "Epoch 73/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.5002 - val_loss: 3.4563\n",
            "Epoch 74/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5167 - val_loss: 11.6345\n",
            "Epoch 75/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5518 - val_loss: 4.4211\n",
            "Epoch 76/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5806 - val_loss: 10.8040\n",
            "Epoch 77/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4409 - val_loss: 6.7120\n",
            "Epoch 78/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4359 - val_loss: 5.5383\n",
            "Epoch 79/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3890 - val_loss: 6.7279\n",
            "Epoch 80/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3731 - val_loss: 5.4404\n",
            "Epoch 81/1000\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 0.3710 - val_loss: 4.6912\n",
            "Epoch 82/1000\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.3519 - val_loss: 2.9338\n",
            "Epoch 83/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.5015 - val_loss: 7.5947\n",
            "Epoch 84/1000\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 0.4371 - val_loss: 6.1630\n",
            "Epoch 85/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4148 - val_loss: 7.8261\n",
            "Epoch 86/1000\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.4073 - val_loss: 6.7704\n",
            "Epoch 87/1000\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4359 - val_loss: 7.1787\n",
            "Epoch 88/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4276 - val_loss: 4.5541\n",
            "Epoch 89/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3750 - val_loss: 9.1294\n",
            "Epoch 90/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4993 - val_loss: 5.0819\n",
            "Epoch 91/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3866 - val_loss: 6.1724\n",
            "Epoch 92/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3665 - val_loss: 6.0087\n",
            "Epoch 93/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3483 - val_loss: 3.3721\n",
            "Epoch 94/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4166 - val_loss: 10.6660\n",
            "Epoch 95/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3527 - val_loss: 6.5526\n",
            "Epoch 96/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3550 - val_loss: 4.6354\n",
            "Epoch 97/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3389 - val_loss: 12.7133\n",
            "Epoch 98/1000\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5108 - val_loss: 6.3879\n",
            "Epoch 99/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3907 - val_loss: 9.6920\n",
            "Epoch 100/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3206 - val_loss: 4.8708\n",
            "Epoch 101/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3300 - val_loss: 7.9073\n",
            "Epoch 102/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2914 - val_loss: 7.2216\n",
            "Epoch 103/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3597 - val_loss: 4.9181\n",
            "Epoch 104/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3699 - val_loss: 5.1607\n",
            "Epoch 105/1000\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.3238 - val_loss: 3.1197\n",
            "Epoch 106/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.3271 - val_loss: 5.1742\n",
            "Epoch 107/1000\n",
            "10/10 [==============================] - 1s 84ms/step - loss: 0.2834 - val_loss: 4.7668\n",
            "Epoch 108/1000\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.2829 - val_loss: 20.3363\n",
            "Epoch 109/1000\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 0.9914 - val_loss: 5.7327\n",
            "Epoch 110/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.6078 - val_loss: 11.8615\n",
            "Epoch 111/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5894 - val_loss: 2.7481\n",
            "Epoch 112/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4895 - val_loss: 7.9226\n",
            "Epoch 113/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3822 - val_loss: 6.7400\n",
            "Epoch 114/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4010 - val_loss: 7.7185\n",
            "Epoch 115/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3840 - val_loss: 4.4351\n",
            "Epoch 116/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3365 - val_loss: 9.2926\n",
            "Epoch 117/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3839 - val_loss: 4.3313\n",
            "Epoch 118/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3471 - val_loss: 5.1217\n",
            "Epoch 119/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2997 - val_loss: 6.1089\n",
            "Epoch 120/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3018 - val_loss: 5.7543\n",
            "Epoch 121/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3359 - val_loss: 5.5549\n",
            "Epoch 122/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3433 - val_loss: 8.7301\n",
            "Epoch 123/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3670 - val_loss: 12.7145\n",
            "Epoch 124/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5270 - val_loss: 3.4955\n",
            "Epoch 125/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7251 - val_loss: 7.9529\n",
            "Epoch 126/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5428 - val_loss: 12.3015\n",
            "Epoch 127/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5346 - val_loss: 6.0780\n",
            "Epoch 128/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3878 - val_loss: 12.9778\n",
            "Epoch 129/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.4887 - val_loss: 5.6466\n",
            "Epoch 130/1000\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.3369 - val_loss: 5.8765\n",
            "Epoch 131/1000\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.4280 - val_loss: 10.4309\n",
            "Epoch 132/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.3852 - val_loss: 11.9632\n",
            "Epoch 133/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.5712 - val_loss: 3.5671\n",
            "Epoch 134/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.3428 - val_loss: 7.2730\n",
            "Epoch 135/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3463 - val_loss: 6.9387\n",
            "Epoch 136/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3045 - val_loss: 3.8034\n",
            "Epoch 137/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3189 - val_loss: 1.9386\n",
            "Epoch 138/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.3597 - val_loss: 8.9504\n",
            "Epoch 139/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3349 - val_loss: 5.3453\n",
            "Epoch 140/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2491 - val_loss: 5.0557\n",
            "Epoch 141/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2233 - val_loss: 5.9931\n",
            "Epoch 142/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4352 - val_loss: 10.2975\n",
            "Epoch 143/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4946 - val_loss: 8.0289\n",
            "Epoch 144/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3259 - val_loss: 8.9565\n",
            "Epoch 145/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3118 - val_loss: 7.8809\n",
            "Epoch 146/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3192 - val_loss: 8.3166\n",
            "Epoch 147/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2986 - val_loss: 8.1691\n",
            "Epoch 148/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2597 - val_loss: 6.0819\n",
            "Epoch 149/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2634 - val_loss: 9.0581\n",
            "Epoch 150/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2668 - val_loss: 7.0244\n",
            "Epoch 151/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2409 - val_loss: 6.7381\n",
            "Epoch 152/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1867 - val_loss: 6.6966\n",
            "Epoch 153/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2019 - val_loss: 9.2537\n",
            "Epoch 154/1000\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3186 - val_loss: 7.3580\n",
            "Epoch 155/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.3900 - val_loss: 11.1650\n",
            "Epoch 156/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.4720 - val_loss: 4.6759\n",
            "Epoch 157/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.3323 - val_loss: 5.4361\n",
            "Epoch 158/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.2302 - val_loss: 7.5540\n",
            "Epoch 159/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3736 - val_loss: 3.3110\n",
            "Epoch 160/1000\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.4359 - val_loss: 4.0598\n",
            "Epoch 161/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4093 - val_loss: 6.6799\n",
            "Epoch 162/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.2577 - val_loss: 4.7081\n",
            "Epoch 163/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2131 - val_loss: 8.9108\n",
            "Epoch 164/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2643 - val_loss: 5.8161\n",
            "Epoch 165/1000\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1977 - val_loss: 8.7889\n",
            "Epoch 166/1000\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.2280 - val_loss: 6.8705\n",
            "Epoch 167/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3140 - val_loss: 6.0665\n",
            "Epoch 168/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3134 - val_loss: 6.7179\n",
            "Epoch 169/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1556 - val_loss: 7.3964\n",
            "Epoch 170/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1153 - val_loss: 5.7592\n",
            "Epoch 171/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1409 - val_loss: 4.5750\n",
            "Epoch 172/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1130 - val_loss: 8.9268\n",
            "Epoch 173/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1095 - val_loss: 7.6657\n",
            "Epoch 174/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2336 - val_loss: 7.0785\n",
            "Epoch 175/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3157 - val_loss: 5.1791\n",
            "Epoch 176/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2323 - val_loss: 4.4145\n",
            "Epoch 177/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2084 - val_loss: 8.1735\n",
            "Epoch 178/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1870 - val_loss: 8.5382\n",
            "Epoch 179/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1523 - val_loss: 4.5798\n",
            "Epoch 180/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1776 - val_loss: 5.9209\n",
            "Epoch 181/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.1979 - val_loss: 7.2107\n",
            "Epoch 182/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.2853 - val_loss: 11.1110\n",
            "Epoch 183/1000\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 0.4675 - val_loss: 12.7797\n",
            "Epoch 184/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4029 - val_loss: 9.3091\n",
            "Epoch 185/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2071 - val_loss: 3.7522\n",
            "Epoch 186/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2333 - val_loss: 7.0603\n",
            "Epoch 187/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2594 - val_loss: 11.9949\n",
            "Epoch 188/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2320 - val_loss: 8.2585\n",
            "Epoch 189/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0977 - val_loss: 6.7384\n",
            "Epoch 190/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1659 - val_loss: 5.4120\n",
            "Epoch 191/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1756 - val_loss: 8.5141\n",
            "Epoch 192/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1350 - val_loss: 4.9177\n",
            "Epoch 193/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0997 - val_loss: 8.2042\n",
            "Epoch 194/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1454 - val_loss: 5.7071\n",
            "Epoch 195/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2768 - val_loss: 9.2504\n",
            "Epoch 196/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.2137 - val_loss: 12.4189\n",
            "Epoch 197/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.2661 - val_loss: 4.5573\n",
            "Epoch 198/1000\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.2500 - val_loss: 6.1381\n",
            "Epoch 199/1000\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.1858 - val_loss: 10.1932\n",
            "Epoch 200/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.1936 - val_loss: 8.0094\n",
            "Epoch 201/1000\n",
            "10/10 [==============================] - 1s 86ms/step - loss: 0.1540 - val_loss: 5.6480\n",
            "Epoch 202/1000\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.1385 - val_loss: 7.1055\n",
            "Epoch 203/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.2298 - val_loss: 7.7172\n",
            "Epoch 204/1000\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 0.2528 - val_loss: 6.9727\n",
            "Epoch 205/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1475 - val_loss: 5.0572\n",
            "Epoch 206/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2436 - val_loss: 4.8933\n",
            "Epoch 207/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1380 - val_loss: 8.2477\n",
            "Epoch 208/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1796 - val_loss: 9.3790\n",
            "Epoch 209/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1469 - val_loss: 5.0656\n",
            "Epoch 210/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1481 - val_loss: 2.8174\n",
            "Epoch 211/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2878 - val_loss: 10.4225\n",
            "Epoch 212/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3051 - val_loss: 7.0589\n",
            "Epoch 213/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2307 - val_loss: 4.3443\n",
            "Epoch 214/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1773 - val_loss: 5.8705\n",
            "Epoch 215/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1370 - val_loss: 6.3838\n",
            "Epoch 216/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0718 - val_loss: 8.4584\n",
            "Epoch 217/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0683 - val_loss: 7.3414\n",
            "Epoch 218/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2446 - val_loss: 9.8521\n",
            "Epoch 219/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2713 - val_loss: 3.4584\n",
            "Epoch 220/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2645 - val_loss: 4.0510\n",
            "Epoch 221/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1844 - val_loss: 3.6268\n",
            "Epoch 222/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2194 - val_loss: 5.6493\n",
            "Epoch 223/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1694 - val_loss: 9.4240\n",
            "Epoch 224/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0965 - val_loss: 6.5736\n",
            "Epoch 225/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0672 - val_loss: 5.4819\n",
            "Epoch 226/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0888 - val_loss: 6.8323\n",
            "Epoch 227/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0584 - val_loss: 4.1337\n",
            "Epoch 228/1000\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 0.0493 - val_loss: 5.4442\n",
            "Epoch 229/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0616 - val_loss: 7.1595\n",
            "Epoch 230/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2431 - val_loss: 2.0033\n",
            "Epoch 231/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4466 - val_loss: 12.2391\n",
            "Epoch 232/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3359 - val_loss: 10.7236\n",
            "Epoch 233/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2585 - val_loss: 11.0417\n",
            "Epoch 234/1000\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.3993 - val_loss: 11.5458\n",
            "Epoch 235/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3224 - val_loss: 6.6569\n",
            "Epoch 236/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2366 - val_loss: 9.5030\n",
            "Epoch 237/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2499 - val_loss: 6.9166\n",
            "Epoch 238/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1600 - val_loss: 5.1503\n",
            "Epoch 239/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1112 - val_loss: 7.1632\n",
            "Epoch 240/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0754 - val_loss: 6.4181\n",
            "Epoch 241/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1947 - val_loss: 6.2993\n",
            "Epoch 242/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3926 - val_loss: 9.3368\n",
            "Epoch 243/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1783 - val_loss: 6.3261\n",
            "Epoch 244/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1571 - val_loss: 9.3515\n",
            "Epoch 245/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1546 - val_loss: 7.4062\n",
            "Epoch 246/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2313 - val_loss: 10.1984\n",
            "Epoch 247/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1833 - val_loss: 9.7784\n",
            "Epoch 248/1000\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.3864 - val_loss: 5.4624\n",
            "Epoch 249/1000\n",
            "10/10 [==============================] - 1s 86ms/step - loss: 0.5008 - val_loss: 5.4739\n",
            "Epoch 250/1000\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.5195 - val_loss: 5.4366\n",
            "Epoch 251/1000\n",
            "10/10 [==============================] - 1s 85ms/step - loss: 0.3861 - val_loss: 6.0229\n",
            "Epoch 252/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.2023 - val_loss: 4.3799\n",
            "Epoch 253/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1621 - val_loss: 6.9603\n",
            "Epoch 254/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1476 - val_loss: 6.3178\n",
            "Epoch 255/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1288 - val_loss: 3.9972\n",
            "Epoch 256/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1611 - val_loss: 9.5809\n",
            "Epoch 257/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0783 - val_loss: 8.0270\n",
            "Epoch 258/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1283 - val_loss: 3.6122\n",
            "Epoch 259/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2534 - val_loss: 10.7570\n",
            "Epoch 260/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3012 - val_loss: 5.6827\n",
            "Epoch 261/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2404 - val_loss: 5.9131\n",
            "Epoch 262/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1586 - val_loss: 6.6069\n",
            "Epoch 263/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1495 - val_loss: 11.8455\n",
            "Epoch 264/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2214 - val_loss: 5.5092\n",
            "Epoch 265/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2152 - val_loss: 4.8695\n",
            "Epoch 266/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1632 - val_loss: 10.0679\n",
            "Epoch 267/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1597 - val_loss: 11.1173\n",
            "Epoch 268/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2402 - val_loss: 3.8170\n",
            "Epoch 269/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3210 - val_loss: 4.3672\n",
            "Epoch 270/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1520 - val_loss: 4.7374\n",
            "Epoch 271/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1208 - val_loss: 4.2213\n",
            "Epoch 272/1000\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.0917 - val_loss: 5.8422\n",
            "Epoch 273/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.0723 - val_loss: 6.2893\n",
            "Epoch 274/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0971 - val_loss: 6.1859\n",
            "Epoch 275/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.0823 - val_loss: 7.9332\n",
            "Epoch 276/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0813 - val_loss: 2.8947\n",
            "Epoch 277/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0957 - val_loss: 5.4870\n",
            "Epoch 278/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0591 - val_loss: 10.5872\n",
            "Epoch 279/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1149 - val_loss: 10.1432\n",
            "Epoch 280/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2998 - val_loss: 5.4167\n",
            "Epoch 281/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5832 - val_loss: 5.1103\n",
            "Epoch 282/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4163 - val_loss: 3.0617\n",
            "Epoch 283/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1998 - val_loss: 7.7661\n",
            "Epoch 284/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1877 - val_loss: 7.4191\n",
            "Epoch 285/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1363 - val_loss: 7.2057\n",
            "Epoch 286/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0964 - val_loss: 5.1963\n",
            "Epoch 287/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0809 - val_loss: 5.9508\n",
            "Epoch 288/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0811 - val_loss: 4.9052\n",
            "Epoch 289/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1004 - val_loss: 4.4805\n",
            "Epoch 290/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0587 - val_loss: 5.4470\n",
            "Epoch 291/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0500 - val_loss: 6.4274\n",
            "Epoch 292/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1366 - val_loss: 9.7897\n",
            "Epoch 293/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3358 - val_loss: 8.5809\n",
            "Epoch 294/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2783 - val_loss: 5.1853\n",
            "Epoch 295/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2723 - val_loss: 8.2635\n",
            "Epoch 296/1000\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.4197 - val_loss: 10.4813\n",
            "Epoch 297/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.2793 - val_loss: 5.2820\n",
            "Epoch 298/1000\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.1384 - val_loss: 3.8005\n",
            "Epoch 299/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.1439 - val_loss: 4.1178\n",
            "Epoch 300/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0775 - val_loss: 6.8483\n",
            "Epoch 301/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0749 - val_loss: 7.5272\n",
            "Epoch 302/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0742 - val_loss: 6.7234\n",
            "Epoch 303/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3181 - val_loss: 6.4299\n",
            "Epoch 304/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1259 - val_loss: 6.5041\n",
            "Epoch 305/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1196 - val_loss: 6.4312\n",
            "Epoch 306/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0788 - val_loss: 7.7093\n",
            "Epoch 307/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0627 - val_loss: 4.0970\n",
            "Epoch 308/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0611 - val_loss: 6.9012\n",
            "Epoch 309/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2091 - val_loss: 1.0054\n",
            "Epoch 310/1000\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 0.5295 - val_loss: 9.5043\n",
            "Epoch 311/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2190 - val_loss: 6.6612\n",
            "Epoch 312/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1739 - val_loss: 4.6410\n",
            "Epoch 313/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1324 - val_loss: 6.6174\n",
            "Epoch 314/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0871 - val_loss: 4.6140\n",
            "Epoch 315/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0892 - val_loss: 5.6163\n",
            "Epoch 316/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0855 - val_loss: 5.9611\n",
            "Epoch 317/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0671 - val_loss: 3.1732\n",
            "Epoch 318/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1082 - val_loss: 1.9218\n",
            "Epoch 319/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2043 - val_loss: 8.3956\n",
            "Epoch 320/1000\n",
            "10/10 [==============================] - 1s 80ms/step - loss: 0.1265 - val_loss: 2.7115\n",
            "Epoch 321/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.2292 - val_loss: 9.0172\n",
            "Epoch 322/1000\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.1340 - val_loss: 5.2189\n",
            "Epoch 323/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.0881 - val_loss: 9.0113\n",
            "Epoch 324/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.1983 - val_loss: 3.5541\n",
            "Epoch 325/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1626 - val_loss: 7.0234\n",
            "Epoch 326/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0671 - val_loss: 6.5960\n",
            "Epoch 327/1000\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 0.1106 - val_loss: 8.2572\n",
            "Epoch 328/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2258 - val_loss: 1.5316\n",
            "Epoch 329/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2713 - val_loss: 15.4958\n",
            "Epoch 330/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5463 - val_loss: 7.8974\n",
            "Epoch 331/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.3910 - val_loss: 14.6766\n",
            "Epoch 332/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5199 - val_loss: 2.5326\n",
            "Epoch 333/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2490 - val_loss: 5.1356\n",
            "Epoch 334/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1931 - val_loss: 8.8307\n",
            "Epoch 335/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3066 - val_loss: 10.7709\n",
            "Epoch 336/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2628 - val_loss: 9.7146\n",
            "Epoch 337/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3726 - val_loss: 14.3123\n",
            "Epoch 338/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3370 - val_loss: 18.2703\n",
            "Epoch 339/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4543 - val_loss: 20.1876\n",
            "Epoch 340/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4086 - val_loss: 11.9775\n",
            "Epoch 341/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2964 - val_loss: 1.2024\n",
            "Epoch 342/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2320 - val_loss: 2.9160\n",
            "Epoch 343/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1691 - val_loss: 4.3870\n",
            "Epoch 344/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1582 - val_loss: 8.0332\n",
            "Epoch 345/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.1758 - val_loss: 4.0015\n",
            "Epoch 346/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0819 - val_loss: 6.7313\n",
            "Epoch 347/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.1041 - val_loss: 4.9454\n",
            "Epoch 348/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0598 - val_loss: 4.6967\n",
            "Epoch 349/1000\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.0605 - val_loss: 3.6884\n",
            "Epoch 350/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1855 - val_loss: 11.7157\n",
            "Epoch 351/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3091 - val_loss: 14.7420\n",
            "Epoch 352/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.3029 - val_loss: 11.8496\n",
            "Epoch 353/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1823 - val_loss: 6.8041\n",
            "Epoch 354/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1544 - val_loss: 8.9271\n",
            "Epoch 355/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0914 - val_loss: 5.4321\n",
            "Epoch 356/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0751 - val_loss: 5.8663\n",
            "Epoch 357/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0659 - val_loss: 6.4189\n",
            "Epoch 358/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0726 - val_loss: 6.2885\n",
            "Epoch 359/1000\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.0512 - val_loss: 6.4704\n",
            "Epoch 360/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1729 - val_loss: 3.8210\n",
            "Epoch 361/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1244 - val_loss: 6.6443\n",
            "Epoch 362/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1710 - val_loss: 5.4243\n",
            "Epoch 363/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2703 - val_loss: 14.2024\n",
            "Epoch 364/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2225 - val_loss: 7.2899\n",
            "Epoch 365/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1534 - val_loss: 5.6727\n",
            "Epoch 366/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0969 - val_loss: 7.5019\n",
            "Epoch 367/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1145 - val_loss: 6.0085\n",
            "Epoch 368/1000\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 0.1522 - val_loss: 4.5085\n",
            "Epoch 369/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0979 - val_loss: 7.4669\n",
            "Epoch 370/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0961 - val_loss: 3.8860\n",
            "Epoch 371/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0614 - val_loss: 4.9584\n",
            "Epoch 372/1000\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0394 - val_loss: 6.2179\n",
            "Epoch 373/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0509 - val_loss: 5.5092\n",
            "Epoch 374/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1414 - val_loss: 2.0488\n",
            "Epoch 375/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2001 - val_loss: 6.5515\n",
            "Epoch 376/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1214 - val_loss: 5.9608\n",
            "Epoch 377/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0903 - val_loss: 4.9124\n",
            "Epoch 378/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1088 - val_loss: 7.7066\n",
            "Epoch 379/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0877 - val_loss: 7.8249\n",
            "Epoch 380/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0687 - val_loss: 6.7524\n",
            "Epoch 381/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0561 - val_loss: 7.0576\n",
            "Epoch 382/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1317 - val_loss: 6.7040\n",
            "Epoch 383/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0807 - val_loss: 4.5970\n",
            "Epoch 384/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0473 - val_loss: 6.9751\n",
            "Epoch 385/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1613 - val_loss: 5.2227\n",
            "Epoch 386/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2077 - val_loss: 10.6574\n",
            "Epoch 387/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.2570 - val_loss: 12.6846\n",
            "Epoch 388/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2495 - val_loss: 6.0518\n",
            "Epoch 389/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1293 - val_loss: 4.0976\n",
            "Epoch 390/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2142 - val_loss: 6.6920\n",
            "Epoch 391/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1375 - val_loss: 3.4336\n",
            "Epoch 392/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.1461 - val_loss: 5.3977\n",
            "Epoch 393/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.2050 - val_loss: 10.5297\n",
            "Epoch 394/1000\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.2469 - val_loss: 3.6054\n",
            "Epoch 395/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.2170 - val_loss: 14.0432\n",
            "Epoch 396/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3128 - val_loss: 0.7607\n",
            "Epoch 397/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5209 - val_loss: 3.3142\n",
            "Epoch 398/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3343 - val_loss: 11.9909\n",
            "Epoch 399/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3984 - val_loss: 10.8372\n",
            "Epoch 400/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1723 - val_loss: 10.1286\n",
            "Epoch 401/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1425 - val_loss: 4.5570\n",
            "Epoch 402/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1296 - val_loss: 4.3279\n",
            "Epoch 403/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0543 - val_loss: 3.4998\n",
            "Epoch 404/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0951 - val_loss: 4.6328\n",
            "Epoch 405/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0988 - val_loss: 6.7834\n",
            "Epoch 406/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1580 - val_loss: 2.7515\n",
            "Epoch 407/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1489 - val_loss: 6.4333\n",
            "Epoch 408/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0544 - val_loss: 3.4765\n",
            "Epoch 409/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1325 - val_loss: 5.6264\n",
            "Epoch 410/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1376 - val_loss: 6.9047\n",
            "Epoch 411/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0493 - val_loss: 4.0414\n",
            "Epoch 412/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0570 - val_loss: 4.8921\n",
            "Epoch 413/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0543 - val_loss: 2.8406\n",
            "Epoch 414/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0680 - val_loss: 4.3450\n",
            "Epoch 415/1000\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.2005 - val_loss: 4.2292\n",
            "Epoch 416/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.1026 - val_loss: 9.4029\n",
            "Epoch 417/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.1224 - val_loss: 5.4020\n",
            "Epoch 418/1000\n",
            "10/10 [==============================] - 1s 85ms/step - loss: 0.0858 - val_loss: 7.0966\n",
            "Epoch 419/1000\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.0628 - val_loss: 5.6459\n",
            "Epoch 420/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0490 - val_loss: 3.3147\n",
            "Epoch 421/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1048 - val_loss: 6.5767\n",
            "Epoch 422/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1404 - val_loss: 3.9610\n",
            "Epoch 423/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0569 - val_loss: 3.6445\n",
            "Epoch 424/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2196 - val_loss: 10.6751\n",
            "Epoch 425/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1089 - val_loss: 8.6031\n",
            "Epoch 426/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1386 - val_loss: 4.2915\n",
            "Epoch 427/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0931 - val_loss: 3.4811\n",
            "Epoch 428/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0491 - val_loss: 5.7887\n",
            "Epoch 429/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0751 - val_loss: 1.3769\n",
            "Epoch 430/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1895 - val_loss: 11.1656\n",
            "Epoch 431/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5516 - val_loss: 9.2785\n",
            "Epoch 432/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.6027 - val_loss: 18.6096\n",
            "Epoch 433/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4305 - val_loss: 8.1531\n",
            "Epoch 434/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2533 - val_loss: 3.4878\n",
            "Epoch 435/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4735 - val_loss: 10.8185\n",
            "Epoch 436/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.6580 - val_loss: 17.4583\n",
            "Epoch 437/1000\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5108 - val_loss: 4.7656\n",
            "Epoch 438/1000\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 0.2969 - val_loss: 2.6388\n",
            "Epoch 439/1000\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.1711 - val_loss: 4.7340\n",
            "Epoch 440/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.0966 - val_loss: 5.9529\n",
            "Epoch 441/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.1014 - val_loss: 8.1562\n",
            "Epoch 442/1000\n",
            "10/10 [==============================] - 1s 153ms/step - loss: 0.1054 - val_loss: 3.1483\n",
            "Epoch 443/1000\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 0.1385 - val_loss: 2.4659\n",
            "Epoch 444/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1487 - val_loss: 5.5730\n",
            "Epoch 445/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0555 - val_loss: 7.5320\n",
            "Epoch 446/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1294 - val_loss: 4.3674\n",
            "Epoch 447/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2037 - val_loss: 6.2478\n",
            "Epoch 448/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0768 - val_loss: 7.2179\n",
            "Epoch 449/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0630 - val_loss: 9.5681\n",
            "Epoch 450/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0652 - val_loss: 4.6075\n",
            "Epoch 451/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0964 - val_loss: 2.9064\n",
            "Epoch 452/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1055 - val_loss: 6.6917\n",
            "Epoch 453/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1397 - val_loss: 7.9334\n",
            "Epoch 454/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0771 - val_loss: 3.1204\n",
            "Epoch 455/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2108 - val_loss: 11.7910\n",
            "Epoch 456/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3422 - val_loss: 3.3111\n",
            "Epoch 457/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1409 - val_loss: 5.6602\n",
            "Epoch 458/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1066 - val_loss: 9.8716\n",
            "Epoch 459/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1123 - val_loss: 6.0267\n",
            "Epoch 460/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1847 - val_loss: 0.8345\n",
            "Epoch 461/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.3334 - val_loss: 10.9961\n",
            "Epoch 462/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3081 - val_loss: 1.2409\n",
            "Epoch 463/1000\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 0.2971 - val_loss: 7.5767\n",
            "Epoch 464/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.1679 - val_loss: 8.0636\n",
            "Epoch 465/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.1961 - val_loss: 6.9904\n",
            "Epoch 466/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.1069 - val_loss: 6.1754\n",
            "Epoch 467/1000\n",
            "10/10 [==============================] - 1s 82ms/step - loss: 0.1649 - val_loss: 4.7390\n",
            "Epoch 468/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1660 - val_loss: 4.2686\n",
            "Epoch 469/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1643 - val_loss: 1.9035\n",
            "Epoch 470/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.2345 - val_loss: 2.7534\n",
            "Epoch 471/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1497 - val_loss: 5.3022\n",
            "Epoch 472/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0585 - val_loss: 5.0830\n",
            "Epoch 473/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0533 - val_loss: 4.2703\n",
            "Epoch 474/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0571 - val_loss: 3.8757\n",
            "Epoch 475/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0515 - val_loss: 3.5375\n",
            "Epoch 476/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0339 - val_loss: 6.3820\n",
            "Epoch 477/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0602 - val_loss: 3.7191\n",
            "Epoch 478/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0985 - val_loss: 8.0897\n",
            "Epoch 479/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2259 - val_loss: 3.7839\n",
            "Epoch 480/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1336 - val_loss: 3.9041\n",
            "Epoch 481/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1332 - val_loss: 4.4220\n",
            "Epoch 482/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1549 - val_loss: 5.3808\n",
            "Epoch 483/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1292 - val_loss: 1.6515\n",
            "Epoch 484/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1794 - val_loss: 7.2486\n",
            "Epoch 485/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1170 - val_loss: 6.0535\n",
            "Epoch 486/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1059 - val_loss: 2.0826\n",
            "Epoch 487/1000\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 0.2279 - val_loss: 12.4555\n",
            "Epoch 488/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.2012 - val_loss: 3.8288\n",
            "Epoch 489/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.1988 - val_loss: 18.6316\n",
            "Epoch 490/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.2938 - val_loss: 8.1591\n",
            "Epoch 491/1000\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 0.1167 - val_loss: 6.2249\n",
            "Epoch 492/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0771 - val_loss: 3.1355\n",
            "Epoch 493/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0895 - val_loss: 4.6833\n",
            "Epoch 494/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0954 - val_loss: 1.7354\n",
            "Epoch 495/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0557 - val_loss: 2.9579\n",
            "Epoch 496/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0700 - val_loss: 2.7312\n",
            "Epoch 497/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1587 - val_loss: 4.1038\n",
            "Epoch 498/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1248 - val_loss: 2.9209\n",
            "Epoch 499/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0803 - val_loss: 7.3048\n",
            "Epoch 500/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0709 - val_loss: 5.8545\n",
            "Epoch 501/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0466 - val_loss: 7.1478\n",
            "Epoch 502/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0347 - val_loss: 2.8572\n",
            "Epoch 503/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0509 - val_loss: 3.5368\n",
            "Epoch 504/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1606 - val_loss: 7.8221\n",
            "Epoch 505/1000\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1404 - val_loss: 2.7379\n",
            "Epoch 506/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1476 - val_loss: 8.5146\n",
            "Epoch 507/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2192 - val_loss: 3.4207\n",
            "Epoch 508/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1871 - val_loss: 4.4588\n",
            "Epoch 509/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1014 - val_loss: 5.6443\n",
            "Epoch 510/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1075 - val_loss: 5.4511\n",
            "Epoch 511/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0434 - val_loss: 4.7888\n",
            "Epoch 512/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0465 - val_loss: 2.5161\n",
            "Epoch 513/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.1530 - val_loss: 8.1792\n",
            "Epoch 514/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1320 - val_loss: 8.4577\n",
            "Epoch 515/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0983 - val_loss: 5.8750\n",
            "Epoch 516/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0807 - val_loss: 4.5279\n",
            "Epoch 517/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0661 - val_loss: 3.5484\n",
            "Epoch 518/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1088 - val_loss: 5.9771\n",
            "Epoch 519/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1454 - val_loss: 2.5412\n",
            "Epoch 520/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.2320 - val_loss: 1.3735\n",
            "Epoch 521/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2428 - val_loss: 2.9092\n",
            "Epoch 522/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1456 - val_loss: 4.1241\n",
            "Epoch 523/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1640 - val_loss: 3.2351\n",
            "Epoch 524/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1201 - val_loss: 3.7478\n",
            "Epoch 525/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0907 - val_loss: 3.6755\n",
            "Epoch 526/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0313 - val_loss: 5.0479\n",
            "Epoch 527/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1390 - val_loss: 5.4304\n",
            "Epoch 528/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.3859 - val_loss: 4.1067\n",
            "Epoch 529/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.2234 - val_loss: 10.2454\n",
            "Epoch 530/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1052 - val_loss: 4.4032\n",
            "Epoch 531/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2253 - val_loss: 7.4571\n",
            "Epoch 532/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2650 - val_loss: 3.4810\n",
            "Epoch 533/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1000 - val_loss: 4.1629\n",
            "Epoch 534/1000\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 0.0998 - val_loss: 5.4881\n",
            "Epoch 535/1000\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.0554 - val_loss: 5.4772\n",
            "Epoch 536/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.1488 - val_loss: 5.0828\n",
            "Epoch 537/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.1496 - val_loss: 3.6226\n",
            "Epoch 538/1000\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 0.2416 - val_loss: 2.4262\n",
            "Epoch 539/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.2607 - val_loss: 7.8195\n",
            "Epoch 540/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2660 - val_loss: 3.1050\n",
            "Epoch 541/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1962 - val_loss: 8.0989\n",
            "Epoch 542/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1454 - val_loss: 2.8143\n",
            "Epoch 543/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0697 - val_loss: 2.5314\n",
            "Epoch 544/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0941 - val_loss: 6.4101\n",
            "Epoch 545/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0692 - val_loss: 4.0609\n",
            "Epoch 546/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0381 - val_loss: 2.7952\n",
            "Epoch 547/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0502 - val_loss: 2.6974\n",
            "Epoch 548/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0832 - val_loss: 4.8209\n",
            "Epoch 549/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0372 - val_loss: 4.4572\n",
            "Epoch 550/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0349 - val_loss: 3.3529\n",
            "Epoch 551/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1592 - val_loss: 5.9750\n",
            "Epoch 552/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0753 - val_loss: 3.3704\n",
            "Epoch 553/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1238 - val_loss: 2.9318\n",
            "Epoch 554/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0771 - val_loss: 3.2753\n",
            "Epoch 555/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0535 - val_loss: 3.9941\n",
            "Epoch 556/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1375 - val_loss: 2.9944\n",
            "Epoch 557/1000\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 0.0761 - val_loss: 6.0225\n",
            "Epoch 558/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0753 - val_loss: 5.1225\n",
            "Epoch 559/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0534 - val_loss: 4.4316\n",
            "Epoch 560/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0462 - val_loss: 5.1121\n",
            "Epoch 561/1000\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 0.1048 - val_loss: 4.8490\n",
            "Epoch 562/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1339 - val_loss: 7.6505\n",
            "Epoch 563/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1529 - val_loss: 3.0807\n",
            "Epoch 564/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0958 - val_loss: 8.7751\n",
            "Epoch 565/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0670 - val_loss: 3.0132\n",
            "Epoch 566/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0978 - val_loss: 3.5281\n",
            "Epoch 567/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0636 - val_loss: 4.4484\n",
            "Epoch 568/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1007 - val_loss: 7.7077\n",
            "Epoch 569/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3892 - val_loss: 1.3225\n",
            "Epoch 570/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3342 - val_loss: 10.5595\n",
            "Epoch 571/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3227 - val_loss: 2.6409\n",
            "Epoch 572/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3191 - val_loss: 2.6601\n",
            "Epoch 573/1000\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.3581 - val_loss: 20.1630\n",
            "Epoch 574/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.6682 - val_loss: 3.6475\n",
            "Epoch 575/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.4146 - val_loss: 18.2856\n",
            "Epoch 576/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3034 - val_loss: 3.4185\n",
            "Epoch 577/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1902 - val_loss: 3.9526\n",
            "Epoch 578/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0961 - val_loss: 6.0107\n",
            "Epoch 579/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0690 - val_loss: 4.3830\n",
            "Epoch 580/1000\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.0542 - val_loss: 2.7896\n",
            "Epoch 581/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0261 - val_loss: 3.3618\n",
            "Epoch 582/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0484 - val_loss: 1.4687\n",
            "Epoch 583/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.2623 - val_loss: 2.4432\n",
            "Epoch 584/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.1638 - val_loss: 10.9140\n",
            "Epoch 585/1000\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.1533 - val_loss: 7.6233\n",
            "Epoch 586/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0760 - val_loss: 7.9380\n",
            "Epoch 587/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0545 - val_loss: 6.5518\n",
            "Epoch 588/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1030 - val_loss: 3.3774\n",
            "Epoch 589/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3895 - val_loss: 10.5485\n",
            "Epoch 590/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2204 - val_loss: 5.5578\n",
            "Epoch 591/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1401 - val_loss: 2.4064\n",
            "Epoch 592/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1550 - val_loss: 6.8187\n",
            "Epoch 593/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0637 - val_loss: 4.1333\n",
            "Epoch 594/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0374 - val_loss: 2.4548\n",
            "Epoch 595/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2684 - val_loss: 2.9951\n",
            "Epoch 596/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.4451 - val_loss: 8.0445\n",
            "Epoch 597/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1411 - val_loss: 7.7086\n",
            "Epoch 598/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1027 - val_loss: 10.2215\n",
            "Epoch 599/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0935 - val_loss: 4.5321\n",
            "Epoch 600/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1434 - val_loss: 1.7508\n",
            "Epoch 601/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3701 - val_loss: 5.2195\n",
            "Epoch 602/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4601 - val_loss: 2.9661\n",
            "Epoch 603/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4587 - val_loss: 1.3849\n",
            "Epoch 604/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.4565 - val_loss: 14.1626\n",
            "Epoch 605/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.3351 - val_loss: 3.8885\n",
            "Epoch 606/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.4657 - val_loss: 3.6251\n",
            "Epoch 607/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.4220 - val_loss: 19.7545\n",
            "Epoch 608/1000\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3042 - val_loss: 7.0996\n",
            "Epoch 609/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3213 - val_loss: 4.9466\n",
            "Epoch 610/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2694 - val_loss: 8.2105\n",
            "Epoch 611/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4882 - val_loss: 22.2010\n",
            "Epoch 612/1000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7302 - val_loss: 7.8122\n",
            "Epoch 613/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4744 - val_loss: 1.7290\n",
            "Epoch 614/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3098 - val_loss: 3.9929\n",
            "Epoch 615/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3109 - val_loss: 6.6029\n",
            "Epoch 616/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2575 - val_loss: 2.2863\n",
            "Epoch 617/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1834 - val_loss: 2.0751\n",
            "Epoch 618/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1504 - val_loss: 2.9964\n",
            "Epoch 619/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0560 - val_loss: 2.5547\n",
            "Epoch 620/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0478 - val_loss: 2.7967\n",
            "Epoch 621/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1221 - val_loss: 5.7942\n",
            "Epoch 622/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1332 - val_loss: 7.5159\n",
            "Epoch 623/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0816 - val_loss: 3.1377\n",
            "Epoch 624/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0518 - val_loss: 3.5165\n",
            "Epoch 625/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0363 - val_loss: 3.2109\n",
            "Epoch 626/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0349 - val_loss: 4.1463\n",
            "Epoch 627/1000\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0818 - val_loss: 3.7674\n",
            "Epoch 628/1000\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.2261 - val_loss: 3.2648\n",
            "Epoch 629/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.3244 - val_loss: 7.1048\n",
            "Epoch 630/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.3565 - val_loss: 3.1569\n",
            "Epoch 631/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.4118 - val_loss: 0.8503\n",
            "Epoch 632/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2865 - val_loss: 4.0286\n",
            "Epoch 633/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2147 - val_loss: 4.7344\n",
            "Epoch 634/1000\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1230 - val_loss: 1.9727\n",
            "Epoch 635/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1002 - val_loss: 5.2454\n",
            "Epoch 636/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0910 - val_loss: 2.0081\n",
            "Epoch 637/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1121 - val_loss: 4.2219\n",
            "Epoch 638/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0380 - val_loss: 3.7171\n",
            "Epoch 639/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0394 - val_loss: 2.2102\n",
            "Epoch 640/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0250 - val_loss: 1.7115\n",
            "Epoch 641/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0252 - val_loss: 1.1536\n",
            "Epoch 642/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0473 - val_loss: 2.5525\n",
            "Epoch 643/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2072 - val_loss: 11.9792\n",
            "Epoch 644/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2419 - val_loss: 4.0080\n",
            "Epoch 645/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1489 - val_loss: 3.8493\n",
            "Epoch 646/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1588 - val_loss: 7.1605\n",
            "Epoch 647/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1432 - val_loss: 2.6747\n",
            "Epoch 648/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0987 - val_loss: 3.0056\n",
            "Epoch 649/1000\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.0494 - val_loss: 2.7558\n",
            "Epoch 650/1000\n",
            "10/10 [==============================] - 1s 81ms/step - loss: 0.0450 - val_loss: 4.5429\n",
            "Epoch 651/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.0352 - val_loss: 4.4216\n",
            "Epoch 652/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0283 - val_loss: 1.8954\n",
            "Epoch 653/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0921 - val_loss: 2.0913\n",
            "Epoch 654/1000\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.0765 - val_loss: 5.7843\n",
            "Epoch 655/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.1164 - val_loss: 4.3504\n",
            "Epoch 656/1000\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.0606 - val_loss: 3.2285\n",
            "Epoch 657/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.0813 - val_loss: 1.5841\n",
            "Epoch 658/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0625 - val_loss: 2.5864\n",
            "Epoch 659/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0318 - val_loss: 2.9472\n",
            "Epoch 660/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0375 - val_loss: 1.6985\n",
            "Epoch 661/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0601 - val_loss: 4.8222\n",
            "Epoch 662/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0792 - val_loss: 1.9864\n",
            "Epoch 663/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.2268 - val_loss: 4.6038\n",
            "Epoch 664/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3631 - val_loss: 6.8534\n",
            "Epoch 665/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2829 - val_loss: 15.6833\n",
            "Epoch 666/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.4718 - val_loss: 4.3599\n",
            "Epoch 667/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.5459 - val_loss: 0.6985\n",
            "Epoch 668/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.3828 - val_loss: 2.3924\n",
            "Epoch 669/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1168 - val_loss: 3.3219\n",
            "Epoch 670/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1399 - val_loss: 5.4479\n",
            "Epoch 671/1000\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.0674 - val_loss: 4.9704\n",
            "Epoch 672/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0686 - val_loss: 8.4178\n",
            "Epoch 673/1000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 0.1174 - val_loss: 3.1980\n",
            "Epoch 674/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0971 - val_loss: 4.8006\n",
            "Epoch 675/1000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 0.0392 - val_loss: 4.7470\n",
            "Epoch 676/1000\n",
            "10/10 [==============================] - 1s 81ms/step - loss: 0.0388 - val_loss: 2.5435\n",
            "Epoch 677/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0891 - val_loss: 0.8487\n",
            "Epoch 678/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0988 - val_loss: 2.7777\n",
            "Epoch 679/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0691 - val_loss: 4.0895\n",
            "Epoch 680/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0868 - val_loss: 1.9159\n",
            "Epoch 681/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0468 - val_loss: 4.4820\n",
            "Epoch 682/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0328 - val_loss: 3.6336\n",
            "Epoch 683/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0220 - val_loss: 2.6765\n",
            "Epoch 684/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0417 - val_loss: 1.1988\n",
            "Epoch 685/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0779 - val_loss: 2.9818\n",
            "Epoch 686/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0365 - val_loss: 2.9610\n",
            "Epoch 687/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0349 - val_loss: 4.1586\n",
            "Epoch 688/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0310 - val_loss: 1.7108\n",
            "Epoch 689/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0198 - val_loss: 2.1427\n",
            "Epoch 690/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0620 - val_loss: 0.7378\n",
            "Epoch 691/1000\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.1612 - val_loss: 6.5314\n",
            "Epoch 692/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0940 - val_loss: 2.8052\n",
            "Epoch 693/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0543 - val_loss: 6.0412\n",
            "Epoch 694/1000\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 0.0381 - val_loss: 3.6662\n",
            "Epoch 695/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0436 - val_loss: 6.2063\n",
            "Epoch 696/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0436 - val_loss: 3.8813\n",
            "Epoch 697/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.1004 - val_loss: 5.8079\n",
            "Epoch 698/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.1001 - val_loss: 5.7340\n",
            "Epoch 699/1000\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.2535 - val_loss: 2.4678\n",
            "Epoch 700/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2685 - val_loss: 3.3417\n",
            "Epoch 701/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.2563 - val_loss: 8.9109\n",
            "Epoch 702/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1826 - val_loss: 6.4327\n",
            "Epoch 703/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1569 - val_loss: 1.8404\n",
            "Epoch 704/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1805 - val_loss: 3.8767\n",
            "Epoch 705/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.2373 - val_loss: 10.2945\n",
            "Epoch 706/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1672 - val_loss: 6.3088\n",
            "Epoch 707/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2104 - val_loss: 1.5578\n",
            "Epoch 708/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1842 - val_loss: 7.4065\n",
            "Epoch 709/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.2656 - val_loss: 1.6628\n",
            "Epoch 710/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1876 - val_loss: 1.7959\n",
            "Epoch 711/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2105 - val_loss: 3.6067\n",
            "Epoch 712/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1488 - val_loss: 3.9824\n",
            "Epoch 713/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0821 - val_loss: 3.0052\n",
            "Epoch 714/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0429 - val_loss: 1.6754\n",
            "Epoch 715/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0476 - val_loss: 1.2310\n",
            "Epoch 716/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0447 - val_loss: 2.2248\n",
            "Epoch 717/1000\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0153 - val_loss: 1.7286\n",
            "Epoch 718/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0455 - val_loss: 2.1213\n",
            "Epoch 719/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0319 - val_loss: 3.3992\n",
            "Epoch 720/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0343 - val_loss: 4.4141\n",
            "Epoch 721/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0944 - val_loss: 6.9207\n",
            "Epoch 722/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1405 - val_loss: 2.1243\n",
            "Epoch 723/1000\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1865 - val_loss: 7.5322\n",
            "Epoch 724/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0746 - val_loss: 6.2398\n",
            "Epoch 725/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0682 - val_loss: 3.3812\n",
            "Epoch 726/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1431 - val_loss: 4.3457\n",
            "Epoch 727/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1114 - val_loss: 3.7956\n",
            "Epoch 728/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0800 - val_loss: 1.0804\n",
            "Epoch 729/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0964 - val_loss: 3.6163\n",
            "Epoch 730/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0441 - val_loss: 4.0935\n",
            "Epoch 731/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0304 - val_loss: 3.7067\n",
            "Epoch 732/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0243 - val_loss: 1.0260\n",
            "Epoch 733/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0330 - val_loss: 1.2763\n",
            "Epoch 734/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0606 - val_loss: 3.0607\n",
            "Epoch 735/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0531 - val_loss: 6.1316\n",
            "Epoch 736/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1135 - val_loss: 2.7394\n",
            "Epoch 737/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0925 - val_loss: 5.5117\n",
            "Epoch 738/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1132 - val_loss: 2.2999\n",
            "Epoch 739/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1151 - val_loss: 6.6504\n",
            "Epoch 740/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1192 - val_loss: 1.9763\n",
            "Epoch 741/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.1732 - val_loss: 3.9594\n",
            "Epoch 742/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.1366 - val_loss: 4.7128\n",
            "Epoch 743/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0919 - val_loss: 3.1344\n",
            "Epoch 744/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1078 - val_loss: 5.2197\n",
            "Epoch 745/1000\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 0.0474 - val_loss: 2.8372\n",
            "Epoch 746/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0445 - val_loss: 2.1210\n",
            "Epoch 747/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0805 - val_loss: 3.4209\n",
            "Epoch 748/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0973 - val_loss: 5.2747\n",
            "Epoch 749/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0669 - val_loss: 4.4194\n",
            "Epoch 750/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2453 - val_loss: 1.7102\n",
            "Epoch 751/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1685 - val_loss: 8.4359\n",
            "Epoch 752/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0666 - val_loss: 4.6418\n",
            "Epoch 753/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.0560 - val_loss: 7.8649\n",
            "Epoch 754/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1758 - val_loss: 0.5230\n",
            "Epoch 755/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.6526 - val_loss: 12.1467\n",
            "Epoch 756/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.5456 - val_loss: 2.0889\n",
            "Epoch 757/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3933 - val_loss: 0.8063\n",
            "Epoch 758/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.2069 - val_loss: 4.1259\n",
            "Epoch 759/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1203 - val_loss: 2.6585\n",
            "Epoch 760/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0560 - val_loss: 2.4353\n",
            "Epoch 761/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0414 - val_loss: 0.9870\n",
            "Epoch 762/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1231 - val_loss: 3.7923\n",
            "Epoch 763/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0983 - val_loss: 2.2530\n",
            "Epoch 764/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0372 - val_loss: 4.2877\n",
            "Epoch 765/1000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 0.0257 - val_loss: 4.4026\n",
            "Epoch 766/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.0453 - val_loss: 3.4200\n",
            "Epoch 767/1000\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 0.0280 - val_loss: 1.3339\n",
            "Epoch 768/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0171 - val_loss: 1.2521\n",
            "Epoch 769/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0400 - val_loss: 2.3182\n",
            "Epoch 770/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0257 - val_loss: 2.1752\n",
            "Epoch 771/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0138 - val_loss: 0.7537\n",
            "Epoch 772/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0796 - val_loss: 4.5363\n",
            "Epoch 773/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0661 - val_loss: 4.0324\n",
            "Epoch 774/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0926 - val_loss: 4.0321\n",
            "Epoch 775/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1118 - val_loss: 3.1130\n",
            "Epoch 776/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0742 - val_loss: 2.5757\n",
            "Epoch 777/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0592 - val_loss: 4.1546\n",
            "Epoch 778/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0504 - val_loss: 3.4201\n",
            "Epoch 779/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0327 - val_loss: 3.8382\n",
            "Epoch 780/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0595 - val_loss: 2.4171\n",
            "Epoch 781/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0616 - val_loss: 0.6751\n",
            "Epoch 782/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1039 - val_loss: 1.8017\n",
            "Epoch 783/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0289 - val_loss: 2.9272\n",
            "Epoch 784/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0319 - val_loss: 2.2022\n",
            "Epoch 785/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2919 - val_loss: 3.1505\n",
            "Epoch 786/1000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 0.0923 - val_loss: 7.4860\n",
            "Epoch 787/1000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.1399 - val_loss: 3.5965\n",
            "Epoch 788/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0726 - val_loss: 1.9054\n",
            "Epoch 789/1000\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.1371 - val_loss: 5.3656\n",
            "Epoch 790/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0598 - val_loss: 3.7690\n",
            "Epoch 791/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0250 - val_loss: 2.4988\n",
            "Epoch 792/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0292 - val_loss: 4.5219\n",
            "Epoch 793/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0639 - val_loss: 3.9226\n",
            "Epoch 794/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0295 - val_loss: 1.4581\n",
            "Epoch 795/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0372 - val_loss: 3.1432\n",
            "Epoch 796/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0407 - val_loss: 4.8880\n",
            "Epoch 797/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0640 - val_loss: 4.0685\n",
            "Epoch 798/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0457 - val_loss: 4.3510\n",
            "Epoch 799/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1386 - val_loss: 4.1496\n",
            "Epoch 800/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1273 - val_loss: 1.6098\n",
            "Epoch 801/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1046 - val_loss: 2.6219\n",
            "Epoch 802/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1437 - val_loss: 5.9955\n",
            "Epoch 803/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0588 - val_loss: 6.9737\n",
            "Epoch 804/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0675 - val_loss: 6.4634\n",
            "Epoch 805/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1668 - val_loss: 3.4992\n",
            "Epoch 806/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1909 - val_loss: 6.4123\n",
            "Epoch 807/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.3181 - val_loss: 1.1604\n",
            "Epoch 808/1000\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 0.4028 - val_loss: 7.2665\n",
            "Epoch 809/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.2187 - val_loss: 5.4255\n",
            "Epoch 810/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.1606 - val_loss: 1.7505\n",
            "Epoch 811/1000\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.2381 - val_loss: 7.2564\n",
            "Epoch 812/1000\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 0.2576 - val_loss: 3.8628\n",
            "Epoch 813/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2863 - val_loss: 3.6757\n",
            "Epoch 814/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.3713 - val_loss: 6.3152\n",
            "Epoch 815/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1946 - val_loss: 4.0193\n",
            "Epoch 816/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2087 - val_loss: 1.9117\n",
            "Epoch 817/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2138 - val_loss: 6.7377\n",
            "Epoch 818/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2302 - val_loss: 2.1339\n",
            "Epoch 819/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1047 - val_loss: 2.2700\n",
            "Epoch 820/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0532 - val_loss: 1.4975\n",
            "Epoch 821/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0314 - val_loss: 1.6291\n",
            "Epoch 822/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0107 - val_loss: 1.6043\n",
            "Epoch 823/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0970 - val_loss: 3.0199\n",
            "Epoch 824/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0648 - val_loss: 2.0009\n",
            "Epoch 825/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1462 - val_loss: 1.2210\n",
            "Epoch 826/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.1406 - val_loss: 5.8006\n",
            "Epoch 827/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0501 - val_loss: 3.8312\n",
            "Epoch 828/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0782 - val_loss: 4.9244\n",
            "Epoch 829/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1023 - val_loss: 4.2867\n",
            "Epoch 830/1000\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 0.1263 - val_loss: 3.1302\n",
            "Epoch 831/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.2130 - val_loss: 3.4637\n",
            "Epoch 832/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.2405 - val_loss: 10.2609\n",
            "Epoch 833/1000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 0.2041 - val_loss: 5.5262\n",
            "Epoch 834/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0856 - val_loss: 4.4413\n",
            "Epoch 835/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0396 - val_loss: 2.6602\n",
            "Epoch 836/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0619 - val_loss: 3.4587\n",
            "Epoch 837/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0604 - val_loss: 3.0402\n",
            "Epoch 838/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0840 - val_loss: 3.0560\n",
            "Epoch 839/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0486 - val_loss: 4.7030\n",
            "Epoch 840/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0395 - val_loss: 5.2680\n",
            "Epoch 841/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0656 - val_loss: 2.9177\n",
            "Epoch 842/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0518 - val_loss: 1.2146\n",
            "Epoch 843/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0775 - val_loss: 2.1433\n",
            "Epoch 844/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0273 - val_loss: 2.6224\n",
            "Epoch 845/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0189 - val_loss: 1.5065\n",
            "Epoch 846/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0354 - val_loss: 3.3058\n",
            "Epoch 847/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2158 - val_loss: 8.4998\n",
            "Epoch 848/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.2039 - val_loss: 1.8417\n",
            "Epoch 849/1000\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0719 - val_loss: 5.1715\n",
            "Epoch 850/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.1255 - val_loss: 1.7911\n",
            "Epoch 851/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0646 - val_loss: 4.5193\n",
            "Epoch 852/1000\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 0.0339 - val_loss: 3.5984\n",
            "Epoch 853/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0355 - val_loss: 1.6639\n",
            "Epoch 854/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0309 - val_loss: 2.8893\n",
            "Epoch 855/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0224 - val_loss: 3.0358\n",
            "Epoch 856/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.1309 - val_loss: 2.5498\n",
            "Epoch 857/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0898 - val_loss: 3.4169\n",
            "Epoch 858/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0364 - val_loss: 3.0485\n",
            "Epoch 859/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0566 - val_loss: 1.9378\n",
            "Epoch 860/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.1658 - val_loss: 9.1884\n",
            "Epoch 861/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.3207 - val_loss: 0.7091\n",
            "Epoch 862/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.4298 - val_loss: 16.0227\n",
            "Epoch 863/1000\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.3127 - val_loss: 7.6595\n",
            "Epoch 864/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1412 - val_loss: 2.6036\n",
            "Epoch 865/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0646 - val_loss: 4.6517\n",
            "Epoch 866/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0469 - val_loss: 2.0638\n",
            "Epoch 867/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0521 - val_loss: 2.2389\n",
            "Epoch 868/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.0475 - val_loss: 3.7382\n",
            "Epoch 869/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0309 - val_loss: 3.7425\n",
            "Epoch 870/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.0483 - val_loss: 2.7462\n",
            "Epoch 871/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0432 - val_loss: 2.3402\n",
            "Epoch 872/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0336 - val_loss: 1.1617\n",
            "Epoch 873/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0332 - val_loss: 1.8055\n",
            "Epoch 874/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0164 - val_loss: 1.4222\n",
            "Epoch 875/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0576 - val_loss: 3.9128\n",
            "Epoch 876/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0722 - val_loss: 1.4649\n",
            "Epoch 877/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0945 - val_loss: 2.5614\n",
            "Epoch 878/1000\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 0.1248 - val_loss: 2.6372\n",
            "Epoch 879/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0511 - val_loss: 5.7935\n",
            "Epoch 880/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0331 - val_loss: 3.0465\n",
            "Epoch 881/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0301 - val_loss: 1.6741\n",
            "Epoch 882/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0582 - val_loss: 1.9802\n",
            "Epoch 883/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0421 - val_loss: 2.3955\n",
            "Epoch 884/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0308 - val_loss: 2.2233\n",
            "Epoch 885/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0277 - val_loss: 1.9313\n",
            "Epoch 886/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0936 - val_loss: 13.4301\n",
            "Epoch 887/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.4815 - val_loss: 2.2525\n",
            "Epoch 888/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.5148 - val_loss: 10.0118\n",
            "Epoch 889/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.8419 - val_loss: 19.1991\n",
            "Epoch 890/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.7464 - val_loss: 3.3244\n",
            "Epoch 891/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.3081 - val_loss: 0.9137\n",
            "Epoch 892/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1858 - val_loss: 2.8445\n",
            "Epoch 893/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0505 - val_loss: 5.7376\n",
            "Epoch 894/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0373 - val_loss: 3.7699\n",
            "Epoch 895/1000\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.0299 - val_loss: 3.4186\n",
            "Epoch 896/1000\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 0.0216 - val_loss: 1.6856\n",
            "Epoch 897/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0449 - val_loss: 3.3760\n",
            "Epoch 898/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0574 - val_loss: 2.3624\n",
            "Epoch 899/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0713 - val_loss: 1.0299\n",
            "Epoch 900/1000\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.1398 - val_loss: 4.3506\n",
            "Epoch 901/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0610 - val_loss: 4.6191\n",
            "Epoch 902/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0501 - val_loss: 4.2928\n",
            "Epoch 903/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0696 - val_loss: 6.4262\n",
            "Epoch 904/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1485 - val_loss: 7.0993\n",
            "Epoch 905/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.1087 - val_loss: 5.1134\n",
            "Epoch 906/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0510 - val_loss: 3.3835\n",
            "Epoch 907/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0384 - val_loss: 2.9266\n",
            "Epoch 908/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0564 - val_loss: 4.7412\n",
            "Epoch 909/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1470 - val_loss: 4.0477\n",
            "Epoch 910/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0479 - val_loss: 3.0915\n",
            "Epoch 911/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0519 - val_loss: 2.8761\n",
            "Epoch 912/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0494 - val_loss: 3.0952\n",
            "Epoch 913/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0262 - val_loss: 3.2215\n",
            "Epoch 914/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0365 - val_loss: 3.3466\n",
            "Epoch 915/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0476 - val_loss: 0.6260\n",
            "Epoch 916/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0979 - val_loss: 2.5987\n",
            "Epoch 917/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0440 - val_loss: 3.3228\n",
            "Epoch 918/1000\n",
            "10/10 [==============================] - 1s 92ms/step - loss: 0.0319 - val_loss: 2.5904\n",
            "Epoch 919/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0367 - val_loss: 3.1243\n",
            "Epoch 920/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0481 - val_loss: 4.2144\n",
            "Epoch 921/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0579 - val_loss: 4.8719\n",
            "Epoch 922/1000\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 0.1558 - val_loss: 2.5719\n",
            "Epoch 923/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0967 - val_loss: 7.9542\n",
            "Epoch 924/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1016 - val_loss: 2.5248\n",
            "Epoch 925/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0853 - val_loss: 7.0076\n",
            "Epoch 926/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0655 - val_loss: 2.9322\n",
            "Epoch 927/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0377 - val_loss: 3.2427\n",
            "Epoch 928/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0232 - val_loss: 3.5257\n",
            "Epoch 929/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0595 - val_loss: 5.0428\n",
            "Epoch 930/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1042 - val_loss: 1.2719\n",
            "Epoch 931/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.1159 - val_loss: 2.1012\n",
            "Epoch 932/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0458 - val_loss: 3.1491\n",
            "Epoch 933/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0256 - val_loss: 1.1739\n",
            "Epoch 934/1000\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.0370 - val_loss: 1.0421\n",
            "Epoch 935/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0892 - val_loss: 2.4189\n",
            "Epoch 936/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0813 - val_loss: 8.0968\n",
            "Epoch 937/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.4454 - val_loss: 3.3604\n",
            "Epoch 938/1000\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.3829 - val_loss: 14.7501\n",
            "Epoch 939/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3709 - val_loss: 1.7529\n",
            "Epoch 940/1000\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 0.1836 - val_loss: 2.3909\n",
            "Epoch 941/1000\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.0735 - val_loss: 3.2742\n",
            "Epoch 942/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0505 - val_loss: 4.2516\n",
            "Epoch 943/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0434 - val_loss: 3.2150\n",
            "Epoch 944/1000\n",
            "10/10 [==============================] - 1s 81ms/step - loss: 0.0933 - val_loss: 3.3522\n",
            "Epoch 945/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0957 - val_loss: 3.7595\n",
            "Epoch 946/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0459 - val_loss: 2.5834\n",
            "Epoch 947/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0347 - val_loss: 3.5514\n",
            "Epoch 948/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0253 - val_loss: 3.1876\n",
            "Epoch 949/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0255 - val_loss: 3.6539\n",
            "Epoch 950/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0248 - val_loss: 3.7771\n",
            "Epoch 951/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0199 - val_loss: 2.0634\n",
            "Epoch 952/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0412 - val_loss: 1.4355\n",
            "Epoch 953/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0555 - val_loss: 2.7811\n",
            "Epoch 954/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0480 - val_loss: 1.3460\n",
            "Epoch 955/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.2143 - val_loss: 1.2309\n",
            "Epoch 956/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.1601 - val_loss: 8.8099\n",
            "Epoch 957/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.2562 - val_loss: 1.7354\n",
            "Epoch 958/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1153 - val_loss: 2.3696\n",
            "Epoch 959/1000\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.0912 - val_loss: 4.1778\n",
            "Epoch 960/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1269 - val_loss: 0.9759\n",
            "Epoch 961/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0791 - val_loss: 2.6731\n",
            "Epoch 962/1000\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 0.0183 - val_loss: 2.8711\n",
            "Epoch 963/1000\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0178 - val_loss: 2.0731\n",
            "Epoch 964/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0681 - val_loss: 4.2591\n",
            "Epoch 965/1000\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 0.0443 - val_loss: 3.2654\n",
            "Epoch 966/1000\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.0400 - val_loss: 2.7387\n",
            "Epoch 967/1000\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.0247 - val_loss: 1.9904\n",
            "Epoch 968/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0162 - val_loss: 3.1528\n",
            "Epoch 969/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1126 - val_loss: 2.6647\n",
            "Epoch 970/1000\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.1544 - val_loss: 1.2460\n",
            "Epoch 971/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1004 - val_loss: 3.2507\n",
            "Epoch 972/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0957 - val_loss: 3.5296\n",
            "Epoch 973/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0583 - val_loss: 4.3138\n",
            "Epoch 974/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0414 - val_loss: 2.0198\n",
            "Epoch 975/1000\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0373 - val_loss: 3.6617\n",
            "Epoch 976/1000\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.0460 - val_loss: 2.7644\n",
            "Epoch 977/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0133 - val_loss: 2.9332\n",
            "Epoch 978/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1062 - val_loss: 6.3185\n",
            "Epoch 979/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1271 - val_loss: 4.3920\n",
            "Epoch 980/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0610 - val_loss: 4.0405\n",
            "Epoch 981/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0571 - val_loss: 6.5049\n",
            "Epoch 982/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0757 - val_loss: 1.9877\n",
            "Epoch 983/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0592 - val_loss: 2.3419\n",
            "Epoch 984/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0274 - val_loss: 1.2056\n",
            "Epoch 985/1000\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0248 - val_loss: 2.4911\n",
            "Epoch 986/1000\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 0.0229 - val_loss: 1.4476\n",
            "Epoch 987/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.0236 - val_loss: 1.7632\n",
            "Epoch 988/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.0295 - val_loss: 2.8121\n",
            "Epoch 989/1000\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0862 - val_loss: 1.1059\n",
            "Epoch 990/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0797 - val_loss: 2.6208\n",
            "Epoch 991/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0643 - val_loss: 2.2796\n",
            "Epoch 992/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0996 - val_loss: 4.5293\n",
            "Epoch 993/1000\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0588 - val_loss: 7.2943\n",
            "Epoch 994/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0793 - val_loss: 3.6785\n",
            "Epoch 995/1000\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0258 - val_loss: 1.8277\n",
            "Epoch 996/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0243 - val_loss: 1.9247\n",
            "Epoch 997/1000\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0159 - val_loss: 2.9677\n",
            "Epoch 998/1000\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1390 - val_loss: 1.5068\n",
            "Epoch 999/1000\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2437 - val_loss: 9.1881\n",
            "Epoch 1000/1000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.2248 - val_loss: 3.1163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions1 = model1.predict(X_test).flatten()\n",
        "print(X_test)\n",
        "print(test_predictions1)\n",
        "test_results1 = pd.DataFrame(data={'Test Predictions':test_predictions1, 'Actuals':y_test})\n",
        "test_results1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17359
        },
        "id": "pz1804itVZIc",
        "outputId": "0df5ffbc-12a9-4e03-c328-597071478ba9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 15ms/step\n",
            "[[[-52.94254394]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.81489992]]\n",
            "\n",
            " [[-52.88708726]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.51608985]]\n",
            "\n",
            " [[-52.60044764]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.29292731]]\n",
            "\n",
            " [[-52.33492506]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.23353711]]\n",
            "\n",
            " [[-52.24231336]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.04834217]]\n",
            "\n",
            " [[-52.13477904]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.76476912]]\n",
            "\n",
            " [[-51.86362927]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.39765302]]\n",
            "\n",
            " [[-51.50380818]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-50.95934366]]\n",
            "\n",
            " [[-51.12406141]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.52028511]]\n",
            "\n",
            " [[-50.63190611]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.32102036]]\n",
            "\n",
            " [[-50.39314855]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.17800432]]\n",
            "\n",
            " [[-50.21361806]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.23953497]]\n",
            "\n",
            " [[-50.19222253]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.31435931]]\n",
            "\n",
            " [[-50.30050696]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.35472481]]\n",
            "\n",
            " [[-50.31407465]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.46116092]]\n",
            "\n",
            " [[-50.4557992 ]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.47873973]]\n",
            "\n",
            " [[-50.44526228]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.57181662]]\n",
            "\n",
            " [[-50.51426964]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.56639203]]\n",
            "\n",
            " [[-50.59594105]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.5904813 ]]\n",
            "\n",
            " [[-50.59259916]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.58215956]]\n",
            "\n",
            " [[-50.61262053]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.49779211]]\n",
            "\n",
            " [[-50.55190157]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.45489693]]\n",
            "\n",
            " [[-50.47799735]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.3418331 ]]\n",
            "\n",
            " [[-50.38692228]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32314603]]\n",
            "\n",
            " [[-50.3386263 ]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.12666277]]\n",
            "\n",
            " [[-50.21551764]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-49.88563774]]\n",
            "\n",
            " [[-49.98825503]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.65983005]]\n",
            "\n",
            " [[-49.72168448]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.49126724]]\n",
            "\n",
            " [[-49.57107513]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.12791664]]\n",
            "\n",
            " [[-49.268317  ]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-48.84778164]]\n",
            "\n",
            " [[-48.9450186 ]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.49057878]]\n",
            "\n",
            " [[-48.59411711]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.16485851]]\n",
            "\n",
            " [[-48.2762883 ]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-47.72166797]]\n",
            "\n",
            " [[-47.88634427]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.23339338]]\n",
            "\n",
            " [[-47.39570791]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-46.70607824]]\n",
            "\n",
            " [[-46.8635764 ]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.42456394]]\n",
            "\n",
            " [[-46.48813738]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.11208461]]\n",
            "\n",
            " [[-46.23522767]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.64289674]]\n",
            "\n",
            " [[-45.81482812]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.13680959]]\n",
            "\n",
            " [[-45.30442265]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.55207459]]\n",
            "\n",
            " [[-44.75972774]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-43.99737766]]\n",
            "\n",
            " [[-44.14849027]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.45866853]]\n",
            "\n",
            " [[-43.6515354 ]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.07369114]]\n",
            "\n",
            " [[-43.17138003]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-42.85558873]]\n",
            "\n",
            " [[-42.91604475]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82949152]]\n",
            "\n",
            " [[-42.81357566]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.8698309 ]]\n",
            "\n",
            " [[-42.88137509]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.74973605]]\n",
            "\n",
            " [[-42.77928676]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.67308156]]\n",
            "\n",
            " [[-42.67324626]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.53682594]]\n",
            "\n",
            " [[-42.60346389]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.36059734]]\n",
            "\n",
            " [[-42.3924243 ]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.27284582]]\n",
            "\n",
            " [[-42.32421582]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.00182017]]\n",
            "\n",
            " [[-42.11042659]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.66737955]]\n",
            "\n",
            " [[-41.78064636]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.23345086]]\n",
            "\n",
            " [[-41.39278482]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-40.93530953]]\n",
            "\n",
            " [[-41.00623524]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.74268538]]\n",
            "\n",
            " [[-40.82633027]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.64921066]]\n",
            "\n",
            " [[-40.65543448]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.50099505]]\n",
            "\n",
            " [[-40.57066117]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.31654622]]\n",
            "\n",
            " [[-40.35168421]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.09229517]]\n",
            "\n",
            " [[-40.18562754]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.75803577]]\n",
            "\n",
            " [[-39.85548689]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.49426632]]\n",
            "\n",
            " [[-39.59978385]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.16956091]]\n",
            "\n",
            " [[-39.27949443]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.00183798]]\n",
            "\n",
            " [[-39.03210104]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.79286547]]\n",
            "\n",
            " [[-38.88101188]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.55408711]]\n",
            "\n",
            " [[-38.65149641]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.16758928]]\n",
            "\n",
            " [[-38.31115667]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-37.70150032]]\n",
            "\n",
            " [[-37.84072128]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.2052172 ]]\n",
            "\n",
            " [[-37.38292544]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-36.64899535]]\n",
            "\n",
            " [[-36.81672447]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.19671571]]\n",
            "\n",
            " [[-36.36037863]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-35.67888299]]\n",
            "\n",
            " [[-35.8345917 ]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.25887846]]\n",
            "\n",
            " [[-35.41219674]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-34.92584627]]\n",
            "\n",
            " [[-35.03800122]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.50543465]]\n",
            "\n",
            " [[-34.65870424]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.09199801]]\n",
            "\n",
            " [[-34.2429866 ]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.56928687]]\n",
            "\n",
            " [[-33.7544275 ]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.03429144]]\n",
            "\n",
            " [[-33.20978726]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.4874653 ]]\n",
            "\n",
            " [[-32.6525533 ]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.04235085]]\n",
            "\n",
            " [[-32.20283678]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.53634936]]\n",
            "\n",
            " [[-31.68863635]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.01312605]]\n",
            "\n",
            " [[-31.19791608]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.59185077]]\n",
            "\n",
            " [[-30.73142468]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.1035144 ]]\n",
            "\n",
            " [[-30.27719051]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.52474784]]\n",
            "\n",
            " [[-29.72670125]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-28.8711147 ]]\n",
            "\n",
            " [[-29.09645822]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.15566643]]\n",
            "\n",
            " [[-28.40030288]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.4272172 ]]\n",
            "\n",
            " [[-27.64983596]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-26.79385472]]\n",
            "\n",
            " [[-26.99990222]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.16934236]]\n",
            "\n",
            " [[-26.35927849]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-25.65763892]]\n",
            "\n",
            " [[-25.8379374 ]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.245207  ]]\n",
            "\n",
            " [[-25.38169345]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-24.84318559]]\n",
            "\n",
            " [[-24.97637812]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.48777984]]\n",
            "\n",
            " [[-24.5804586 ]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.13010756]]\n",
            "\n",
            " [[-24.2618252 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.74114588]]]\n",
            "[-53.205975 -52.98445  -52.69904  -52.551037 -52.43664  -52.19721\n",
            " -51.859447 -51.456593 -50.981647 -50.652046 -50.462646 -50.393322\n",
            " -50.46202  -50.514645 -50.611813 -50.65801  -50.706715 -50.780006\n",
            " -50.7932   -50.810326 -50.770317 -50.694366 -50.60902  -50.542118\n",
            " -50.442123 -50.2297   -49.973934 -49.77521  -49.50323  -49.167194\n",
            " -48.824596 -48.473362 -48.085423 -47.596    -47.062046 -46.637375\n",
            " -46.33958  -45.937702 -45.42418  -44.863308 -44.251614 -43.706074\n",
            " -43.219807 -42.91987  -42.786198 -42.81036  -42.752705 -42.64433\n",
            " -42.55492  -42.374317 -42.266407 -42.072155 -41.749622 -41.353943\n",
            " -40.970028 -40.74624  -40.582302 -40.47068  -40.275974 -40.08541\n",
            " -39.77257  -39.492096 -39.16686  -38.92145  -38.74175  -38.512623\n",
            " -38.161835 -37.68501  -37.193535 -36.595562 -36.127205 -35.560272\n",
            " -35.135143 -34.772743 -34.355145 -33.92024  -33.366436 -32.78349\n",
            " -32.198475 -31.766218 -31.206036 -30.686707 -30.234726 -29.750275\n",
            " -29.170776 -28.538412 -27.856419 -27.131287 -26.485992 -25.862772\n",
            " -25.348312 -24.905746 -24.506554 -24.126835 -23.806889 -23.412708]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Test Predictions    Actuals\n",
              "0         -53.205975 -52.718817\n",
              "1         -52.984451 -52.408805\n",
              "2         -52.699039 -52.281384\n",
              "3         -52.551037 -52.197083\n",
              "4         -52.436642 -51.939383\n",
              "..               ...        ...\n",
              "91        -24.905746 -25.097316\n",
              "92        -24.506554 -24.698456\n",
              "93        -24.126835 -24.381302\n",
              "94        -23.806889 -23.986863\n",
              "95        -23.412708 -23.986863\n",
              "\n",
              "[96 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f76e53ff-22b6-4713-bd75-dd946cfe3de4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Predictions</th>\n",
              "      <th>Actuals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-53.205975</td>\n",
              "      <td>-52.718817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-52.984451</td>\n",
              "      <td>-52.408805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-52.699039</td>\n",
              "      <td>-52.281384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-52.551037</td>\n",
              "      <td>-52.197083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-52.436642</td>\n",
              "      <td>-51.939383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>-24.905746</td>\n",
              "      <td>-25.097316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>-24.506554</td>\n",
              "      <td>-24.698456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>-24.126835</td>\n",
              "      <td>-24.381302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>-23.806889</td>\n",
              "      <td>-23.986863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>-23.412708</td>\n",
              "      <td>-23.986863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f76e53ff-22b6-4713-bd75-dd946cfe3de4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f76e53ff-22b6-4713-bd75-dd946cfe3de4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f76e53ff-22b6-4713-bd75-dd946cfe3de4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acdc7b5f-cb42-4aee-9f11-1a04d3fe47be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acdc7b5f-cb42-4aee-9f11-1a04d3fe47be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acdc7b5f-cb42-4aee-9f11-1a04d3fe47be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e3ed5c42-f922-4377-b33b-4c5f7d11cf4e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_results1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e3ed5c42-f922-4377-b33b-4c5f7d11cf4e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_results1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_results1",
              "summary": "{\n  \"name\": \"test_results1\",\n  \"rows\": 96,\n  \"fields\": [\n    {\n      \"column\": \"Test Predictions\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          -31.206035614013672,\n          -32.78348922729492,\n          -34.772743225097656\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actuals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.490652520995768,\n        \"min\": -52.71881690914811,\n        \"max\": -23.986862897951863,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          -37.01624714653313,\n          -50.3261774912853,\n          -35.134646999199404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_results1['Test Predictions'],color='blue',marker='o')\n",
        "plt.plot(test_results1['Actuals'],color='red',marker='s')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "fGQUr6_UVkiV",
        "outputId": "15af1fe5-8a3e-4940-afdc-9737826287ff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x792b28be3a30>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6jwesbNBVunf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(9, 1)))\n",
        "model2.add(Dense(1))\n",
        "model2.compile(optimizer='adam', loss='mse')\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "76b990e9-c3f5-43f5-a7a8-c28db12fab00",
        "id": "9gF2wJ14V59B"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirection  (None, 100)               20800     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20901 (81.64 KB)\n",
            "Trainable params: 20901 (81.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(X_train, y_train, epochs=1000, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "59a39ae1-5267-40ee-fb2f-d30867cf0dcd",
        "id": "ETI2FyYgV59I"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "10/10 [==============================] - 4s 89ms/step - loss: 900.2759 - val_loss: 1389.5243\n",
            "Epoch 2/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 120.7165 - val_loss: 170.4058\n",
            "Epoch 3/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 18.7764 - val_loss: 30.8430\n",
            "Epoch 4/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 2.7523 - val_loss: 14.8692\n",
            "Epoch 5/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 1.5635 - val_loss: 4.6921\n",
            "Epoch 6/1000\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6309 - val_loss: 7.2375\n",
            "Epoch 7/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.4443 - val_loss: 2.0643\n",
            "Epoch 8/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4313 - val_loss: 3.9905\n",
            "Epoch 9/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4052 - val_loss: 2.4926\n",
            "Epoch 10/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3758 - val_loss: 3.0565\n",
            "Epoch 11/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3640 - val_loss: 3.2135\n",
            "Epoch 12/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3525 - val_loss: 3.8973\n",
            "Epoch 13/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3468 - val_loss: 3.7778\n",
            "Epoch 14/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3352 - val_loss: 3.6644\n",
            "Epoch 15/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3357 - val_loss: 4.2740\n",
            "Epoch 16/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3248 - val_loss: 4.9910\n",
            "Epoch 17/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3292 - val_loss: 3.6243\n",
            "Epoch 18/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3125 - val_loss: 4.2339\n",
            "Epoch 19/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3018 - val_loss: 4.9779\n",
            "Epoch 20/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3036 - val_loss: 4.2388\n",
            "Epoch 21/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2911 - val_loss: 4.3738\n",
            "Epoch 22/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2814 - val_loss: 3.7489\n",
            "Epoch 23/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2966 - val_loss: 5.4620\n",
            "Epoch 24/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2872 - val_loss: 3.7615\n",
            "Epoch 25/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2811 - val_loss: 4.0447\n",
            "Epoch 26/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2841 - val_loss: 3.4470\n",
            "Epoch 27/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2796 - val_loss: 4.5799\n",
            "Epoch 28/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2521 - val_loss: 3.5226\n",
            "Epoch 29/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2426 - val_loss: 4.1810\n",
            "Epoch 30/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2392 - val_loss: 4.1050\n",
            "Epoch 31/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2528 - val_loss: 3.7497\n",
            "Epoch 32/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2365 - val_loss: 2.8298\n",
            "Epoch 33/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2294 - val_loss: 4.0745\n",
            "Epoch 34/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2149 - val_loss: 3.3934\n",
            "Epoch 35/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2178 - val_loss: 3.2848\n",
            "Epoch 36/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2024 - val_loss: 3.7374\n",
            "Epoch 37/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2144 - val_loss: 3.6808\n",
            "Epoch 38/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1969 - val_loss: 2.8088\n",
            "Epoch 39/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1828 - val_loss: 2.7186\n",
            "Epoch 40/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1798 - val_loss: 2.6660\n",
            "Epoch 41/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1748 - val_loss: 3.1127\n",
            "Epoch 42/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1697 - val_loss: 3.3357\n",
            "Epoch 43/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1638 - val_loss: 2.7079\n",
            "Epoch 44/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1552 - val_loss: 3.0469\n",
            "Epoch 45/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1515 - val_loss: 2.2926\n",
            "Epoch 46/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1451 - val_loss: 2.6746\n",
            "Epoch 47/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1449 - val_loss: 3.3804\n",
            "Epoch 48/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1490 - val_loss: 3.2235\n",
            "Epoch 49/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1397 - val_loss: 3.0844\n",
            "Epoch 50/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1417 - val_loss: 2.6334\n",
            "Epoch 51/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1416 - val_loss: 2.8601\n",
            "Epoch 52/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1570 - val_loss: 2.0002\n",
            "Epoch 53/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1537 - val_loss: 2.3721\n",
            "Epoch 54/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1382 - val_loss: 2.8808\n",
            "Epoch 55/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1381 - val_loss: 2.8885\n",
            "Epoch 56/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1290 - val_loss: 2.6308\n",
            "Epoch 57/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1195 - val_loss: 3.3204\n",
            "Epoch 58/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1193 - val_loss: 2.7301\n",
            "Epoch 59/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1202 - val_loss: 2.4450\n",
            "Epoch 60/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1286 - val_loss: 3.0525\n",
            "Epoch 61/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1252 - val_loss: 3.5693\n",
            "Epoch 62/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1237 - val_loss: 3.5648\n",
            "Epoch 63/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1347 - val_loss: 3.3901\n",
            "Epoch 64/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1225 - val_loss: 3.7476\n",
            "Epoch 65/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1212 - val_loss: 3.2442\n",
            "Epoch 66/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1033 - val_loss: 4.1281\n",
            "Epoch 67/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1111 - val_loss: 2.8727\n",
            "Epoch 68/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1068 - val_loss: 2.6573\n",
            "Epoch 69/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0941 - val_loss: 3.7423\n",
            "Epoch 70/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0918 - val_loss: 2.8010\n",
            "Epoch 71/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0955 - val_loss: 3.4921\n",
            "Epoch 72/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0850 - val_loss: 3.1953\n",
            "Epoch 73/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0806 - val_loss: 3.4568\n",
            "Epoch 74/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0852 - val_loss: 2.5141\n",
            "Epoch 75/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0715 - val_loss: 2.9032\n",
            "Epoch 76/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0689 - val_loss: 3.1056\n",
            "Epoch 77/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0617 - val_loss: 2.5821\n",
            "Epoch 78/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0788 - val_loss: 2.7143\n",
            "Epoch 79/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0817 - val_loss: 4.1167\n",
            "Epoch 80/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0783 - val_loss: 2.9549\n",
            "Epoch 81/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0745 - val_loss: 4.6059\n",
            "Epoch 82/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0854 - val_loss: 3.0297\n",
            "Epoch 83/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0587 - val_loss: 2.1596\n",
            "Epoch 84/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0625 - val_loss: 1.9469\n",
            "Epoch 85/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0650 - val_loss: 2.9790\n",
            "Epoch 86/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0524 - val_loss: 3.4979\n",
            "Epoch 87/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0710 - val_loss: 3.0740\n",
            "Epoch 88/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0816 - val_loss: 2.4663\n",
            "Epoch 89/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0816 - val_loss: 3.7323\n",
            "Epoch 90/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0581 - val_loss: 2.4557\n",
            "Epoch 91/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0558 - val_loss: 3.0545\n",
            "Epoch 92/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0399 - val_loss: 2.4454\n",
            "Epoch 93/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0321 - val_loss: 2.9567\n",
            "Epoch 94/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0291 - val_loss: 2.9750\n",
            "Epoch 95/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0308 - val_loss: 3.2952\n",
            "Epoch 96/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0404 - val_loss: 3.1498\n",
            "Epoch 97/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0632 - val_loss: 3.2433\n",
            "Epoch 98/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0479 - val_loss: 2.7504\n",
            "Epoch 99/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0288 - val_loss: 2.7938\n",
            "Epoch 100/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0259 - val_loss: 2.8258\n",
            "Epoch 101/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0245 - val_loss: 2.8636\n",
            "Epoch 102/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0247 - val_loss: 3.5071\n",
            "Epoch 103/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0281 - val_loss: 2.9691\n",
            "Epoch 104/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0293 - val_loss: 2.8946\n",
            "Epoch 105/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0186 - val_loss: 3.4081\n",
            "Epoch 106/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0221 - val_loss: 2.7450\n",
            "Epoch 107/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0390 - val_loss: 2.4165\n",
            "Epoch 108/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 3.1683\n",
            "Epoch 109/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0377 - val_loss: 2.6398\n",
            "Epoch 110/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0470 - val_loss: 2.8204\n",
            "Epoch 111/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0560 - val_loss: 3.3029\n",
            "Epoch 112/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0401 - val_loss: 2.6857\n",
            "Epoch 113/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0217 - val_loss: 2.9965\n",
            "Epoch 114/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0211 - val_loss: 3.3995\n",
            "Epoch 115/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 3.6020\n",
            "Epoch 116/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 2.7019\n",
            "Epoch 117/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 3.0748\n",
            "Epoch 118/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 2.9993\n",
            "Epoch 119/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 3.0692\n",
            "Epoch 120/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 3.1825\n",
            "Epoch 121/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 2.7391\n",
            "Epoch 122/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 3.0035\n",
            "Epoch 123/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 2.9038\n",
            "Epoch 124/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 2.8386\n",
            "Epoch 125/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 2.9945\n",
            "Epoch 126/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0198 - val_loss: 2.7612\n",
            "Epoch 127/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0200 - val_loss: 2.6833\n",
            "Epoch 128/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 3.1462\n",
            "Epoch 129/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0176 - val_loss: 2.2771\n",
            "Epoch 130/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0185 - val_loss: 2.4861\n",
            "Epoch 131/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0184 - val_loss: 3.0915\n",
            "Epoch 132/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0164 - val_loss: 2.8692\n",
            "Epoch 133/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0164 - val_loss: 2.3657\n",
            "Epoch 134/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0238 - val_loss: 2.7919\n",
            "Epoch 135/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 2.7051\n",
            "Epoch 136/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 2.7352\n",
            "Epoch 137/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 2.6699\n",
            "Epoch 138/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 2.6428\n",
            "Epoch 139/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0173 - val_loss: 2.2374\n",
            "Epoch 140/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 3.1879\n",
            "Epoch 141/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 2.9567\n",
            "Epoch 142/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 2.2687\n",
            "Epoch 143/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0120 - val_loss: 2.4369\n",
            "Epoch 144/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0177 - val_loss: 2.5647\n",
            "Epoch 145/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0179 - val_loss: 3.5560\n",
            "Epoch 146/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 2.6908\n",
            "Epoch 147/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 2.4659\n",
            "Epoch 148/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0088 - val_loss: 2.6420\n",
            "Epoch 149/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 2.6481\n",
            "Epoch 150/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 2.6359\n",
            "Epoch 151/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 2.5625\n",
            "Epoch 152/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 3.2421\n",
            "Epoch 153/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 2.3510\n",
            "Epoch 154/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 2.3551\n",
            "Epoch 155/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 2.8090\n",
            "Epoch 156/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 2.9057\n",
            "Epoch 157/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 2.2868\n",
            "Epoch 158/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0127 - val_loss: 2.3496\n",
            "Epoch 159/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 2.3456\n",
            "Epoch 160/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 2.3552\n",
            "Epoch 161/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 2.5410\n",
            "Epoch 162/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0084 - val_loss: 2.6070\n",
            "Epoch 163/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 2.6870\n",
            "Epoch 164/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 2.0907\n",
            "Epoch 165/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 2.8055\n",
            "Epoch 166/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 2.8695\n",
            "Epoch 167/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 2.2082\n",
            "Epoch 168/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0112 - val_loss: 2.1678\n",
            "Epoch 169/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0112 - val_loss: 1.9190\n",
            "Epoch 170/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0211 - val_loss: 2.8207\n",
            "Epoch 171/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0231 - val_loss: 3.0143\n",
            "Epoch 172/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0163 - val_loss: 2.1541\n",
            "Epoch 173/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0204 - val_loss: 2.4467\n",
            "Epoch 174/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0222 - val_loss: 3.0978\n",
            "Epoch 175/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0214 - val_loss: 2.4594\n",
            "Epoch 176/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0234 - val_loss: 3.6482\n",
            "Epoch 177/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0162 - val_loss: 2.1811\n",
            "Epoch 178/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0112 - val_loss: 2.4072\n",
            "Epoch 179/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0100 - val_loss: 2.5312\n",
            "Epoch 180/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 2.4787\n",
            "Epoch 181/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0133 - val_loss: 2.0012\n",
            "Epoch 182/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0082 - val_loss: 2.7043\n",
            "Epoch 183/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 2.3681\n",
            "Epoch 184/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 2.3220\n",
            "Epoch 185/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0108 - val_loss: 2.2752\n",
            "Epoch 186/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 2.1333\n",
            "Epoch 187/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 2.3683\n",
            "Epoch 188/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 2.4087\n",
            "Epoch 189/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 2.3227\n",
            "Epoch 190/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 2.5615\n",
            "Epoch 191/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 2.8439\n",
            "Epoch 192/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 2.7079\n",
            "Epoch 193/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 2.1975\n",
            "Epoch 194/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 1.9897\n",
            "Epoch 195/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0113 - val_loss: 2.3372\n",
            "Epoch 196/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 2.4134\n",
            "Epoch 197/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 2.7124\n",
            "Epoch 198/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 1.7344\n",
            "Epoch 199/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 2.1839\n",
            "Epoch 200/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0087 - val_loss: 2.5644\n",
            "Epoch 201/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 2.3983\n",
            "Epoch 202/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0114 - val_loss: 2.3417\n",
            "Epoch 203/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 2.4735\n",
            "Epoch 204/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 2.7884\n",
            "Epoch 205/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 2.3636\n",
            "Epoch 206/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0193 - val_loss: 2.3751\n",
            "Epoch 207/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 2.3650\n",
            "Epoch 208/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 2.2753\n",
            "Epoch 209/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 2.4873\n",
            "Epoch 210/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 2.3726\n",
            "Epoch 211/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 2.2457\n",
            "Epoch 212/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 2.7503\n",
            "Epoch 213/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 2.6798\n",
            "Epoch 214/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0142 - val_loss: 2.1164\n",
            "Epoch 215/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0154 - val_loss: 2.4967\n",
            "Epoch 216/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 2.3877\n",
            "Epoch 217/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 3.0232\n",
            "Epoch 218/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 3.2756\n",
            "Epoch 219/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0166 - val_loss: 1.9578\n",
            "Epoch 220/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 1.7142\n",
            "Epoch 221/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 2.1737\n",
            "Epoch 222/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 2.7077\n",
            "Epoch 223/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0119 - val_loss: 2.3452\n",
            "Epoch 224/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 2.3140\n",
            "Epoch 225/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 2.0836\n",
            "Epoch 226/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 2.3186\n",
            "Epoch 227/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 1.9896\n",
            "Epoch 228/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 2.4780\n",
            "Epoch 229/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 2.1377\n",
            "Epoch 230/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0138 - val_loss: 2.2905\n",
            "Epoch 231/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 2.2351\n",
            "Epoch 232/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0128 - val_loss: 2.4060\n",
            "Epoch 233/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 2.3777\n",
            "Epoch 234/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 2.2833\n",
            "Epoch 235/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0122 - val_loss: 2.2024\n",
            "Epoch 236/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 2.4298\n",
            "Epoch 237/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0071 - val_loss: 2.0741\n",
            "Epoch 238/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 2.3417\n",
            "Epoch 239/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 2.3620\n",
            "Epoch 240/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 2.4565\n",
            "Epoch 241/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 2.1894\n",
            "Epoch 242/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0207 - val_loss: 2.1108\n",
            "Epoch 243/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0170 - val_loss: 3.0718\n",
            "Epoch 244/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0224 - val_loss: 2.0401\n",
            "Epoch 245/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 2.2007\n",
            "Epoch 246/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0185 - val_loss: 1.6585\n",
            "Epoch 247/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0182 - val_loss: 1.3780\n",
            "Epoch 248/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0102 - val_loss: 1.6743\n",
            "Epoch 249/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0150 - val_loss: 1.8123\n",
            "Epoch 250/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0231 - val_loss: 1.9242\n",
            "Epoch 251/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0228 - val_loss: 2.9430\n",
            "Epoch 252/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0225 - val_loss: 1.6214\n",
            "Epoch 253/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0156 - val_loss: 2.2500\n",
            "Epoch 254/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 1.9918\n",
            "Epoch 255/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0128 - val_loss: 2.0778\n",
            "Epoch 256/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0128 - val_loss: 2.2261\n",
            "Epoch 257/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0168 - val_loss: 1.8621\n",
            "Epoch 258/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 2.1701\n",
            "Epoch 259/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0049 - val_loss: 2.3248\n",
            "Epoch 260/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 2.4499\n",
            "Epoch 261/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0195 - val_loss: 2.7701\n",
            "Epoch 262/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 1.8624\n",
            "Epoch 263/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0083 - val_loss: 1.7333\n",
            "Epoch 264/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0115 - val_loss: 2.1269\n",
            "Epoch 265/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 2.1635\n",
            "Epoch 266/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 1.9007\n",
            "Epoch 267/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0080 - val_loss: 2.5033\n",
            "Epoch 268/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0218 - val_loss: 0.8652\n",
            "Epoch 269/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0230 - val_loss: 2.0580\n",
            "Epoch 270/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0698 - val_loss: 1.6444\n",
            "Epoch 271/1000\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0448 - val_loss: 1.5663\n",
            "Epoch 272/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0328 - val_loss: 2.9083\n",
            "Epoch 273/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0300 - val_loss: 1.4466\n",
            "Epoch 274/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0240 - val_loss: 2.2613\n",
            "Epoch 275/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0280 - val_loss: 2.3441\n",
            "Epoch 276/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0299 - val_loss: 1.1365\n",
            "Epoch 277/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0253 - val_loss: 2.9251\n",
            "Epoch 278/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0283 - val_loss: 1.1616\n",
            "Epoch 279/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0298 - val_loss: 2.1598\n",
            "Epoch 280/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0174 - val_loss: 1.8589\n",
            "Epoch 281/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0360 - val_loss: 1.2847\n",
            "Epoch 282/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.0395 - val_loss: 2.6335\n",
            "Epoch 283/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0339 - val_loss: 1.3980\n",
            "Epoch 284/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0368 - val_loss: 1.8206\n",
            "Epoch 285/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0254 - val_loss: 3.4124\n",
            "Epoch 286/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 1.6301\n",
            "Epoch 287/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0347 - val_loss: 2.0777\n",
            "Epoch 288/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0217 - val_loss: 2.0971\n",
            "Epoch 289/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0354 - val_loss: 2.9070\n",
            "Epoch 290/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0332 - val_loss: 1.8927\n",
            "Epoch 291/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0176 - val_loss: 2.1949\n",
            "Epoch 292/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0163 - val_loss: 2.6754\n",
            "Epoch 293/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 2.9174\n",
            "Epoch 294/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0497 - val_loss: 0.9816\n",
            "Epoch 295/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0326 - val_loss: 3.2295\n",
            "Epoch 296/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0324 - val_loss: 1.7932\n",
            "Epoch 297/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 3.0620\n",
            "Epoch 298/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 2.1874\n",
            "Epoch 299/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0110 - val_loss: 1.5312\n",
            "Epoch 300/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0095 - val_loss: 2.4254\n",
            "Epoch 301/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 2.3706\n",
            "Epoch 302/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 2.2218\n",
            "Epoch 303/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 2.6805\n",
            "Epoch 304/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 2.4735\n",
            "Epoch 305/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 1.8268\n",
            "Epoch 306/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0066 - val_loss: 1.7968\n",
            "Epoch 307/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 1.9374\n",
            "Epoch 308/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0077 - val_loss: 1.8961\n",
            "Epoch 309/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 1.8101\n",
            "Epoch 310/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 1.9387\n",
            "Epoch 311/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 1.6697\n",
            "Epoch 312/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 1.4108\n",
            "Epoch 313/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0075 - val_loss: 2.5348\n",
            "Epoch 314/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 2.4367\n",
            "Epoch 315/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0140 - val_loss: 2.7693\n",
            "Epoch 316/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0166 - val_loss: 1.2869\n",
            "Epoch 317/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0160 - val_loss: 2.0738\n",
            "Epoch 318/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0223 - val_loss: 1.7114\n",
            "Epoch 319/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 2.2169\n",
            "Epoch 320/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 1.7920\n",
            "Epoch 321/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0189 - val_loss: 1.1178\n",
            "Epoch 322/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0255 - val_loss: 1.4898\n",
            "Epoch 323/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 2.0336\n",
            "Epoch 324/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0123 - val_loss: 2.5153\n",
            "Epoch 325/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 1.8701\n",
            "Epoch 326/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0133 - val_loss: 1.5111\n",
            "Epoch 327/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 1.9684\n",
            "Epoch 328/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0271 - val_loss: 1.4002\n",
            "Epoch 329/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0521 - val_loss: 4.0498\n",
            "Epoch 330/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0597 - val_loss: 1.8899\n",
            "Epoch 331/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 3.0269\n",
            "Epoch 332/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0472 - val_loss: 1.5038\n",
            "Epoch 333/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0313 - val_loss: 2.1890\n",
            "Epoch 334/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0243 - val_loss: 2.4197\n",
            "Epoch 335/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0267 - val_loss: 3.2581\n",
            "Epoch 336/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0333 - val_loss: 1.5913\n",
            "Epoch 337/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 3.1359\n",
            "Epoch 338/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0109 - val_loss: 3.2146\n",
            "Epoch 339/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0195 - val_loss: 2.1606\n",
            "Epoch 340/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0218 - val_loss: 0.5200\n",
            "Epoch 341/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0681 - val_loss: 0.8235\n",
            "Epoch 342/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0400 - val_loss: 1.7617\n",
            "Epoch 343/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0571 - val_loss: 4.4675\n",
            "Epoch 344/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.1318 - val_loss: 1.1468\n",
            "Epoch 345/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0790 - val_loss: 3.3058\n",
            "Epoch 346/1000\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0321 - val_loss: 3.3775\n",
            "Epoch 347/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0489 - val_loss: 3.7971\n",
            "Epoch 348/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0830 - val_loss: 2.1316\n",
            "Epoch 349/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0696 - val_loss: 2.7085\n",
            "Epoch 350/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0343 - val_loss: 5.2109\n",
            "Epoch 351/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0307 - val_loss: 2.5674\n",
            "Epoch 352/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0181 - val_loss: 3.2353\n",
            "Epoch 353/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0114 - val_loss: 3.3964\n",
            "Epoch 354/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0142 - val_loss: 2.4544\n",
            "Epoch 355/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 2.8035\n",
            "Epoch 356/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0250 - val_loss: 2.4958\n",
            "Epoch 357/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0238 - val_loss: 2.2309\n",
            "Epoch 358/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0136 - val_loss: 2.7762\n",
            "Epoch 359/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 2.2689\n",
            "Epoch 360/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0117 - val_loss: 1.8146\n",
            "Epoch 361/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0217 - val_loss: 2.0027\n",
            "Epoch 362/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0214 - val_loss: 2.5002\n",
            "Epoch 363/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 3.0615\n",
            "Epoch 364/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0113 - val_loss: 2.6869\n",
            "Epoch 365/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 1.8864\n",
            "Epoch 366/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 3.0314\n",
            "Epoch 367/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 3.1195\n",
            "Epoch 368/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 3.5120\n",
            "Epoch 369/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 2.1861\n",
            "Epoch 370/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 1.7595\n",
            "Epoch 371/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0171 - val_loss: 1.8047\n",
            "Epoch 372/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0199 - val_loss: 2.9431\n",
            "Epoch 373/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0288 - val_loss: 2.8304\n",
            "Epoch 374/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0506 - val_loss: 1.6855\n",
            "Epoch 375/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0430 - val_loss: 1.8448\n",
            "Epoch 376/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0457 - val_loss: 3.0174\n",
            "Epoch 377/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 1.9455\n",
            "Epoch 378/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0202 - val_loss: 2.6941\n",
            "Epoch 379/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0225 - val_loss: 1.8415\n",
            "Epoch 380/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0171 - val_loss: 1.7509\n",
            "Epoch 381/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0294 - val_loss: 3.7024\n",
            "Epoch 382/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0253 - val_loss: 2.9129\n",
            "Epoch 383/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 3.1551\n",
            "Epoch 384/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0128 - val_loss: 1.8903\n",
            "Epoch 385/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 2.3356\n",
            "Epoch 386/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 2.9762\n",
            "Epoch 387/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 2.1858\n",
            "Epoch 388/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0129 - val_loss: 2.8577\n",
            "Epoch 389/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 2.6695\n",
            "Epoch 390/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 2.9998\n",
            "Epoch 391/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 1.8190\n",
            "Epoch 392/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 1.8278\n",
            "Epoch 393/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 1.9592\n",
            "Epoch 394/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 2.6353\n",
            "Epoch 395/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 1.8708\n",
            "Epoch 396/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 2.0580\n",
            "Epoch 397/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 1.7603\n",
            "Epoch 398/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 1.5609\n",
            "Epoch 399/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0205 - val_loss: 1.6151\n",
            "Epoch 400/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0370 - val_loss: 1.8680\n",
            "Epoch 401/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0183 - val_loss: 1.7003\n",
            "Epoch 402/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 2.1217\n",
            "Epoch 403/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0082 - val_loss: 2.2838\n",
            "Epoch 404/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 2.5313\n",
            "Epoch 405/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 1.9519\n",
            "Epoch 406/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0246 - val_loss: 2.3178\n",
            "Epoch 407/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0332 - val_loss: 2.3197\n",
            "Epoch 408/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0135 - val_loss: 1.3534\n",
            "Epoch 409/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0181 - val_loss: 2.5054\n",
            "Epoch 410/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 2.5661\n",
            "Epoch 411/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 1.3179\n",
            "Epoch 412/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0289 - val_loss: 1.0882\n",
            "Epoch 413/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0187 - val_loss: 2.5237\n",
            "Epoch 414/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0189 - val_loss: 1.9693\n",
            "Epoch 415/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0132 - val_loss: 1.6865\n",
            "Epoch 416/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0120 - val_loss: 1.8823\n",
            "Epoch 417/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0109 - val_loss: 2.1495\n",
            "Epoch 418/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 1.7087\n",
            "Epoch 419/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0159 - val_loss: 1.7848\n",
            "Epoch 420/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 2.9549\n",
            "Epoch 421/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0462 - val_loss: 1.7490\n",
            "Epoch 422/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0258 - val_loss: 3.2643\n",
            "Epoch 423/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0408 - val_loss: 2.5365\n",
            "Epoch 424/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0201 - val_loss: 2.1877\n",
            "Epoch 425/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 2.6779\n",
            "Epoch 426/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0161 - val_loss: 1.7184\n",
            "Epoch 427/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0218 - val_loss: 2.3166\n",
            "Epoch 428/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0185 - val_loss: 2.2150\n",
            "Epoch 429/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0134 - val_loss: 2.2266\n",
            "Epoch 430/1000\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0069 - val_loss: 1.9799\n",
            "Epoch 431/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 2.4090\n",
            "Epoch 432/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 1.5206\n",
            "Epoch 433/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0217 - val_loss: 2.2904\n",
            "Epoch 434/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 1.7541\n",
            "Epoch 435/1000\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0113 - val_loss: 1.8784\n",
            "Epoch 436/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 2.5887\n",
            "Epoch 437/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 1.6711\n",
            "Epoch 438/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 2.3236\n",
            "Epoch 439/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 1.7313\n",
            "Epoch 440/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0295 - val_loss: 4.3052\n",
            "Epoch 441/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.1082 - val_loss: 3.6356\n",
            "Epoch 442/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0474 - val_loss: 2.0050\n",
            "Epoch 443/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0342 - val_loss: 2.2853\n",
            "Epoch 444/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0479 - val_loss: 1.6563\n",
            "Epoch 445/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0411 - val_loss: 3.3109\n",
            "Epoch 446/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0504 - val_loss: 2.0521\n",
            "Epoch 447/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0308 - val_loss: 2.2190\n",
            "Epoch 448/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 5.1331\n",
            "Epoch 449/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1231 - val_loss: 1.3493\n",
            "Epoch 450/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0569 - val_loss: 2.1087\n",
            "Epoch 451/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0288 - val_loss: 1.5297\n",
            "Epoch 452/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0334 - val_loss: 2.7149\n",
            "Epoch 453/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0316 - val_loss: 2.7289\n",
            "Epoch 454/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0248 - val_loss: 2.7411\n",
            "Epoch 455/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0153 - val_loss: 2.2890\n",
            "Epoch 456/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0173 - val_loss: 3.1643\n",
            "Epoch 457/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0179 - val_loss: 3.9647\n",
            "Epoch 458/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0292 - val_loss: 3.2177\n",
            "Epoch 459/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0299 - val_loss: 2.4737\n",
            "Epoch 460/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0191 - val_loss: 2.3581\n",
            "Epoch 461/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 2.5836\n",
            "Epoch 462/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 2.8253\n",
            "Epoch 463/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0146 - val_loss: 2.3223\n",
            "Epoch 464/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0213 - val_loss: 2.0764\n",
            "Epoch 465/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0173 - val_loss: 2.3807\n",
            "Epoch 466/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0229 - val_loss: 2.3691\n",
            "Epoch 467/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0278 - val_loss: 2.1857\n",
            "Epoch 468/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 1.3077\n",
            "Epoch 469/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0377 - val_loss: 2.8124\n",
            "Epoch 470/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0431 - val_loss: 3.9700\n",
            "Epoch 471/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0409 - val_loss: 2.4721\n",
            "Epoch 472/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 2.1930\n",
            "Epoch 473/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0192 - val_loss: 2.2849\n",
            "Epoch 474/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0115 - val_loss: 1.8265\n",
            "Epoch 475/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 1.7371\n",
            "Epoch 476/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0301 - val_loss: 2.9291\n",
            "Epoch 477/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 2.2701\n",
            "Epoch 478/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0149 - val_loss: 1.8897\n",
            "Epoch 479/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0543 - val_loss: 4.1814\n",
            "Epoch 480/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.1223 - val_loss: 2.8330\n",
            "Epoch 481/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0780 - val_loss: 0.7928\n",
            "Epoch 482/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0613 - val_loss: 3.4696\n",
            "Epoch 483/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0677 - val_loss: 2.4413\n",
            "Epoch 484/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0503 - val_loss: 2.1154\n",
            "Epoch 485/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0303 - val_loss: 2.5895\n",
            "Epoch 486/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0343 - val_loss: 2.7994\n",
            "Epoch 487/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0224 - val_loss: 2.2926\n",
            "Epoch 488/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0167 - val_loss: 3.5442\n",
            "Epoch 489/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0136 - val_loss: 1.7483\n",
            "Epoch 490/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0281 - val_loss: 1.3655\n",
            "Epoch 491/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0274 - val_loss: 1.2351\n",
            "Epoch 492/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0288 - val_loss: 4.0174\n",
            "Epoch 493/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0304 - val_loss: 2.5330\n",
            "Epoch 494/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0145 - val_loss: 2.1587\n",
            "Epoch 495/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 2.4704\n",
            "Epoch 496/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0106 - val_loss: 2.1496\n",
            "Epoch 497/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0141 - val_loss: 2.4869\n",
            "Epoch 498/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 2.3490\n",
            "Epoch 499/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 1.6971\n",
            "Epoch 500/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0360 - val_loss: 2.2993\n",
            "Epoch 501/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0252 - val_loss: 3.8600\n",
            "Epoch 502/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 2.6454\n",
            "Epoch 503/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0164 - val_loss: 2.2175\n",
            "Epoch 504/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 2.5041\n",
            "Epoch 505/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 2.7652\n",
            "Epoch 506/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 1.9407\n",
            "Epoch 507/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0230 - val_loss: 2.3319\n",
            "Epoch 508/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0329 - val_loss: 1.4212\n",
            "Epoch 509/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0215 - val_loss: 3.0868\n",
            "Epoch 510/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0301 - val_loss: 3.4657\n",
            "Epoch 511/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0257 - val_loss: 2.4339\n",
            "Epoch 512/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0163 - val_loss: 2.1851\n",
            "Epoch 513/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 3.4489\n",
            "Epoch 514/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0242 - val_loss: 2.5073\n",
            "Epoch 515/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 1.6114\n",
            "Epoch 516/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0104 - val_loss: 2.6055\n",
            "Epoch 517/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0170 - val_loss: 3.1389\n",
            "Epoch 518/1000\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0155 - val_loss: 1.9424\n",
            "Epoch 519/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0051 - val_loss: 2.5534\n",
            "Epoch 520/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0066 - val_loss: 1.6134\n",
            "Epoch 521/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0638 - val_loss: 1.3015\n",
            "Epoch 522/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.1003 - val_loss: 4.2781\n",
            "Epoch 523/1000\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0317 - val_loss: 4.1483\n",
            "Epoch 524/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 4.0999\n",
            "Epoch 525/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0205 - val_loss: 2.4189\n",
            "Epoch 526/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 2.5058\n",
            "Epoch 527/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0085 - val_loss: 3.0005\n",
            "Epoch 528/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 2.4680\n",
            "Epoch 529/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0108 - val_loss: 2.1676\n",
            "Epoch 530/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 2.2503\n",
            "Epoch 531/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 1.7833\n",
            "Epoch 532/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0209 - val_loss: 2.4152\n",
            "Epoch 533/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0347 - val_loss: 1.4523\n",
            "Epoch 534/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0186 - val_loss: 0.9951\n",
            "Epoch 535/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0206 - val_loss: 0.8702\n",
            "Epoch 536/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0749 - val_loss: 0.2685\n",
            "Epoch 537/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1336 - val_loss: 0.8431\n",
            "Epoch 538/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0508 - val_loss: 5.7984\n",
            "Epoch 539/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0815 - val_loss: 5.2577\n",
            "Epoch 540/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0500 - val_loss: 2.0159\n",
            "Epoch 541/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1030 - val_loss: 5.3978\n",
            "Epoch 542/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0483 - val_loss: 7.4659\n",
            "Epoch 543/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0497 - val_loss: 2.4779\n",
            "Epoch 544/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1687 - val_loss: 5.2217\n",
            "Epoch 545/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3354 - val_loss: 3.6201\n",
            "Epoch 546/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1958 - val_loss: 0.2606\n",
            "Epoch 547/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2548 - val_loss: 0.6655\n",
            "Epoch 548/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1666 - val_loss: 3.0417\n",
            "Epoch 549/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0455 - val_loss: 3.4749\n",
            "Epoch 550/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0301 - val_loss: 2.6565\n",
            "Epoch 551/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0270 - val_loss: 2.5849\n",
            "Epoch 552/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0246 - val_loss: 2.1824\n",
            "Epoch 553/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0224 - val_loss: 1.8791\n",
            "Epoch 554/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0100 - val_loss: 1.6447\n",
            "Epoch 555/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 1.6481\n",
            "Epoch 556/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 1.9927\n",
            "Epoch 557/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0610 - val_loss: 2.7468\n",
            "Epoch 558/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0496 - val_loss: 1.2880\n",
            "Epoch 559/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0400 - val_loss: 1.8282\n",
            "Epoch 560/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0289 - val_loss: 4.3953\n",
            "Epoch 561/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0202 - val_loss: 2.4764\n",
            "Epoch 562/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 2.1478\n",
            "Epoch 563/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 2.2549\n",
            "Epoch 564/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 2.1113\n",
            "Epoch 565/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0229 - val_loss: 1.3900\n",
            "Epoch 566/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0246 - val_loss: 2.8410\n",
            "Epoch 567/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 1.6239\n",
            "Epoch 568/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.9165\n",
            "Epoch 569/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0312 - val_loss: 1.8025\n",
            "Epoch 570/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0403 - val_loss: 1.9726\n",
            "Epoch 571/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0355 - val_loss: 2.3965\n",
            "Epoch 572/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 2.9240\n",
            "Epoch 573/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 1.6658\n",
            "Epoch 574/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0124 - val_loss: 2.2634\n",
            "Epoch 575/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0137 - val_loss: 1.9039\n",
            "Epoch 576/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0205 - val_loss: 1.8734\n",
            "Epoch 577/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 2.0990\n",
            "Epoch 578/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 1.4280\n",
            "Epoch 579/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 1.4873\n",
            "Epoch 580/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0081 - val_loss: 1.3628\n",
            "Epoch 581/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.6957\n",
            "Epoch 582/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 1.3401\n",
            "Epoch 583/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0153 - val_loss: 0.8161\n",
            "Epoch 584/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 1.8471\n",
            "Epoch 585/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0112 - val_loss: 2.6909\n",
            "Epoch 586/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 1.4814\n",
            "Epoch 587/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.7855\n",
            "Epoch 588/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0438 - val_loss: 1.1891\n",
            "Epoch 589/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0422 - val_loss: 2.5644\n",
            "Epoch 590/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0231 - val_loss: 4.8346\n",
            "Epoch 591/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0204 - val_loss: 1.9153\n",
            "Epoch 592/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 3.6844\n",
            "Epoch 593/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0121 - val_loss: 1.0682\n",
            "Epoch 594/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0115 - val_loss: 1.8207\n",
            "Epoch 595/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0107 - val_loss: 2.1028\n",
            "Epoch 596/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0163 - val_loss: 1.4532\n",
            "Epoch 597/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0220 - val_loss: 2.1359\n",
            "Epoch 598/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 2.2919\n",
            "Epoch 599/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0068 - val_loss: 1.2712\n",
            "Epoch 600/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0070 - val_loss: 1.4432\n",
            "Epoch 601/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0061 - val_loss: 0.8752\n",
            "Epoch 602/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 1.1758\n",
            "Epoch 603/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 1.2637\n",
            "Epoch 604/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0130 - val_loss: 1.9746\n",
            "Epoch 605/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 1.7743\n",
            "Epoch 606/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0133 - val_loss: 1.8694\n",
            "Epoch 607/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0113 - val_loss: 2.1863\n",
            "Epoch 608/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 2.1758\n",
            "Epoch 609/1000\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.0051 - val_loss: 1.5707\n",
            "Epoch 610/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0045 - val_loss: 0.8650\n",
            "Epoch 611/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.4818\n",
            "Epoch 612/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0164 - val_loss: 1.5168\n",
            "Epoch 613/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0143 - val_loss: 1.1099\n",
            "Epoch 614/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0086 - val_loss: 2.5380\n",
            "Epoch 615/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 1.1972\n",
            "Epoch 616/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0080 - val_loss: 1.2761\n",
            "Epoch 617/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 1.5242\n",
            "Epoch 618/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 2.1068\n",
            "Epoch 619/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 2.0156\n",
            "Epoch 620/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 0.6429\n",
            "Epoch 621/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0264 - val_loss: 1.7218\n",
            "Epoch 622/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0148 - val_loss: 2.7825\n",
            "Epoch 623/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0126 - val_loss: 2.4480\n",
            "Epoch 624/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 1.1326\n",
            "Epoch 625/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 1.2722\n",
            "Epoch 626/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 1.1296\n",
            "Epoch 627/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0228 - val_loss: 0.5041\n",
            "Epoch 628/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0466 - val_loss: 4.4547\n",
            "Epoch 629/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0399 - val_loss: 1.2624\n",
            "Epoch 630/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0687 - val_loss: 1.4857\n",
            "Epoch 631/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0379 - val_loss: 2.8037\n",
            "Epoch 632/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0155 - val_loss: 2.0037\n",
            "Epoch 633/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 1.7108\n",
            "Epoch 634/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0117 - val_loss: 1.9298\n",
            "Epoch 635/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0112 - val_loss: 1.8420\n",
            "Epoch 636/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 1.4626\n",
            "Epoch 637/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0298 - val_loss: 1.3233\n",
            "Epoch 638/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0329 - val_loss: 2.4300\n",
            "Epoch 639/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0349 - val_loss: 1.4599\n",
            "Epoch 640/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0342 - val_loss: 3.1606\n",
            "Epoch 641/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 1.5675\n",
            "Epoch 642/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 2.4250\n",
            "Epoch 643/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 1.8983\n",
            "Epoch 644/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0355 - val_loss: 4.1579\n",
            "Epoch 645/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0450 - val_loss: 1.5523\n",
            "Epoch 646/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0133 - val_loss: 2.3982\n",
            "Epoch 647/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0189 - val_loss: 2.0662\n",
            "Epoch 648/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0314 - val_loss: 1.2222\n",
            "Epoch 649/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0478 - val_loss: 3.4427\n",
            "Epoch 650/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0424 - val_loss: 2.4222\n",
            "Epoch 651/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0254 - val_loss: 2.3106\n",
            "Epoch 652/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0233 - val_loss: 2.2773\n",
            "Epoch 653/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0257 - val_loss: 2.0214\n",
            "Epoch 654/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0094 - val_loss: 2.2979\n",
            "Epoch 655/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 1.5946\n",
            "Epoch 656/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 1.7020\n",
            "Epoch 657/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0165 - val_loss: 2.2757\n",
            "Epoch 658/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0258 - val_loss: 1.7327\n",
            "Epoch 659/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0369 - val_loss: 2.9084\n",
            "Epoch 660/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0161 - val_loss: 2.3743\n",
            "Epoch 661/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 1.3091\n",
            "Epoch 662/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 2.2772\n",
            "Epoch 663/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0221 - val_loss: 2.0159\n",
            "Epoch 664/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 1.4464\n",
            "Epoch 665/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 1.2066\n",
            "Epoch 666/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.7770\n",
            "Epoch 667/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 1.8461\n",
            "Epoch 668/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 1.9032\n",
            "Epoch 669/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 1.2451\n",
            "Epoch 670/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0065 - val_loss: 1.0041\n",
            "Epoch 671/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0150 - val_loss: 0.5541\n",
            "Epoch 672/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0296 - val_loss: 2.6582\n",
            "Epoch 673/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0151 - val_loss: 1.1648\n",
            "Epoch 674/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 1.8171\n",
            "Epoch 675/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0227 - val_loss: 2.1375\n",
            "Epoch 676/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0215 - val_loss: 2.0473\n",
            "Epoch 677/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 1.3538\n",
            "Epoch 678/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0101 - val_loss: 1.8769\n",
            "Epoch 679/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0125 - val_loss: 1.4717\n",
            "Epoch 680/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0140 - val_loss: 1.0332\n",
            "Epoch 681/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0140 - val_loss: 2.4814\n",
            "Epoch 682/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0060 - val_loss: 1.8598\n",
            "Epoch 683/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 1.1404\n",
            "Epoch 684/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 1.2417\n",
            "Epoch 685/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0034 - val_loss: 1.3341\n",
            "Epoch 686/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0128 - val_loss: 0.8422\n",
            "Epoch 687/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.8492\n",
            "Epoch 688/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 2.4054\n",
            "Epoch 689/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0171 - val_loss: 0.7749\n",
            "Epoch 690/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0354 - val_loss: 1.7051\n",
            "Epoch 691/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0243 - val_loss: 2.6006\n",
            "Epoch 692/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0183 - val_loss: 2.4682\n",
            "Epoch 693/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 1.1831\n",
            "Epoch 694/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.9616\n",
            "Epoch 695/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.8975\n",
            "Epoch 696/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.2910\n",
            "Epoch 697/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 1.3598\n",
            "Epoch 698/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0124 - val_loss: 1.6809\n",
            "Epoch 699/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 1.9819\n",
            "Epoch 700/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0146 - val_loss: 2.0566\n",
            "Epoch 701/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0207 - val_loss: 2.4412\n",
            "Epoch 702/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 2.6533\n",
            "Epoch 703/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 1.1132\n",
            "Epoch 704/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0112 - val_loss: 0.3728\n",
            "Epoch 705/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0116 - val_loss: 1.1590\n",
            "Epoch 706/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0255 - val_loss: 2.4305\n",
            "Epoch 707/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0380 - val_loss: 1.1688\n",
            "Epoch 708/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0402 - val_loss: 1.1083\n",
            "Epoch 709/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0302 - val_loss: 2.3282\n",
            "Epoch 710/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0328 - val_loss: 2.0723\n",
            "Epoch 711/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0496 - val_loss: 2.8192\n",
            "Epoch 712/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0405 - val_loss: 2.3419\n",
            "Epoch 713/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0201 - val_loss: 1.8482\n",
            "Epoch 714/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0135 - val_loss: 1.2419\n",
            "Epoch 715/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 1.0579\n",
            "Epoch 716/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.9191\n",
            "Epoch 717/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0124 - val_loss: 0.1224\n",
            "Epoch 718/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0196 - val_loss: 1.5159\n",
            "Epoch 719/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0060 - val_loss: 1.0825\n",
            "Epoch 720/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 1.5425\n",
            "Epoch 721/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0287 - val_loss: 2.5392\n",
            "Epoch 722/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0568 - val_loss: 2.2480\n",
            "Epoch 723/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0247 - val_loss: 3.0617\n",
            "Epoch 724/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0141 - val_loss: 3.4570\n",
            "Epoch 725/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0307 - val_loss: 0.7621\n",
            "Epoch 726/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0806 - val_loss: 0.9514\n",
            "Epoch 727/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0412 - val_loss: 2.2196\n",
            "Epoch 728/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0385 - val_loss: 3.0136\n",
            "Epoch 729/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0442 - val_loss: 1.3758\n",
            "Epoch 730/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0250 - val_loss: 2.9563\n",
            "Epoch 731/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0157 - val_loss: 1.9365\n",
            "Epoch 732/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 2.6405\n",
            "Epoch 733/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0178 - val_loss: 1.1941\n",
            "Epoch 734/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 1.3154\n",
            "Epoch 735/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.6854\n",
            "Epoch 736/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0266 - val_loss: 2.3097\n",
            "Epoch 737/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0238 - val_loss: 0.9814\n",
            "Epoch 738/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0295 - val_loss: 2.1330\n",
            "Epoch 739/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 1.3540\n",
            "Epoch 740/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 1.2674\n",
            "Epoch 741/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0060 - val_loss: 0.9555\n",
            "Epoch 742/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 1.1489\n",
            "Epoch 743/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0178 - val_loss: 1.0342\n",
            "Epoch 744/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 1.4879\n",
            "Epoch 745/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.5940\n",
            "Epoch 746/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.6388\n",
            "Epoch 747/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.6370\n",
            "Epoch 748/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.6012\n",
            "Epoch 749/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 1.1195\n",
            "Epoch 750/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.8341\n",
            "Epoch 751/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 1.0089\n",
            "Epoch 752/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.4048\n",
            "Epoch 753/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.8701\n",
            "Epoch 754/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0073 - val_loss: 1.6867\n",
            "Epoch 755/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 2.1720\n",
            "Epoch 756/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0111 - val_loss: 0.2528\n",
            "Epoch 757/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2038 - val_loss: 5.5561\n",
            "Epoch 758/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2686 - val_loss: 2.0759\n",
            "Epoch 759/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.2122 - val_loss: 0.8615\n",
            "Epoch 760/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.1707 - val_loss: 2.5577\n",
            "Epoch 761/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0926 - val_loss: 1.4086\n",
            "Epoch 762/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0604 - val_loss: 4.8172\n",
            "Epoch 763/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0378 - val_loss: 2.3555\n",
            "Epoch 764/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0290 - val_loss: 2.4289\n",
            "Epoch 765/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0163 - val_loss: 2.3296\n",
            "Epoch 766/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 1.8571\n",
            "Epoch 767/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0522 - val_loss: 3.3059\n",
            "Epoch 768/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0880 - val_loss: 1.1657\n",
            "Epoch 769/1000\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 0.0587 - val_loss: 3.3597\n",
            "Epoch 770/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0394 - val_loss: 0.7676\n",
            "Epoch 771/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0361 - val_loss: 0.5890\n",
            "Epoch 772/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0515 - val_loss: 1.6087\n",
            "Epoch 773/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0175 - val_loss: 2.6300\n",
            "Epoch 774/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0266 - val_loss: 0.9301\n",
            "Epoch 775/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0223 - val_loss: 1.3453\n",
            "Epoch 776/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 1.3277\n",
            "Epoch 777/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 1.8529\n",
            "Epoch 778/1000\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0082 - val_loss: 1.1575\n",
            "Epoch 779/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0054 - val_loss: 1.3618\n",
            "Epoch 780/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0162 - val_loss: 0.8651\n",
            "Epoch 781/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 1.6714\n",
            "Epoch 782/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.5792\n",
            "Epoch 783/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.4490\n",
            "Epoch 784/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0082 - val_loss: 1.2085\n",
            "Epoch 785/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 1.3392\n",
            "Epoch 786/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0156 - val_loss: 1.9661\n",
            "Epoch 787/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 1.4871\n",
            "Epoch 788/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0086 - val_loss: 1.2571\n",
            "Epoch 789/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0078 - val_loss: 0.9364\n",
            "Epoch 790/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.4748\n",
            "Epoch 791/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 2.0474\n",
            "Epoch 792/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 0.4085\n",
            "Epoch 793/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0263 - val_loss: 0.3736\n",
            "Epoch 794/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0290 - val_loss: 2.9515\n",
            "Epoch 795/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0153 - val_loss: 2.8750\n",
            "Epoch 796/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0139 - val_loss: 1.5810\n",
            "Epoch 797/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0109 - val_loss: 2.0657\n",
            "Epoch 798/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 1.1990\n",
            "Epoch 799/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.9316\n",
            "Epoch 800/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0179 - val_loss: 2.2892\n",
            "Epoch 801/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0202 - val_loss: 1.7402\n",
            "Epoch 802/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 1.7326\n",
            "Epoch 803/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 2.0689\n",
            "Epoch 804/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0179 - val_loss: 1.1039\n",
            "Epoch 805/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 1.7985\n",
            "Epoch 806/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.7346\n",
            "Epoch 807/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0071 - val_loss: 1.9153\n",
            "Epoch 808/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0477 - val_loss: 1.5376\n",
            "Epoch 809/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0546 - val_loss: 2.2902\n",
            "Epoch 810/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0657 - val_loss: 2.8759\n",
            "Epoch 811/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0338 - val_loss: 3.0129\n",
            "Epoch 812/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.5748\n",
            "Epoch 813/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0127 - val_loss: 0.7056\n",
            "Epoch 814/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0212 - val_loss: 1.5329\n",
            "Epoch 815/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0266 - val_loss: 2.1230\n",
            "Epoch 816/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0323 - val_loss: 2.5305\n",
            "Epoch 817/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 0.9625\n",
            "Epoch 818/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0213 - val_loss: 2.4586\n",
            "Epoch 819/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0116 - val_loss: 1.9378\n",
            "Epoch 820/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 1.1999\n",
            "Epoch 821/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.6245\n",
            "Epoch 822/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0070 - val_loss: 1.0863\n",
            "Epoch 823/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 1.6346\n",
            "Epoch 824/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.6032\n",
            "Epoch 825/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.8118\n",
            "Epoch 826/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0124 - val_loss: 1.2772\n",
            "Epoch 827/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0087 - val_loss: 0.5200\n",
            "Epoch 828/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 1.1385\n",
            "Epoch 829/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0086 - val_loss: 0.4143\n",
            "Epoch 830/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0321 - val_loss: 1.9248\n",
            "Epoch 831/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0320 - val_loss: 2.2265\n",
            "Epoch 832/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0152 - val_loss: 0.9441\n",
            "Epoch 833/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.8729\n",
            "Epoch 834/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0116 - val_loss: 1.5149\n",
            "Epoch 835/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0149 - val_loss: 1.6808\n",
            "Epoch 836/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0266 - val_loss: 1.7045\n",
            "Epoch 837/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0494 - val_loss: 0.6891\n",
            "Epoch 838/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0316 - val_loss: 1.4184\n",
            "Epoch 839/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.7079\n",
            "Epoch 840/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0223 - val_loss: 1.6566\n",
            "Epoch 841/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0209 - val_loss: 1.5046\n",
            "Epoch 842/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0143 - val_loss: 1.0022\n",
            "Epoch 843/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0125 - val_loss: 0.9324\n",
            "Epoch 844/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0236 - val_loss: 0.9811\n",
            "Epoch 845/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0582 - val_loss: 2.0457\n",
            "Epoch 846/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0285 - val_loss: 2.4903\n",
            "Epoch 847/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0258 - val_loss: 1.9786\n",
            "Epoch 848/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 1.4769\n",
            "Epoch 849/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0111 - val_loss: 1.4479\n",
            "Epoch 850/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0249 - val_loss: 1.3657\n",
            "Epoch 851/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0144 - val_loss: 1.5563\n",
            "Epoch 852/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0066 - val_loss: 1.2312\n",
            "Epoch 853/1000\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.9102\n",
            "Epoch 854/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0064 - val_loss: 0.6115\n",
            "Epoch 855/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0144 - val_loss: 1.0794\n",
            "Epoch 856/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0123 - val_loss: 1.3954\n",
            "Epoch 857/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 0.9605\n",
            "Epoch 858/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.3973\n",
            "Epoch 859/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0108 - val_loss: 0.7485\n",
            "Epoch 860/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 1.1174\n",
            "Epoch 861/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 1.6877\n",
            "Epoch 862/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0129 - val_loss: 0.8896\n",
            "Epoch 863/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0117 - val_loss: 1.4024\n",
            "Epoch 864/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 1.4773\n",
            "Epoch 865/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0057 - val_loss: 0.9370\n",
            "Epoch 866/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.6170\n",
            "Epoch 867/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.7316\n",
            "Epoch 868/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0063 - val_loss: 0.3263\n",
            "Epoch 869/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 1.5524\n",
            "Epoch 870/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.8981\n",
            "Epoch 871/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.7872\n",
            "Epoch 872/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.8746\n",
            "Epoch 873/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 1.0545\n",
            "Epoch 874/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.6987\n",
            "Epoch 875/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0159 - val_loss: 0.8124\n",
            "Epoch 876/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 1.2682\n",
            "Epoch 877/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0127 - val_loss: 0.6188\n",
            "Epoch 878/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.7370\n",
            "Epoch 879/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0236 - val_loss: 2.2623\n",
            "Epoch 880/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 1.2147\n",
            "Epoch 881/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.7219\n",
            "Epoch 882/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 1.5799\n",
            "Epoch 883/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 1.3453\n",
            "Epoch 884/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0044 - val_loss: 1.2865\n",
            "Epoch 885/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.6670\n",
            "Epoch 886/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.5385\n",
            "Epoch 887/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.6987\n",
            "Epoch 888/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.6549\n",
            "Epoch 889/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 1.1521\n",
            "Epoch 890/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.8738\n",
            "Epoch 891/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.4857\n",
            "Epoch 892/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0082 - val_loss: 0.7061\n",
            "Epoch 893/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.4681\n",
            "Epoch 894/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0086 - val_loss: 0.1193\n",
            "Epoch 895/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0110 - val_loss: 0.3318\n",
            "Epoch 896/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0111 - val_loss: 0.6864\n",
            "Epoch 897/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.9682\n",
            "Epoch 898/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.9416\n",
            "Epoch 899/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0079 - val_loss: 1.7184\n",
            "Epoch 900/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0104 - val_loss: 0.6629\n",
            "Epoch 901/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0065 - val_loss: 0.2538\n",
            "Epoch 902/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0101 - val_loss: 0.8561\n",
            "Epoch 903/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.7193\n",
            "Epoch 904/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.3614\n",
            "Epoch 905/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.3304\n",
            "Epoch 906/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0143 - val_loss: 0.9272\n",
            "Epoch 907/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 3.0162\n",
            "Epoch 908/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.7902\n",
            "Epoch 909/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0150 - val_loss: 0.7198\n",
            "Epoch 910/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0284 - val_loss: 1.0733\n",
            "Epoch 911/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0564 - val_loss: 2.2314\n",
            "Epoch 912/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0528 - val_loss: 0.8291\n",
            "Epoch 913/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0305 - val_loss: 0.9907\n",
            "Epoch 914/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0955 - val_loss: 4.2225\n",
            "Epoch 915/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1376 - val_loss: 1.5994\n",
            "Epoch 916/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0794 - val_loss: 2.5890\n",
            "Epoch 917/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0282 - val_loss: 0.4487\n",
            "Epoch 918/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0780 - val_loss: 5.0378\n",
            "Epoch 919/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.1946 - val_loss: 0.3809\n",
            "Epoch 920/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1554 - val_loss: 0.3426\n",
            "Epoch 921/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1226 - val_loss: 2.9319\n",
            "Epoch 922/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2032 - val_loss: 0.4608\n",
            "Epoch 923/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.1288 - val_loss: 0.5276\n",
            "Epoch 924/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0804 - val_loss: 0.4876\n",
            "Epoch 925/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0767 - val_loss: 0.4526\n",
            "Epoch 926/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0783 - val_loss: 1.0767\n",
            "Epoch 927/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0453 - val_loss: 2.3188\n",
            "Epoch 928/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0208 - val_loss: 1.9322\n",
            "Epoch 929/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 2.2923\n",
            "Epoch 930/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0202 - val_loss: 1.3253\n",
            "Epoch 931/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0162 - val_loss: 1.3152\n",
            "Epoch 932/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 1.0755\n",
            "Epoch 933/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0056 - val_loss: 1.4660\n",
            "Epoch 934/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.9163\n",
            "Epoch 935/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.9807\n",
            "Epoch 936/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0060 - val_loss: 0.7435\n",
            "Epoch 937/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.7596\n",
            "Epoch 938/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0058 - val_loss: 0.6658\n",
            "Epoch 939/1000\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.7533\n",
            "Epoch 940/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0040 - val_loss: 0.6346\n",
            "Epoch 941/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0037 - val_loss: 0.6471\n",
            "Epoch 942/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0059 - val_loss: 0.7338\n",
            "Epoch 943/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0043 - val_loss: 0.6261\n",
            "Epoch 944/1000\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.6846\n",
            "Epoch 945/1000\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.0036 - val_loss: 0.5693\n",
            "Epoch 946/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0068 - val_loss: 0.6369\n",
            "Epoch 947/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0041 - val_loss: 0.7234\n",
            "Epoch 948/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0056 - val_loss: 0.8833\n",
            "Epoch 949/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.7178\n",
            "Epoch 950/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.7262\n",
            "Epoch 951/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0044 - val_loss: 0.7144\n",
            "Epoch 952/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0037 - val_loss: 0.6078\n",
            "Epoch 953/1000\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 1.1194\n",
            "Epoch 954/1000\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0064 - val_loss: 0.5015\n",
            "Epoch 955/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.7111\n",
            "Epoch 956/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 1.0369\n",
            "Epoch 957/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.4876\n",
            "Epoch 958/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0174 - val_loss: 1.6521\n",
            "Epoch 959/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0257 - val_loss: 0.8921\n",
            "Epoch 960/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0256 - val_loss: 0.9916\n",
            "Epoch 961/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 1.7082\n",
            "Epoch 962/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0069 - val_loss: 1.3087\n",
            "Epoch 963/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 1.4457\n",
            "Epoch 964/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.8966\n",
            "Epoch 965/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 0.6358\n",
            "Epoch 966/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.8557\n",
            "Epoch 967/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.8762\n",
            "Epoch 968/1000\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.0049 - val_loss: 0.9186\n",
            "Epoch 969/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.8148\n",
            "Epoch 970/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.8422\n",
            "Epoch 971/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 1.0335\n",
            "Epoch 972/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 0.7687\n",
            "Epoch 973/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.9881\n",
            "Epoch 974/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0168 - val_loss: 0.7609\n",
            "Epoch 975/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0127 - val_loss: 1.0762\n",
            "Epoch 976/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.9974\n",
            "Epoch 977/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 1.2603\n",
            "Epoch 978/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.9806\n",
            "Epoch 979/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0039 - val_loss: 0.7019\n",
            "Epoch 980/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.7307\n",
            "Epoch 981/1000\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.8964\n",
            "Epoch 982/1000\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.4563\n",
            "Epoch 983/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0113 - val_loss: 1.0807\n",
            "Epoch 984/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.9189\n",
            "Epoch 985/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 1.1787\n",
            "Epoch 986/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.6507\n",
            "Epoch 987/1000\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0056 - val_loss: 0.8847\n",
            "Epoch 988/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.6104\n",
            "Epoch 989/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.5253\n",
            "Epoch 990/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 1.1290\n",
            "Epoch 991/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0151 - val_loss: 1.1007\n",
            "Epoch 992/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.9980\n",
            "Epoch 993/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 1.3152\n",
            "Epoch 994/1000\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.8954\n",
            "Epoch 995/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.9753\n",
            "Epoch 996/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0044 - val_loss: 0.9336\n",
            "Epoch 997/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.8488\n",
            "Epoch 998/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.6936\n",
            "Epoch 999/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0044 - val_loss: 1.0988\n",
            "Epoch 1000/1000\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.5558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions2 = model2.predict(X_test).flatten()\n",
        "print(X_test)\n",
        "print(test_predictions2)\n",
        "test_results2 = pd.DataFrame(data={'Test Predictions':test_predictions2, 'Actuals':y_test})\n",
        "test_results2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17359
        },
        "outputId": "cfda7bc9-a00f-440c-c87e-0107bec57f37",
        "id": "kbG-YXJTV59I"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step\n",
            "[[[-52.94254394]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.95279873]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.93366321]\n",
            "  [-52.88708726]\n",
            "  [-52.81489992]]\n",
            "\n",
            " [[-52.88708726]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.81489992]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.71881691]\n",
            "  [-52.60044764]\n",
            "  [-52.51608985]]\n",
            "\n",
            " [[-52.60044764]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.51608985]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.40880473]\n",
            "  [-52.33492506]\n",
            "  [-52.29292731]]\n",
            "\n",
            " [[-52.33492506]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.29292731]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.28138373]\n",
            "  [-52.24231336]\n",
            "  [-52.23353711]]\n",
            "\n",
            " [[-52.24231336]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.23353711]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.19708277]\n",
            "  [-52.13477904]\n",
            "  [-52.04834217]]\n",
            "\n",
            " [[-52.13477904]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-52.04834217]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.93938281]\n",
            "  [-51.86362927]\n",
            "  [-51.76476912]]\n",
            "\n",
            " [[-51.86362927]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.76476912]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.64434586]\n",
            "  [-51.50380818]\n",
            "  [-51.39765302]]\n",
            "\n",
            " [[-51.50380818]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.39765302]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-51.27060332]\n",
            "  [-51.12406141]\n",
            "  [-50.95934366]]\n",
            "\n",
            " [[-51.12406141]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.95934366]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.77768569]\n",
            "  [-50.63190611]\n",
            "  [-50.52028511]]\n",
            "\n",
            " [[-50.63190611]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.52028511]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.4412057 ]\n",
            "  [-50.39314855]\n",
            "  [-50.32102036]]\n",
            "\n",
            " [[-50.39314855]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.32102036]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.27953438]\n",
            "  [-50.21361806]\n",
            "  [-50.17800432]]\n",
            "\n",
            " [[-50.21361806]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.17800432]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.17130609]\n",
            "  [-50.19222253]\n",
            "  [-50.23953497]]\n",
            "\n",
            " [[-50.19222253]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.23953497]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.25672098]\n",
            "  [-50.30050696]\n",
            "  [-50.31435931]]\n",
            "\n",
            " [[-50.30050696]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31435931]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.30020584]\n",
            "  [-50.31407465]\n",
            "  [-50.35472481]]\n",
            "\n",
            " [[-50.31407465]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.35472481]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.42099494]\n",
            "  [-50.4557992 ]\n",
            "  [-50.46116092]]\n",
            "\n",
            " [[-50.4557992 ]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.46116092]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.43898103]\n",
            "  [-50.44526228]\n",
            "  [-50.47873973]]\n",
            "\n",
            " [[-50.44526228]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.47873973]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.48284716]\n",
            "  [-50.51426964]\n",
            "  [-50.57181662]]\n",
            "\n",
            " [[-50.51426964]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.57181662]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.59837468]\n",
            "  [-50.59594105]\n",
            "  [-50.56639203]]\n",
            "\n",
            " [[-50.59594105]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.56639203]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.56570706]\n",
            "  [-50.59259916]\n",
            "  [-50.5904813 ]]\n",
            "\n",
            " [[-50.59259916]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.5904813 ]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.61601886]\n",
            "  [-50.61262053]\n",
            "  [-50.58215956]]\n",
            "\n",
            " [[-50.61262053]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.58215956]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.5806125 ]\n",
            "  [-50.55190157]\n",
            "  [-50.49779211]]\n",
            "\n",
            " [[-50.55190157]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.49779211]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.47360941]\n",
            "  [-50.47799735]\n",
            "  [-50.45489693]]\n",
            "\n",
            " [[-50.47799735]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.45489693]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.40609122]\n",
            "  [-50.38692228]\n",
            "  [-50.3418331 ]]\n",
            "\n",
            " [[-50.38692228]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3418331 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32617749]\n",
            "  [-50.3386263 ]\n",
            "  [-50.32314603]]\n",
            "\n",
            " [[-50.3386263 ]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.32314603]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.28154382]\n",
            "  [-50.21551764]\n",
            "  [-50.12666277]]\n",
            "\n",
            " [[-50.21551764]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-50.12666277]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-50.06910474]\n",
            "  [-49.98825503]\n",
            "  [-49.88563774]]\n",
            "\n",
            " [[-49.98825503]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.88563774]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.81481913]\n",
            "  [-49.72168448]\n",
            "  [-49.65983005]]\n",
            "\n",
            " [[-49.72168448]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.65983005]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.6277962 ]\n",
            "  [-49.57107513]\n",
            "  [-49.49126724]]\n",
            "\n",
            " [[-49.57107513]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.49126724]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.38987667]\n",
            "  [-49.268317  ]\n",
            "  [-49.12791664]]\n",
            "\n",
            " [[-49.268317  ]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-49.12791664]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-49.02067969]\n",
            "  [-48.9450186 ]\n",
            "  [-48.84778164]]\n",
            "\n",
            " [[-48.9450186 ]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.84778164]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.73037414]\n",
            "  [-48.59411711]\n",
            "  [-48.49057878]]\n",
            "\n",
            " [[-48.59411711]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.49057878]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.36743261]\n",
            "  [-48.2762883 ]\n",
            "  [-48.16485851]]\n",
            "\n",
            " [[-48.2762883 ]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-48.16485851]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-48.03446342]\n",
            "  [-47.88634427]\n",
            "  [-47.72166797]]\n",
            "\n",
            " [[-47.88634427]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.72166797]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.5415315 ]\n",
            "  [-47.39570791]\n",
            "  [-47.23339338]]\n",
            "\n",
            " [[-47.39570791]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-47.23339338]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-47.05567539]\n",
            "  [-46.8635764 ]\n",
            "  [-46.70607824]]\n",
            "\n",
            " [[-46.8635764 ]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.70607824]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.58146936]\n",
            "  [-46.48813738]\n",
            "  [-46.42456394]]\n",
            "\n",
            " [[-46.48813738]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.42456394]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.3398108 ]\n",
            "  [-46.23522767]\n",
            "  [-46.11208461]]\n",
            "\n",
            " [[-46.23522767]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-46.11208461]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.97157665]\n",
            "  [-45.81482812]\n",
            "  [-45.64289674]]\n",
            "\n",
            " [[-45.81482812]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.64289674]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.45677753]\n",
            "  [-45.30442265]\n",
            "  [-45.13680959]]\n",
            "\n",
            " [[-45.30442265]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-45.13680959]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.95493276]\n",
            "  [-44.75972774]\n",
            "  [-44.55207459]]\n",
            "\n",
            " [[-44.75972774]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.55207459]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-44.33280112]\n",
            "  [-44.14849027]\n",
            "  [-43.99737766]]\n",
            "\n",
            " [[-44.14849027]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.99737766]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.83140617]\n",
            "  [-43.6515354 ]\n",
            "  [-43.45866853]]\n",
            "\n",
            " [[-43.6515354 ]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.45866853]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.29917727]\n",
            "  [-43.17138003]\n",
            "  [-43.07369114]]\n",
            "\n",
            " [[-43.17138003]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-43.07369114]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-43.00461577]\n",
            "  [-42.91604475]\n",
            "  [-42.85558873]]\n",
            "\n",
            " [[-42.91604475]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.85558873]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82186619]\n",
            "  [-42.81357566]\n",
            "  [-42.82949152]]\n",
            "\n",
            " [[-42.81357566]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.82949152]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.86846005]\n",
            "  [-42.88137509]\n",
            "  [-42.8698309 ]]\n",
            "\n",
            " [[-42.88137509]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.8698309 ]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.83532967]\n",
            "  [-42.77928676]\n",
            "  [-42.74973605]]\n",
            "\n",
            " [[-42.77928676]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.74973605]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.69837299]\n",
            "  [-42.67324626]\n",
            "  [-42.67308156]]\n",
            "\n",
            " [[-42.67324626]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.67308156]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.64933764]\n",
            "  [-42.60346389]\n",
            "  [-42.53682594]]\n",
            "\n",
            " [[-42.60346389]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.53682594]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.45071042]\n",
            "  [-42.3924243 ]\n",
            "  [-42.36059734]]\n",
            "\n",
            " [[-42.3924243 ]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.36059734]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.35393857]\n",
            "  [-42.32421582]\n",
            "  [-42.27284582]]\n",
            "\n",
            " [[-42.32421582]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.27284582]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.20116348]\n",
            "  [-42.11042659]\n",
            "  [-42.00182017]]\n",
            "\n",
            " [[-42.11042659]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-42.00182017]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.87646063]\n",
            "  [-41.78064636]\n",
            "  [-41.66737955]]\n",
            "\n",
            " [[-41.78064636]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.66737955]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.53775011]\n",
            "  [-41.39278482]\n",
            "  [-41.23345086]]\n",
            "\n",
            " [[-41.39278482]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.23345086]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-41.10512319]\n",
            "  [-41.00623524]\n",
            "  [-40.93530953]]\n",
            "\n",
            " [[-41.00623524]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.93530953]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.8909529 ]\n",
            "  [-40.82633027]\n",
            "  [-40.74268538]]\n",
            "\n",
            " [[-40.82633027]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.74268538]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.68616932]\n",
            "  [-40.65543448]\n",
            "  [-40.64921066]]\n",
            "\n",
            " [[-40.65543448]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.64921066]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.62049654]\n",
            "  [-40.57066117]\n",
            "  [-40.50099505]]\n",
            "\n",
            " [[-40.57066117]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.50099505]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.41271457]\n",
            "  [-40.35168421]\n",
            "  [-40.31654622]]\n",
            "\n",
            " [[-40.35168421]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.31654622]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.26077389]\n",
            "  [-40.18562754]\n",
            "  [-40.09229517]]\n",
            "\n",
            " [[-40.18562754]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-40.09229517]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.98189651]\n",
            "  [-39.85548689]\n",
            "  [-39.75803577]]\n",
            "\n",
            " [[-39.85548689]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.75803577]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.68808208]\n",
            "  [-39.59978385]\n",
            "  [-39.49426632]]\n",
            "\n",
            " [[-39.59978385]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.49426632]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.3725901 ]\n",
            "  [-39.27949443]\n",
            "  [-39.16956091]]\n",
            "\n",
            " [[-39.27949443]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.16956091]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.08756591]\n",
            "  [-39.03210104]\n",
            "  [-39.00183798]]\n",
            "\n",
            " [[-39.03210104]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-39.00183798]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.95106031]\n",
            "  [-38.88101188]\n",
            "  [-38.79286547]]\n",
            "\n",
            " [[-38.88101188]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.79286547]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.73146638]\n",
            "  [-38.65149641]\n",
            "  [-38.55408711]]\n",
            "\n",
            " [[-38.65149641]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.55408711]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.44030529]\n",
            "  [-38.31115667]\n",
            "  [-38.16758928]]\n",
            "\n",
            " [[-38.31115667]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-38.16758928]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-38.01049674]\n",
            "  [-37.84072128]\n",
            "  [-37.70150032]]\n",
            "\n",
            " [[-37.84072128]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.70150032]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.54861931]\n",
            "  [-37.38292544]\n",
            "  [-37.2052172 ]]\n",
            "\n",
            " [[-37.38292544]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-37.2052172 ]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-37.01624715]\n",
            "  [-36.81672447]\n",
            "  [-36.64899535]]\n",
            "\n",
            " [[-36.81672447]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.64899535]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.51141489]\n",
            "  [-36.36037863]\n",
            "  [-36.19671571]]\n",
            "\n",
            " [[-36.36037863]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-36.19671571]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-36.02120779]\n",
            "  [-35.8345917 ]\n",
            "  [-35.67888299]]\n",
            "\n",
            " [[-35.8345917 ]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.67888299]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.55248099]\n",
            "  [-35.41219674]\n",
            "  [-35.25887846]]\n",
            "\n",
            " [[-35.41219674]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.25887846]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-35.134647  ]\n",
            "  [-35.03800122]\n",
            "  [-34.92584627]]\n",
            "\n",
            " [[-35.03800122]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.92584627]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.79911931]\n",
            "  [-34.65870424]\n",
            "  [-34.50543465]]\n",
            "\n",
            " [[-34.65870424]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.50543465]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.38107685]\n",
            "  [-34.2429866 ]\n",
            "  [-34.09199801]]\n",
            "\n",
            " [[-34.2429866 ]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-34.09199801]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.92889771]\n",
            "  [-33.7544275 ]\n",
            "  [-33.56928687]]\n",
            "\n",
            " [[-33.7544275 ]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.56928687]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.37413534]\n",
            "  [-33.20978726]\n",
            "  [-33.03429144]]\n",
            "\n",
            " [[-33.20978726]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-33.03429144]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.84833182]\n",
            "  [-32.6525533 ]\n",
            "  [-32.4874653 ]]\n",
            "\n",
            " [[-32.6525533 ]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.4874653 ]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.35146259]\n",
            "  [-32.20283678]\n",
            "  [-32.04235085]]\n",
            "\n",
            " [[-32.20283678]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-32.04235085]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.87072445]\n",
            "  [-31.68863635]\n",
            "  [-31.53634936]]\n",
            "\n",
            " [[-31.68863635]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.53634936]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.37254329]\n",
            "  [-31.19791608]\n",
            "  [-31.01312605]]\n",
            "\n",
            " [[-31.19791608]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-31.01312605]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.85815006]\n",
            "  [-30.73142468]\n",
            "  [-30.59185077]]\n",
            "\n",
            " [[-30.73142468]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.59185077]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.44019749]\n",
            "  [-30.27719051]\n",
            "  [-30.1035144 ]]\n",
            "\n",
            " [[-30.27719051]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-30.1035144 ]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.91981494]\n",
            "  [-29.72670125]\n",
            "  [-29.52474784]]\n",
            "\n",
            " [[-29.72670125]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.52474784]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-29.31449652]\n",
            "  [-29.09645822]\n",
            "  [-28.8711147 ]]\n",
            "\n",
            " [[-29.09645822]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.8711147 ]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.63892018]\n",
            "  [-28.40030288]\n",
            "  [-28.15566643]]\n",
            "\n",
            " [[-28.40030288]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-28.15566643]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.90539128]\n",
            "  [-27.64983596]\n",
            "  [-27.4272172 ]]\n",
            "\n",
            " [[-27.64983596]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-27.4272172 ]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-27.19780615]\n",
            "  [-26.99990222]\n",
            "  [-26.79385472]]\n",
            "\n",
            " [[-26.99990222]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.79385472]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.58015804]\n",
            "  [-26.35927849]\n",
            "  [-26.16934236]]\n",
            "\n",
            " [[-26.35927849]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-26.16934236]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-26.00870589]\n",
            "  [-25.8379374 ]\n",
            "  [-25.65763892]]\n",
            "\n",
            " [[-25.8379374 ]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.65763892]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.50606509]\n",
            "  [-25.38169345]\n",
            "  [-25.245207  ]]\n",
            "\n",
            " [[-25.38169345]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-25.245207  ]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-25.09731619]\n",
            "  [-24.97637812]\n",
            "  [-24.84318559]]\n",
            "\n",
            " [[-24.97637812]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.84318559]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.69845566]\n",
            "  [-24.5804586 ]\n",
            "  [-24.48777984]]\n",
            "\n",
            " [[-24.5804586 ]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.48777984]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.38130152]\n",
            "  [-24.2618252 ]\n",
            "  [-24.13010756]]\n",
            "\n",
            " [[-24.2618252 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-24.13010756]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.9868629 ]\n",
            "  [-23.87017888]\n",
            "  [-23.74114588]]]\n",
            "[-52.73829  -52.405334 -52.191345 -52.163177 -51.95576  -51.64265\n",
            " -51.261986 -50.8007   -50.35569  -50.200047 -50.077763 -50.182053\n",
            " -50.26725  -50.302135 -50.417843 -50.42125  -50.532032 -50.507114\n",
            " -50.522778 -50.512543 -50.410114 -50.371193 -50.250755 -50.244648\n",
            " -50.02041  -49.757977 -49.537415 -49.379642 -48.97591  -48.70071\n",
            " -48.339638 -48.01307  -47.54282  -47.035175 -46.502625 -46.272797\n",
            " -45.964622 -45.450718 -44.9275   -44.324043 -43.773228 -43.242496\n",
            " -42.889084 -42.725525 -42.748425 -42.813015 -42.657833 -42.587536\n",
            " -42.439857 -42.246674 -42.180477 -41.86567  -41.506344 -41.048195\n",
            " -40.776546 -40.621567 -40.551655 -40.403503 -40.202095 -39.972366\n",
            " -39.60472  -39.353092 -39.013325 -38.884212 -38.67963  -38.422024\n",
            " -37.999435 -37.50802  -37.002663 -36.426907 -35.999756 -35.470192\n",
            " -35.073666 -34.762394 -34.331192 -33.91052  -33.362312 -32.81609\n",
            " -32.270096 -31.849888 -31.333403 -30.809881 -30.407724 -29.91725\n",
            " -29.310059 -28.63351  -27.899702 -27.165781 -26.560337 -25.94271\n",
            " -25.461918 -25.07149  -24.682383 -24.334845 -23.991714 -23.580252]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Test Predictions    Actuals\n",
              "0         -52.738289 -52.718817\n",
              "1         -52.405334 -52.408805\n",
              "2         -52.191345 -52.281384\n",
              "3         -52.163177 -52.197083\n",
              "4         -51.955761 -51.939383\n",
              "..               ...        ...\n",
              "91        -25.071489 -25.097316\n",
              "92        -24.682383 -24.698456\n",
              "93        -24.334845 -24.381302\n",
              "94        -23.991714 -23.986863\n",
              "95        -23.580252 -23.986863\n",
              "\n",
              "[96 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fbf2e0f-093f-43be-a2dc-0f91e5d58f5c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Predictions</th>\n",
              "      <th>Actuals</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-52.738289</td>\n",
              "      <td>-52.718817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-52.405334</td>\n",
              "      <td>-52.408805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-52.191345</td>\n",
              "      <td>-52.281384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-52.163177</td>\n",
              "      <td>-52.197083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-51.955761</td>\n",
              "      <td>-51.939383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>-25.071489</td>\n",
              "      <td>-25.097316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>-24.682383</td>\n",
              "      <td>-24.698456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>-24.334845</td>\n",
              "      <td>-24.381302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>-23.991714</td>\n",
              "      <td>-23.986863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>-23.580252</td>\n",
              "      <td>-23.986863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fbf2e0f-093f-43be-a2dc-0f91e5d58f5c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2fbf2e0f-093f-43be-a2dc-0f91e5d58f5c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2fbf2e0f-093f-43be-a2dc-0f91e5d58f5c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-95f964a6-f8d4-458d-8722-98c27c8dabad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95f964a6-f8d4-458d-8722-98c27c8dabad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-95f964a6-f8d4-458d-8722-98c27c8dabad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_546b8146-8dca-43b5-9512-b64a8a94fbc7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_results2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_546b8146-8dca-43b5-9512-b64a8a94fbc7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_results2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_results2",
              "summary": "{\n  \"name\": \"test_results2\",\n  \"rows\": 96,\n  \"fields\": [\n    {\n      \"column\": \"Test Predictions\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          -31.333402633666992,\n          -32.81608963012695,\n          -34.762393951416016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actuals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.490652520995768,\n        \"min\": -52.71881690914811,\n        \"max\": -23.986862897951863,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          -37.01624714653313,\n          -50.3261774912853,\n          -35.134646999199404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_results2['Test Predictions'],color='blue',marker='o')\n",
        "plt.plot(test_results2['Actuals'],color='red',marker='s')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "9e7fb8d0-c34b-41c8-ee8e-1c8df27958d6",
        "id": "Mq-xDg8oV59I"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x792b19ad19c0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}